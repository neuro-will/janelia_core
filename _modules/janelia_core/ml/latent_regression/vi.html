<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>janelia_core.ml.latent_regression.vi &mdash; janelia_core 1.0 documentation</title><link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/language_data.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> janelia_core
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Setting up the core library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html#dependencies">Dependencies</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../autoapi/janelia_core/index.html">janelia_core</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">janelia_core</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>janelia_core.ml.latent_regression.vi</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for janelia_core.ml.latent_regression.vi</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Tools for fitting latent regression models with variational inference. &quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">import</span> <span class="nn">janelia_core</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.datasets</span> <span class="kn">import</span> <span class="n">TimeSeriesBatch</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.latent_regression.subject_models</span> <span class="kn">import</span> <span class="n">LatentRegModel</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.torch_distributions</span> <span class="kn">import</span> <span class="n">CondMatrixProductDistribution</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.torch_distributions</span> <span class="kn">import</span> <span class="n">CondVAEDistribution</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.torch_distributions</span> <span class="kn">import</span> <span class="n">DistributionPenalizer</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.torch_parameter_penalizers</span> <span class="kn">import</span> <span class="n">ParameterPenalizer</span>

<span class="kn">from</span> <span class="nn">janelia_core.ml.utils</span> <span class="kn">import</span> <span class="n">format_and_check_learning_rates</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.utils</span> <span class="kn">import</span> <span class="n">torch_devices_memory_usage</span>


<div class="viewcode-block" id="format_output_list"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.format_output_list">[docs]</a><span class="k">def</span> <span class="nf">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">it_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">vls</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]):</span>
    <span class="sd">&quot;&quot;&quot; Produces a string to display a list of outputs.</span>

<span class="sd">    String will be of the format:</span>

<span class="sd">        base_str + &#39; &#39; + it_str+inds[0] + &#39;: &#39; + str(vls[0]) + &#39;, &#39; + it_str+inds[1] + &#39;: &#39; + str(vls[1]) + ...</span>

<span class="sd">    Args:</span>
<span class="sd">        base_str: The base string that preceeds everything else on the string</span>

<span class="sd">        it_str: The string that should come befor each printed value</span>

<span class="sd">        vls: The values that should be printed</span>

<span class="sd">        inds: The indices to associate with each printed value</span>

<span class="sd">    Returns:</span>
<span class="sd">        f_str: The formatted string</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_vls</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vls</span><span class="p">)</span>

    <span class="n">f_str</span> <span class="o">=</span> <span class="n">base_str</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">vl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">vls</span><span class="p">):</span>
        <span class="n">f_str</span> <span class="o">+=</span> <span class="n">it_str</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">inds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39;: {&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;:.2e}&#39;</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_vls</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">f_str</span> <span class="o">+=</span> <span class="s1">&#39;, &#39;</span>

    <span class="c1"># Format values</span>
    <span class="n">f_str</span> <span class="o">=</span> <span class="n">f_str</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">vls</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">f_str</span></div>


<div class="viewcode-block" id="concatenate_check_points"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.concatenate_check_points">[docs]</a><span class="k">def</span> <span class="nf">concatenate_check_points</span><span class="p">(</span><span class="n">check_points</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">params</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; Concatenates lists of checkpoints and computes total epochs to each checkpoint from multiple rounds of fitting.</span>

<span class="sd">    Args:</span>
<span class="sd">        check_points: check_points[i] is a sequence of check points produced by a call to</span>
<span class="sd">        MultiSubjectVIFitter.fit().  It is assumed that entries in check_points match the order they were produced</span>
<span class="sd">        in the actual fitting.</span>

<span class="sd">        params: params[i] is a dictionary for the call to MultiSubjectVIFitter.fit() that produced the checkpoints</span>
<span class="sd">        in check_points[i].  Is should have the fields:</span>
<span class="sd">            cp_epochs: For the epochs that the checkpoints were created at</span>
<span class="sd">            n_epochs: For the total number of epochs that fitting was run for</span>

<span class="sd">    Returns:</span>

<span class="sd">        conc_check_points: The concatenated list of check points</span>

<span class="sd">        cp_epochs: The total accumulated epochs that were run to get to each check point.</span>

<span class="sd">        orig_cp_fits: orig_cp_fits[0,i] is the index of the fit for the i^th concatenated checkpoint and</span>
<span class="sd">                      orig_cp_fits[1,i] is the index of this check point in the logs for that fit.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_fits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">check_points</span><span class="p">)</span>

    <span class="n">n_fit_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;n_epochs&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
    <span class="n">cp_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;cp_epochs&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>

    <span class="c1"># Record where each check point came from</span>
    <span class="n">cp_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([(</span><span class="n">c_i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cp_es</span><span class="p">)))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">c_i</span><span class="p">,</span> <span class="n">cp_es</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cp_epochs</span><span class="p">)])</span>
    <span class="n">cp_fit_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cp_es</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">cp_es</span> <span class="ow">in</span> <span class="n">cp_epochs</span><span class="p">])</span>
    <span class="n">orig_cp_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">cp_fits</span><span class="p">,</span> <span class="n">cp_fit_inds</span><span class="p">])</span>

    <span class="c1"># Make sure cp_epochs are arrays</span>
    <span class="n">cp_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">vls</span><span class="p">)</span> <span class="k">for</span> <span class="n">vls</span> <span class="ow">in</span> <span class="n">cp_epochs</span><span class="p">]</span>

    <span class="n">total_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">f_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_fits</span><span class="p">):</span>
        <span class="n">cp_epochs</span><span class="p">[</span><span class="n">f_i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">total_sum</span>
        <span class="n">total_sum</span> <span class="o">+=</span> <span class="n">n_fit_epochs</span><span class="p">[</span><span class="n">f_i</span><span class="p">]</span>

    <span class="n">cp_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">cp_epochs</span><span class="p">)</span>

    <span class="n">conc_check_points</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">check_points</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">conc_check_points</span><span class="p">,</span> <span class="n">cp_epochs</span><span class="p">,</span> <span class="n">orig_cp_fits</span><span class="p">]</span></div>


<div class="viewcode-block" id="PriorCollection"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.PriorCollection">[docs]</a><span class="k">class</span> <span class="nc">PriorCollection</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Holds prior distributions when fitting models with variational inference.</span>

<span class="sd">    This object offers convenience functions for getting all the parameters for the priors as well as moving the</span>
<span class="sd">    distributions to different devices.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span>
                 <span class="n">u_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span>
                 <span class="n">psi_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span>
                 <span class="n">scale_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">offset_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">direct_mapping_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new PriorCollection object.</span>

<span class="sd">        When specifying a prior distribution over a parameter, the user can specify either a CondVAEDistribution object,</span>
<span class="sd">        which will be used if posterior distributions are fit over the parameter.  Alternatively, if point estimates</span>
<span class="sd">        will be fit over the parameter, the user can provide the value None.  E.g., if a distribution will be fit over</span>
<span class="sd">        the first input group modes but not the second p_dists would be set to [d, None], where d is a</span>
<span class="sd">        CondVAEDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            p_dists: Prior distributions over p modes.</span>

<span class="sd">            u_dists: Prior distributions over u modes.</span>

<span class="sd">            psi_dists: Prior distributions over variance parameters.</span>

<span class="sd">            scale_dists: Prior distributions over scale parameters.  If scale parameters are not used in subject</span>
<span class="sd">            models, set this to None.</span>

<span class="sd">            offset_dists: Prior distributions over offset parameters.  If offset parameters are not use in subject</span>
<span class="sd">            models, set this to None.</span>

<span class="sd">            direct_mapping_dists: Prior distributions over direct mappings.  direct_mapping_dists[i] should be the</span>
<span class="sd">            prior over the direct mappings in direct_pairs[i] in subject  models.  If direct mappings are not used,</span>
<span class="sd">            set this to None.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="o">=</span> <span class="n">p_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="o">=</span> <span class="n">u_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="o">=</span> <span class="n">psi_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="o">=</span> <span class="n">scale_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="o">=</span> <span class="n">offset_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="o">=</span> <span class="n">direct_mapping_dists</span>

<div class="viewcode-block" id="PriorCollection.get_used_devices"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.PriorCollection.get_used_devices">[docs]</a>    <span class="k">def</span> <span class="nf">get_used_devices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns all devices that priors are on. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">psi_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">psi_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">offset_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">offset_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
                                           <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">p_dist_devices</span> <span class="o">+</span> <span class="n">u_dist_devices</span> <span class="o">+</span> <span class="n">psi_dist_devices</span> <span class="o">+</span> <span class="n">scale_dist_devices</span> <span class="o">+</span>
                        <span class="n">offset_dist_devices</span> <span class="o">+</span> <span class="n">direct_mapping_dist_devices</span><span class="p">))</span></div>

<div class="viewcode-block" id="PriorCollection.r_params"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.PriorCollection.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Gets parameters of all modules for which gradients can be estimated with the reparameterization trick. &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_dist_params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">psi_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">psi_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span> <span class="k">for</span>
                                                           <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">p_dist_params</span><span class="p">,</span> <span class="n">u_dist_params</span><span class="p">,</span> <span class="n">psi_dist_params</span><span class="p">,</span> <span class="n">scale_dist_params</span><span class="p">,</span>
                                    <span class="n">offset_dist_params</span><span class="p">,</span> <span class="n">direct_mapping_dist_params</span><span class="p">))</span></div>

<div class="viewcode-block" id="PriorCollection.s_params"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.PriorCollection.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Gets parameters of all modules for which gradients can be estimated with the score method. &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">p_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">u_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">u_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">psi_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">psi_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span> <span class="k">for</span>
                                                           <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">p_dist_params</span><span class="p">,</span> <span class="n">u_dist_params</span><span class="p">,</span> <span class="n">psi_dist_params</span><span class="p">,</span> <span class="n">scale_dist_params</span><span class="p">,</span>
                                    <span class="n">offset_dist_params</span><span class="p">,</span> <span class="n">direct_mapping_dist_params</span><span class="p">))</span></div>

<div class="viewcode-block" id="PriorCollection.to"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.PriorCollection.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot; Moves all distributions in the collection to a specified device. &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">move_if_not_none</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dists</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">)</span></div></div>

<span class="c1"># TODO: Remove if we confirm we no longer need</span>
<span class="c1">#def compute_prior_penalty(mn: torch.Tensor, positions: torch.Tensor):</span>
<span class="c1">#    &quot;&quot;&quot; Computes a penalty for a sampled prior.  This is experimental.</span>
<span class="c1">#</span>
<span class="c1">#    Args:</span>
<span class="c1">#    &quot;&quot;&quot;</span>
<span class="c1">#</span>
<span class="c1">#    n_modes = mn.shape[1]</span>
<span class="c1">#    compute_device = mn.device</span>
<span class="c1">#</span>
<span class="c1">#    penalty = torch.zeros([1], device=compute_device)[0]  # Weird indexing is to get a scalar tensor</span>
<span class="c1">#    for m_i in range(n_modes):</span>
<span class="c1">#        mode_abs_vls = torch.sum(torch.abs(mn[:, m_i:m_i+1]))</span>
<span class="c1">#        mode_l2_norm_sq = torch.sum(mn[:, m_i:m_i+1]**2)</span>
<span class="c1">#        #mode_weighted_positions = positions*mode_abs_vls</span>
<span class="c1">#        #mode_weighted_center = torch.mean(mode_weighted_positions, dim=0)</span>
<span class="c1">#        #penalty += torch.sum(torch.sum((positions - mode_weighted_center)**2, dim=1)*torch.squeeze(mode_abs_vls))</span>
<span class="c1">#        penalty += mode_abs_vls + (mode_l2_norm_sq - 10)**2</span>
<span class="c1">#    return penalty</span>


<div class="viewcode-block" id="SubjectVICollection"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.SubjectVICollection">[docs]</a><span class="k">class</span> <span class="nc">SubjectVICollection</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Holds data, likelihood models and posteriors for fitting data to a single subject with variational inference.</span>

<span class="sd">    This object offers convenience functions to get all the trainable parameters for a subject model and its posteriors</span>
<span class="sd">    as well as moving everything needed for fitting for that subject to different devices.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s_mdl</span><span class="p">:</span> <span class="n">LatentRegModel</span><span class="p">,</span> <span class="n">p_dists</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                 <span class="n">u_dists</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                 <span class="n">psi_dists</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                 <span class="n">data</span><span class="p">:</span> <span class="n">TimeSeriesBatch</span><span class="p">,</span> <span class="n">input_grps</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">output_grps</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">props</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="n">p_props</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">u_props</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">psi_props</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                 <span class="n">scale_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
                     <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">offset_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
                     <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">direct_mappings_dists</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
                     <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">scale_props</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">offset_props</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">direct_mapping_props</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">min_var</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new SubjectVICollection object.</span>

<span class="sd">        When specify the distribution over a parameter of the model, the user can specify either (1) a</span>
<span class="sd">        janelia_core.ml.torch_distributions.CondVAEDistribution object or (2) None.  Specifying a distribution</span>
<span class="sd">        means that distribution will be used as the posterior distribution over the parameter for fitting.  Specifying</span>
<span class="sd">        None, means that a distribution won&#39;t be fit for that parameter.  Instead, a point estimate will be fit by</span>
<span class="sd">        directly optimizing the value of the parameter in the subject model.</span>

<span class="sd">        Args:</span>
<span class="sd">            s_mdl: The likelihood model for the subject.</span>

<span class="sd">            p_dists: The posterior distributions for the p modes.</span>

<span class="sd">            u_dists: The posterior distributions for the u modes.</span>

<span class="sd">            psi_dists: The posterior distributions for psi parameters.</span>

<span class="sd">            data: Data for the subject.</span>

<span class="sd">            input_grps: input_grps[g] is the index into data.data for the g^th input group</span>

<span class="sd">            output_grps: output_grps[h] is the index into data.data for the h^th output group</span>

<span class="sd">            props: props[i] is a tensor of properties.  If there are no properties, this should be None.</span>

<span class="sd">            p_props: p_props[g] is the index into props for the properties for the modes for the g^th input group.  If</span>
<span class="sd">            there are no distributions over the modes for this group, p_props[g] should be None. p_props[g] should also</span>
<span class="sd">            be None if there are distributions for these modes but they are not conditioned on anything.</span>

<span class="sd">            u_props:  p_props[h] is the index into props for the properties for the modes for the h^th output group,</span>
<span class="sd">            same format as u_props.</span>

<span class="sd">            psi_props:  psi_props[h] is the index into props for the properties for the variances for the h^th output</span>
<span class="sd">            group, same format as u_props.</span>

<span class="sd">            scale_dists: The posterior distributions for scale parameters. If scales are not used in the model,</span>
<span class="sd">            set to None.</span>

<span class="sd">            offset_dists: The posterior distributions for offset parameters, same form as scale_dists.</span>

<span class="sd">            direct_mappings_dists: Distributions over direct mappings.  If there are no direct mappings in the model,</span>
<span class="sd">            this should be None.  If there are direct mappings, direct_mapping_dists[i] is the distribution over</span>
<span class="sd">            s_mdl.direct_mappings[i].</span>

<span class="sd">            scale_props:  scale_props[h] is the index into props for the properties for the scales for the h^th output</span>
<span class="sd">            group, same format as u_props.</span>

<span class="sd">            offset_props:  offset_props[h] is the index into props for the properties for the offsets for the h^th output</span>
<span class="sd">            group, same format as u_props.</span>

<span class="sd">            direct_mapping_props: direct_mapping_props[i] is the index into props for the properties for the i^th</span>
<span class="sd">            direct mapping, same format as u_props</span>

<span class="sd">            min_var: min_var[h] is the minimum variance for the additive noise variables for output group h. If</span>
<span class="sd">            set to None, min_var for all output groups will be set to .01.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">s_mdl</span> <span class="o">=</span> <span class="n">s_mdl</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="o">=</span> <span class="n">p_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="o">=</span> <span class="n">u_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="o">=</span> <span class="n">scale_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="o">=</span> <span class="n">offset_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="o">=</span> <span class="n">psi_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="o">=</span> <span class="n">direct_mappings_dists</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_grps</span> <span class="o">=</span> <span class="n">input_grps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_grps</span> <span class="o">=</span> <span class="n">output_grps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">props</span> <span class="o">=</span> <span class="n">props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">u_props</span> <span class="o">=</span> <span class="n">u_props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_props</span> <span class="o">=</span> <span class="n">p_props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_props</span> <span class="o">=</span> <span class="n">scale_props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">offset_props</span> <span class="o">=</span> <span class="n">offset_props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">psi_props</span> <span class="o">=</span> <span class="n">psi_props</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_props</span> <span class="o">=</span> <span class="n">direct_mapping_props</span>

        <span class="k">if</span> <span class="n">min_var</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_var</span> <span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">01</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">p_dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_var</span> <span class="o">=</span> <span class="n">min_var</span>

<div class="viewcode-block" id="SubjectVICollection.trainable_parameters"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.SubjectVICollection.trainable_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">trainable_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parameter</span><span class="o">.</span><span class="n">Parameter</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Returns all trainable parameters for the collection.</span>

<span class="sd">        Returns:</span>
<span class="sd">            params: The list of parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">s_mdl_parameters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">()</span>

        <span class="n">p_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="n">u_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="n">psi_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">scale_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">offset_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span>
                                                           <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">direct_mapping_dist_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">s_mdl_parameters</span><span class="p">,</span> <span class="n">p_dist_params</span><span class="p">,</span> <span class="n">u_dist_params</span><span class="p">,</span> <span class="n">psi_dist_params</span><span class="p">,</span>
                                    <span class="n">scale_dist_params</span><span class="p">,</span> <span class="n">offset_dist_params</span><span class="p">,</span> <span class="n">direct_mapping_dist_params</span><span class="p">))</span></div>

<div class="viewcode-block" id="SubjectVICollection.to"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.SubjectVICollection.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">distribute_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Moves all relevant attributes of the collection to the specified device.</span>

<span class="sd">        Note that by default fitting data will not be moved to the device.</span>

<span class="sd">        Args:</span>
<span class="sd">            device: The device to move attributes to.</span>

<span class="sd">            distribute_data: True if fitting data should be moved to the device as well</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">move_if_not_none</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dists</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">u_dists</span><span class="p">)</span>
        <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">move_if_not_none</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">props</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">props</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">props</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">distribute_data</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MultiSubjectVIFitter"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter">[docs]</a><span class="k">class</span> <span class="nc">MultiSubjectVIFitter</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot; Object for fitting a collection of latent regression models with variational inference.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s_collections</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">SubjectVICollection</span><span class="p">],</span> <span class="n">prior_collection</span><span class="p">:</span> <span class="n">PriorCollection</span><span class="p">,</span>
                 <span class="n">input_modules</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">penalizers</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">ParameterPenalizer</span><span class="p">],</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new MultiSubjectVIFitter object.</span>

<span class="sd">        Args:</span>
<span class="sd">            s_collections: A set of SubjectVICollections to use when fitting data.</span>

<span class="sd">            prior_collection: The prior collection to use when fitting data.</span>

<span class="sd">            input_modules: Contains modules to apply to inputs before they are passed to subject models.  If None,</span>
<span class="sd">            no input modules will be used.  If a list, the g^th module is the module to apply to the input for</span>
<span class="sd">            input group g.  If no module should be applied to a group, the entry for that group should be None.</span>

<span class="sd">            penalizers: Parameter penalizers that will be used when fitting.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If we are not using input_modules, we still create an input_modules list with all None entries, so the</span>
        <span class="c1"># rest of our code can be a bit simpler</span>
        <span class="k">if</span> <span class="n">input_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_modules</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">s_collections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input_grps</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span> <span class="o">=</span> <span class="n">s_collections</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span> <span class="o">=</span> <span class="n">input_modules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span> <span class="o">=</span> <span class="n">prior_collection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="o">=</span> <span class="n">penalizers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Keep track of if we have distributed everything yet</span>

<div class="viewcode-block" id="MultiSubjectVIFitter.create_check_point"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.create_check_point">[docs]</a>    <span class="k">def</span> <span class="nf">create_check_point</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inc_penalizers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns copies of subject vi collections, priors as well as (optionally) penalizer parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            inc_penalizers: True if copies of penalizer parameters should be returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            cp_dict: A dictionary with the following keys:</span>

<span class="sd">                s_collections: Copies of the subject collections, with data and properties removed</span>

<span class="sd">                prior_collection: Copy of the prior collection</span>

<span class="sd">                input_modules: Copy of input modules.</span>

<span class="sd">                parameter_penalizer_dicts: If penalizer parameters are requested, then parameter_penalizer_dicts[i] is</span>
<span class="sd">                the dictionary witch check point parameters for the i^th parameter penalizer, where the ordering of</span>
<span class="sd">                penalizers is the same as when parameter penalizers were provided at the time of the creation of the</span>
<span class="sd">                Fitter object.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">orig_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_used_devices</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="n">distribute_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">s_collections_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">s_coll</span> <span class="ow">in</span> <span class="n">s_collections_copy</span><span class="p">:</span>
            <span class="n">s_coll</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">prior_collection_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="p">)</span>

        <span class="n">input_modules_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inc_penalizers</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">parameter_penalizer_dicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">check_point</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">parameter_penalizer_dicts</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Move subject collections back to devices</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">distribute</span><span class="p">(</span><span class="n">devices</span><span class="o">=</span><span class="n">orig_devices</span><span class="p">,</span> <span class="n">distribute_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;s_collections&#39;</span><span class="p">:</span> <span class="n">s_collections_copy</span><span class="p">,</span>
                <span class="s1">&#39;prior_collection&#39;</span><span class="p">:</span> <span class="n">prior_collection_copy</span><span class="p">,</span>
                <span class="s1">&#39;input_modules&#39;</span><span class="p">:</span> <span class="n">input_modules_copy</span><span class="p">,</span>
                <span class="s1">&#39;parameter_penalizer_dicts&#39;</span><span class="p">:</span> <span class="n">parameter_penalizer_dicts</span><span class="p">}</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.distribute"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.distribute">[docs]</a>    <span class="k">def</span> <span class="nf">distribute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">devices</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span> <span class="n">s_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                   <span class="n">distribute_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Distributes priors, subject collections and penalizers across devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            devices: Devices that priors and subject collections should be distributed across.</span>

<span class="sd">            s_inds: Indices into self.s_collections for subject models which should be distributed across devices.</span>
<span class="sd">            If none, all subject models will be distributed.</span>

<span class="sd">            distribute_data: True if all training data should be distributed to devices.  If there is enough</span>
<span class="sd">            device memory, this can speed up fitting.  If not, set this to false, and batches of data will</span>
<span class="sd">            be sent to the device for each training iteration.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">s_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">s_inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">))</span>

        <span class="n">n_devices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span>
        <span class="n">n_dist_mdls</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_inds</span><span class="p">)</span>

        <span class="c1"># Distribute priors; by convention priors go onto first device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Distribute input modules - these get moved from device to device as they need to process input</span>
        <span class="c1"># for each subject model, so where they go really doesn&#39;t matter, but by default they start on the first</span>
        <span class="c1"># device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># We also put penalizers on first device</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">penalizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">:</span>
                <span class="n">penalizer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Distribute subject collections</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_dist_mdls</span><span class="p">):</span>
            <span class="n">device_ind</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">n_devices</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_inds</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">devices</span><span class="p">[</span><span class="n">device_ind</span><span class="p">],</span> <span class="n">distribute_data</span><span class="o">=</span><span class="n">distribute_data</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span> <span class="o">=</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.trainable_parameters"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.trainable_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">trainable_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">get_prior_params</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Gets all trainable parameters for fitting.</span>

<span class="sd">        This function returns separate parameters for penalizer parameters and all other parameters, to faciltate</span>
<span class="sd">        applying different learning rates to the penalizer parameters.</span>

<span class="sd">        Args:</span>
<span class="sd">            s_inds: Specifies the indices of subjects that will be fit.  Subject indices correspond to their</span>
<span class="sd">            original order in s_collections when the fitter was created. If None, all subjects used.</span>

<span class="sd">            get_prior_params: True if parameters of priors should be included in the set of returned parameters</span>

<span class="sd">        Returns:</span>
<span class="sd">             base_params: Parameters of priors, posteriors, input modules and subject models</span>

<span class="sd">             penalizer_params: Parameters of any penalizers</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Get base parameters</span>
        <span class="k">if</span> <span class="n">s_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">s_inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">get_prior_params</span><span class="p">:</span>
            <span class="n">prior_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prior_params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">collection_params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">()</span> <span class="k">for</span> <span class="n">s_i</span> <span class="ow">in</span> <span class="n">s_inds</span><span class="p">])</span>
        <span class="n">base_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="n">collection_params</span><span class="p">,</span> <span class="n">prior_params</span><span class="p">))</span>

        <span class="c1"># Clean for duplicate parameters.  Subject models might shared a posterior, for example, so we need to</span>
        <span class="c1"># check for this</span>
        <span class="n">non_duplicate_base_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">base_params</span><span class="p">))</span>

        <span class="c1"># Add in input module parameters to base parameters</span>
        <span class="n">input_module_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="n">non_duplicate_base_params</span> <span class="o">=</span> <span class="n">non_duplicate_base_params</span> <span class="o">+</span> <span class="n">input_module_params</span>

        <span class="c1"># Get penalizer parameters - the get_penalizer_params() already checks for duplicates</span>
        <span class="n">non_duplicate_penalizer_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_penalizer_params</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">non_duplicate_base_params</span><span class="p">,</span> <span class="n">non_duplicate_penalizer_params</span><span class="p">]</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.get_penalizer_params"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.get_penalizer_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_penalizer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keys</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of penalizer parameters, optionally filtering by key.</span>

<span class="sd">        Args:</span>
<span class="sd">            keys: If provided, either a string of a single key that returned parameters should match or a</span>
<span class="sd">            sequence of keys parameters can match.  Any parameters not matching the requested key(s), will</span>
<span class="sd">            not be returned.  If keys is None, all penalizer parameters will be returned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            params: A list of the requested parameters</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># First, if we have no penalizers, we just return an empyt list</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

        <span class="c1"># Use all keys if user has not provided any</span>
        <span class="k">if</span> <span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">keys</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">list_param_keys</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="k">if</span> <span class="n">p</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">])</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">keys</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">keys</span><span class="p">]</span>

        <span class="c1"># Get requested parameters</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">keys</span><span class="p">))</span>

        <span class="n">params</span> <span class="o">=</span> <span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">get_marked_params</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">])</span>
                                   <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">])</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">)))</span>

        <span class="k">return</span> <span class="n">params</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.generate_batch_smp_inds"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.generate_batch_smp_inds">[docs]</a>    <span class="k">def</span> <span class="nf">generate_batch_smp_inds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">s_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot; Generates indices of random mini-batches of samples for each subject.</span>

<span class="sd">        Args:</span>
<span class="sd">            n_batches: The number of batches to break the data up for each subject into.</span>

<span class="sd">            s_inds: Specifies the indices of subjects that will be fit.  Subject indices correspond to their</span>
<span class="sd">            original order in s_collections when the fitter was created. If None, s_inds = range(n_subjects).</span>

<span class="sd">        Returns:</span>
<span class="sd">            batch_smp_inds: batch_smp_inds[i][j] is the sample indices for the j^th batch for subject s_inds[i]</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">s_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">s_inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">))</span>

        <span class="n">n_subjects</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_inds</span><span class="p">)</span>

        <span class="n">n_smps</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">s_i</span> <span class="ow">in</span> <span class="n">s_inds</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n_s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_smps</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">n_s</span> <span class="o">&lt;</span> <span class="n">n_batches</span><span class="p">:</span>
                <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Subject &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">s_inds</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">+</span> <span class="s1">&#39; has only &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_s</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; samples, while &#39;</span>
                      <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_batches</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; batches requested.&#39;</span><span class="p">))</span>

        <span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">n_s</span><span class="p">)</span><span class="o">/</span><span class="n">n_batches</span><span class="p">))</span> <span class="k">for</span> <span class="n">n_s</span> <span class="ow">in</span> <span class="n">n_smps</span><span class="p">]</span>

        <span class="n">batch_smp_inds</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_subjects</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_subjects</span><span class="p">):</span>
            <span class="n">subject_batch_smp_inds</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_batches</span>
            <span class="n">perm_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_smps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">start_smp_ind</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">b_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>
                <span class="n">end_smp_ind</span> <span class="o">=</span> <span class="n">start_smp_ind</span><span class="o">+</span><span class="n">batch_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">subject_batch_smp_inds</span><span class="p">[</span><span class="n">b_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">perm_inds</span><span class="p">[</span><span class="n">start_smp_ind</span><span class="p">:</span><span class="n">end_smp_ind</span><span class="p">]</span>
                <span class="n">start_smp_ind</span> <span class="o">=</span> <span class="n">end_smp_ind</span>
            <span class="n">batch_smp_inds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">subject_batch_smp_inds</span>

        <span class="k">return</span> <span class="n">batch_smp_inds</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.get_used_devices"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.get_used_devices">[docs]</a>    <span class="k">def</span> <span class="nf">get_used_devices</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Lists any device currently used for fitting.</span>

<span class="sd">        Returns:</span>
<span class="sd">            devices: The list of devices parameters are on in.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">s_mdl_devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">s_coll</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">s_coll</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">]</span>
        <span class="n">data_devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">s_coll</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">s_coll</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">]</span>  <span class="c1"># TODO: Should check all data tensors</span>
        <span class="n">prior_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">get_used_devices</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">penalizer_parameters</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">penalizer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="k">for</span> <span class="n">penalizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">]</span>
            <span class="n">penalizer_devices</span> <span class="o">=</span> <span class="p">[</span><span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">penalizer_parameters</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">penalizer_devices</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">input_module_devices</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span> <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">s_mdl_devices</span> <span class="o">+</span> <span class="n">data_devices</span> <span class="o">+</span> <span class="n">prior_devices</span> <span class="o">+</span> <span class="n">input_module_devices</span> <span class="o">+</span> <span class="n">penalizer_devices</span><span class="p">))</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.fit"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">n_batches</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">learning_rates</span><span class="o">=.</span><span class="mi">01</span><span class="p">,</span>
            <span class="n">adam_params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{},</span> <span class="n">s_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">fix_priors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">enforce_priors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">update_int</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">print_opts</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">cp_epochs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">cp_penalizers</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">[</span><span class="nb">dict</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">,</span> <span class="kc">None</span><span class="p">]]:</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>

<span class="sd">            n_epochs: The number of epochs to run fitting for.</span>

<span class="sd">            n_batches: The number of batches to break the training data up into per epoch.  When multiple subjects have</span>
<span class="sd">            different numbers of total training samples, the batch size for each subject will be selected so we go</span>
<span class="sd">            through the entire training set for each subject after processing n_batches each epoch.</span>

<span class="sd">            learning_rates: If a single number, this is the learning rate to use for all epochs and parameters.</span>
<span class="sd">            Alternatively, this can be a list of tuples.  Each tuple is of the form</span>
<span class="sd">            (epoch, base_lr, penalizer_lr_opts), where epoch is the epoch the learning rates come into effect on,</span>
<span class="sd">            base_lr is the learning rate for all parameters other than the penalizer parameters and penalizer_lr_opts</span>
<span class="sd">            is a dictionary with keys specifying penalizer parameter keys and values giving the learning rate</span>
<span class="sd">            for those parameters. Multiple tuples can be provided to give a schedule of learning rates.  Here is an</span>
<span class="sd">            example learning_rates: [(0, .001, {&#39;fast&#39;: 1, &#39;slow&#39;, .1}), (100, .0001, {&#39;fast&#39;: .1, &#39;slow&#39;, .01}] that</span>
<span class="sd">            starts with a base learning rates of .001, a learning rate of 1 for parameters of the penalizers that</span>
<span class="sd">            should be assigned a fast learning rate and a learning rate of .1 for parameter of the penalizers that</span>
<span class="sd">            should be assigned a slow learning rate.  At epoch 100, the learning rates are divided by 10 in this</span>
<span class="sd">            example.</span>

<span class="sd">            adam_params: Dictionary of parameters to pass to the call when creating the Adam Optimizer object.</span>
<span class="sd">            Note that if learning rate is specified here *it will be ignored.* (Use the learning_rates option instead).</span>
<span class="sd">            The options specified here will be applied to all parameters at all iterations.</span>

<span class="sd">            s_inds: Specifies the indices of subjects to fit to.  Subject indices correspond to their</span>
<span class="sd">            original order in s_collections when the fitter was created. If None, all subjects used.</span>

<span class="sd">            fix_priors: True if priors should be fixed and not changed during fitting</span>

<span class="sd">            enforce_priors: True if we should calculate kl divergences between priors and posteriors and include</span>
<span class="sd">            this in the objective.</span>

<span class="sd">            update_int: Fitting status will be printed to screen every update_int number of epochs</span>

<span class="sd">            print_opts: Options controlling what is printed to screen.  See _print_fitting_status()</span>

<span class="sd">            cp_epochs: A sequence of epochs after which a check point of the models (as well as optionally the</span>
<span class="sd">            penalizers will be made).  If no check points should be made, set this to None.</span>

<span class="sd">            cp_penalizers: True if penalizers should be included in the check points.</span>

<span class="sd">        Return:</span>
<span class="sd">            log: A dictionary with the following entries:</span>

<span class="sd">                &#39;elapsed_time&#39;: A numpy array of the elapsed time for completion of each epoch</span>

<span class="sd">                &#39;mdl_nll&#39;: mdl_nll[e, i] is the negative log likelihood for the subject model s_inds[i] at the start</span>
<span class="sd">                of epoch e (that is when the objective has been calculated but before parameters have been updated)</span>

<span class="sd">                &#39;sub_p_kl&#39;: sub_p_kl[e,i] is the kl divergence between the posterior and conditional prior for the p</span>
<span class="sd">                modes for subject i at the start of epoch e.</span>

<span class="sd">                &#39;sub_u_kl&#39;: sub_u_kl[e,i] is the kl divergence between the posterior and conditional prior the u modes</span>
<span class="sd">                for subject i at the start of epoch e.</span>

<span class="sd">                &#39;p_prior_penalties&#39;: p_prior_penalties[e, :] is the penalty calculated for each group of p priors at the</span>
<span class="sd">                start of epoch e.</span>

<span class="sd">                &#39;u_prior_penalties&#39;: u_prior_penalties[e, :] is the penalty calculated for each group of u priors at the</span>
<span class="sd">                start of epoch e.</span>

<span class="sd">                parameter_penalties: parameter_penalties[e, :] is the penalty calculated for each parameter penalizer,</span>
<span class="sd">                with the order of entries in each row corresponding to the order penalizers were provided when creating</span>
<span class="sd">                the Fitter object.</span>

<span class="sd">                obj: obj[e] contains the objective value at the start of epoch e.  This is the negative evidence lower</span>
<span class="sd">                bound + weight penalties.</span>

<span class="sd">            check_points: check_points[i] are model parameters for the i^th requested checkpoint. If no check points</span>
<span class="sd">            were requested this will be None.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: If distribute() has not been called before fitting.</span>
<span class="sd">            ValueError: If sample_posteriors is False but enforce_priors is True.</span>
<span class="sd">            ValueError: If weight_penalty_type is not &#39;l1&#39; or &#39;l2&#39;.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">print_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">print_opts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mdl_nll&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                          <span class="s1">&#39;sub_kls&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                          <span class="s1">&#39;memory_usage&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                          <span class="s1">&#39;penalties&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                          <span class="s1">&#39;penalizer_states&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">distributed</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;self.distribute() must be called before fitting.&#39;</span><span class="p">))</span>

        <span class="c1"># See what devices we are using for fitting (this is so we can later query their memory usage)</span>
        <span class="n">all_devices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_used_devices</span><span class="p">()</span>

        <span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  <span class="c1"># Get starting time</span>

        <span class="c1"># Format and check learning rates - no matter the input format this outputs learning rates in a standard format</span>
        <span class="c1"># where the learning rate starting at iteration 0 is guaranteed to be listed first</span>
        <span class="n">learning_rate_its</span><span class="p">,</span> <span class="n">learning_rate_values</span> <span class="o">=</span> <span class="n">format_and_check_learning_rates</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span>

        <span class="c1"># Determine what subjects we are fitting for</span>
        <span class="k">if</span> <span class="n">s_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_subjects</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">)</span>
            <span class="n">s_inds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_subjects</span><span class="p">)</span>
        <span class="n">n_fit_subjects</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_inds</span><span class="p">)</span>

        <span class="c1"># See how many penalizers we are working with</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_penalizers</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_penalizers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">)</span>

        <span class="c1"># Determine the devices the subject collections are on</span>
        <span class="n">subject_coll_devices</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_fit_subjects</span>
        <span class="k">for</span> <span class="n">s_i</span><span class="p">,</span> <span class="n">s_ind</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">s_inds</span><span class="p">):</span>
            <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_ind</span><span class="p">]</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

        <span class="n">n_smp_data_points</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span> <span class="k">for</span> <span class="n">s_i</span> <span class="ow">in</span> <span class="n">s_inds</span><span class="p">]</span>

        <span class="c1"># Pull out groups of parameters with different learning rates</span>
        <span class="n">base_parameters</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">(</span><span class="n">s_inds</span><span class="p">,</span> <span class="n">get_prior_params</span><span class="o">=</span><span class="p">(</span><span class="n">fix_priors</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Means learning rates specified for penalizers</span>
            <span class="n">penalizer_params</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_penalizer_params</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">][</span><span class="n">key</span><span class="p">])</span>
                                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">penalizer_params</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_penalizer_params</span><span class="p">(),</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span>

        <span class="c1"># Setup initial optimizer</span>
        <span class="n">params_with_lr</span> <span class="o">=</span> <span class="p">([{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">base_parameters</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]}]</span> <span class="o">+</span>
                          <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">penalizer_params</span><span class="p">])</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">params_with_lr</span><span class="p">,</span> <span class="o">**</span><span class="n">adam_params</span><span class="p">)</span>

        <span class="c1"># Setup everything for checkpoints if we are creating them</span>
        <span class="n">check_points</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">cp_epochs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_cps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cp_epochs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">n_cps</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cp_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">cp_epochs</span><span class="p">)</span>
                <span class="n">check_points</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cps</span>

        <span class="c1"># Setup everything for logging</span>
        <span class="n">epoch_elapsed_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>
        <span class="n">epoch_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_p_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_u_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_psi_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_scales_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_offsets_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_sub_direct_mappings_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_fit_subjects</span><span class="p">])</span>
        <span class="n">epoch_penalizer_penalties</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">n_penalizers</span><span class="p">])</span>
        <span class="n">epoch_obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">)</span>

        <span class="c1"># Perform fitting</span>
        <span class="n">prev_learning_rates</span> <span class="o">=</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">e_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>

            <span class="c1"># Set the learning rate</span>
            <span class="n">cur_learing_rate_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">learning_rate_its</span> <span class="o">&lt;=</span> <span class="n">e_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cur_learing_rate_ind</span> <span class="o">=</span> <span class="n">cur_learing_rate_ind</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">cur_learning_rates</span> <span class="o">=</span> <span class="n">learning_rate_values</span><span class="p">[</span><span class="n">cur_learing_rate_ind</span><span class="p">,</span> <span class="p">:]</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">cur_learning_rates</span> <span class="o">!=</span> <span class="n">prev_learning_rates</span><span class="p">):</span>
                <span class="c1"># We reset the whole optimizer because ADAM is an adaptive optimizer</span>

                <span class="c1"># Pull out groups of parameters with different learning rates</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cur_learning_rates</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Means learning rates specified for penalizers</span>
                    <span class="n">penalizer_params</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_penalizer_params</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">cur_learning_rates</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">key</span><span class="p">])</span>
                                        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">cur_learning_rates</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">penalizer_params</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_penalizer_params</span><span class="p">(),</span> <span class="n">cur_learning_rates</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])]</span>

                <span class="n">params_with_lr</span> <span class="o">=</span> <span class="p">([{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">base_parameters</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">cur_learning_rates</span><span class="p">[</span><span class="mi">0</span><span class="p">]}]</span> <span class="o">+</span>
                                  <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">]}</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">penalizer_params</span><span class="p">])</span>

                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">params_with_lr</span><span class="p">,</span> <span class="o">**</span><span class="n">adam_params</span><span class="p">)</span>
                <span class="n">prev_learning_rates</span> <span class="o">=</span> <span class="n">cur_learning_rates</span>

            <span class="c1"># Setup the iterators to go through the current data for this epoch in a random order</span>
            <span class="n">epoch_batch_smp_inds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_batch_smp_inds</span><span class="p">(</span><span class="n">n_batches</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">s_inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">)</span>

            <span class="c1"># Process each batch</span>
            <span class="k">for</span> <span class="n">b_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>

                <span class="n">batch_obj_log</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># Zero gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">batch_nll</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_p_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_u_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_psi_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_scales_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_offsets_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_sub_direct_mappings_kl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_fit_subjects</span><span class="p">)</span>
                <span class="n">batch_penalizer_penalties</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_penalizers</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">s_inds</span><span class="p">):</span>

                    <span class="n">s_coll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span>

                    <span class="c1"># Get the data for this batch for this subject, using efficient indexing if all data is</span>
                    <span class="c1"># already on the devices where the subject models are</span>
                    <span class="n">batch_inds</span> <span class="o">=</span> <span class="n">epoch_batch_smp_inds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">b_i</span><span class="p">]</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                        <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">efficient_get_item</span><span class="p">(</span><span class="n">batch_inds</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">batch_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_i</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">batch_inds</span><span class="p">]</span>

                    <span class="c1"># Send the data to the GPU if needed</span>
                    <span class="n">batch_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                  <span class="n">non_blocking</span><span class="o">=</span><span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

                    <span class="c1"># Form x and y for the batch</span>
                    <span class="n">batch_x</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i_g</span><span class="p">][</span><span class="n">batch_data</span><span class="o">.</span><span class="n">i_x</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">i_g</span> <span class="ow">in</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">input_grps</span><span class="p">]</span>
                    <span class="n">batch_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i_h</span><span class="p">][</span><span class="n">batch_data</span><span class="o">.</span><span class="n">i_y</span><span class="p">,</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">i_h</span> <span class="ow">in</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">output_grps</span><span class="p">]</span>
                    <span class="n">n_batch_data_pts</span> <span class="o">=</span> <span class="n">batch_x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

                    <span class="c1"># Make sure the input modules are on the right device for this subject</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># Make sure the posteriors are on the right GPU for this subject (important if we are</span>
                    <span class="c1"># using a shared posterior)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">p_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">u_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_move_dists</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">,</span> <span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># Sample posteriors - note the helper function sets samples to None if there is no</span>
                    <span class="c1"># distribution over a parameter.  In this case, when we provide these None values</span>
                    <span class="c1"># to cond_forward() of the subject model, we indicate that the parameters in</span>
                    <span class="c1"># the subject model should be used.</span>
                    <span class="n">q_p_modes</span><span class="p">,</span> <span class="n">q_p_modes_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">p_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                            <span class="n">s_coll</span><span class="o">.</span><span class="n">p_props</span><span class="p">)</span>
                    <span class="n">q_u_modes</span><span class="p">,</span> <span class="n">q_u_modes_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">u_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                            <span class="n">s_coll</span><span class="o">.</span><span class="n">u_props</span><span class="p">)</span>
                    <span class="n">q_psi_vls</span><span class="p">,</span> <span class="n">q_psi_vls_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                            <span class="n">s_coll</span><span class="o">.</span><span class="n">psi_props</span><span class="p">,</span> <span class="n">squeeze_std_smp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">q_scale_vls</span><span class="p">,</span> <span class="n">q_scale_vls_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                                <span class="n">s_coll</span><span class="o">.</span><span class="n">scale_props</span><span class="p">,</span>
                                                                                <span class="n">squeeze_std_smp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">q_offset_vls</span><span class="p">,</span> <span class="n">q_offset_vls_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span><span class="n">s_coll</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                                  <span class="n">s_coll</span><span class="o">.</span><span class="n">offset_props</span><span class="p">,</span>
                                                                                  <span class="n">squeeze_std_smp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                    <span class="n">q_direct_mapping_vls</span><span class="p">,</span> <span class="n">q_direct_mapping_vls_standard</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sample_posteriors</span><span class="p">(</span>
                            <span class="n">s_coll</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">direct_mapping_props</span><span class="p">,</span>
                            <span class="n">squeeze_std_smp</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                    <span class="c1"># Make sure the m module is on the correct device for this subject, this is</span>
                    <span class="c1"># important when subject models share an m function</span>
                    <span class="n">s_coll</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">subject_coll_devices</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

                    <span class="c1"># Apply input modules</span>
                    <span class="n">batch_x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_g</span> <span class="k">if</span> <span class="n">i_m</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">i_m</span><span class="p">(</span><span class="n">x_g</span><span class="p">)</span> <span class="k">for</span> <span class="n">i_m</span><span class="p">,</span> <span class="n">x_g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">)]</span>

                    <span class="c1"># Calculate the conditional log-likelihood for this subject</span>
                    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">cond_forward</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">q_p_modes_standard</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">q_u_modes_standard</span><span class="p">,</span>
                                                       <span class="n">scales</span><span class="o">=</span><span class="n">q_scale_vls_standard</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">q_offset_vls_standard</span><span class="p">,</span>
                                                       <span class="n">direct_mappings</span><span class="o">=</span><span class="n">q_direct_mapping_vls_standard</span><span class="p">)</span>
                    <span class="n">nll</span> <span class="o">=</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">n_smp_data_points</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">/</span><span class="n">n_batch_data_pts</span><span class="p">)</span><span class="o">*</span><span class="n">s_coll</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">neg_ll</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">batch_y</span><span class="p">,</span> <span class="n">mn</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
                                                                                             <span class="n">psi</span><span class="o">=</span><span class="n">q_psi_vls_standard</span><span class="p">)</span>
                    <span class="n">nll</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">nll</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="n">batch_nll</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">nll</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

                    <span class="c1"># Calculate KL divergences between posteriors and priors</span>
                    <span class="k">if</span> <span class="n">enforce_priors</span><span class="p">:</span>
                        <span class="n">s_p_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">p_dists</span><span class="p">,</span>
                                                                <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">p_dists</span><span class="p">,</span>
                                                                <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">p_props</span><span class="p">,</span>
                                                                <span class="n">smps</span><span class="o">=</span><span class="n">q_p_modes</span><span class="p">)</span>
                        <span class="n">batch_sub_p_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_p_kl_log</span>

                        <span class="n">s_u_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">u_dists</span><span class="p">,</span>
                                                                <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">u_dists</span><span class="p">,</span>
                                                                <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">u_props</span><span class="p">,</span>
                                                                <span class="n">smps</span><span class="o">=</span><span class="n">q_u_modes</span><span class="p">)</span>
                        <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">s_u_kl_log</span>
                        <span class="n">batch_sub_u_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_u_kl_log</span>

                        <span class="n">s_psi_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">,</span>
                                                                  <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">,</span>
                                                                  <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">psi_props</span><span class="p">,</span>
                                                                  <span class="n">smps</span><span class="o">=</span><span class="n">q_psi_vls</span><span class="p">)</span>
                        <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">s_psi_kl_log</span>
                        <span class="n">batch_sub_psi_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_psi_kl_log</span>

                        <span class="n">s_scales_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">,</span>
                                                                     <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">,</span>
                                                                     <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">scale_props</span><span class="p">,</span>
                                                                     <span class="n">smps</span><span class="o">=</span><span class="n">q_scale_vls</span><span class="p">)</span>
                        <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">s_scales_kl_log</span>
                        <span class="n">batch_sub_scales_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_scales_kl_log</span>

                        <span class="n">s_offsets_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">,</span>
                                                                      <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">,</span>
                                                                      <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">offset_props</span><span class="p">,</span>
                                                                      <span class="n">smps</span><span class="o">=</span><span class="n">q_offset_vls</span><span class="p">)</span>
                        <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">s_offsets_kl_log</span>
                        <span class="n">batch_sub_offsets_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_offsets_kl_log</span>

                        <span class="n">s_direct_mappings_kl_log</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">,</span>
                                                                    <span class="n">dists1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">,</span>
                                                                    <span class="n">props</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                                                    <span class="n">prop_inds</span><span class="o">=</span><span class="n">s_coll</span><span class="o">.</span><span class="n">direct_mapping_props</span><span class="p">,</span>
                                                                    <span class="n">smps</span><span class="o">=</span><span class="n">q_offset_vls</span><span class="p">)</span>
                        <span class="n">batch_obj_log</span> <span class="o">+=</span> <span class="n">s_direct_mappings_kl_log</span>
                        <span class="n">batch_sub_direct_mappings_kl</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_direct_mappings_kl_log</span>

                <span class="c1"># Apply penalizers</span>
                <span class="k">for</span> <span class="n">pen_i</span><span class="p">,</span> <span class="n">penalizer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">):</span>
                    <span class="n">batch_penalizer_penalties</span><span class="p">[</span><span class="n">pen_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">penalizer</span><span class="o">.</span><span class="n">penalize_and_backwards</span><span class="p">()</span>

                <span class="c1"># Take a gradient step</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># Make sure no private variance values are too small if we are fitting variances with point estimates</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">s_j</span> <span class="ow">in</span> <span class="n">s_inds</span><span class="p">:</span>
                        <span class="n">s_coll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">[</span><span class="n">s_j</span><span class="p">]</span>
                        <span class="n">s_min_var</span> <span class="o">=</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">min_var</span>
                        <span class="n">s_mdl</span> <span class="o">=</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">s_mdl</span>
                        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">n_output_groups</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">s_coll</span><span class="o">.</span><span class="n">psi_dists</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                                <span class="n">small_psi_inds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">psi</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">s_min_var</span><span class="p">[</span><span class="n">h</span><span class="p">])</span>
                                <span class="n">s_mdl</span><span class="o">.</span><span class="n">psi</span><span class="p">[</span><span class="n">h</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">small_psi_inds</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_min_var</span><span class="p">[</span><span class="n">h</span><span class="p">]</span>

            <span class="c1"># Handle checkpoints if needed</span>
            <span class="k">if</span> <span class="n">cp_epochs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">cp_epochs</span> <span class="o">==</span> <span class="n">e_i</span><span class="p">):</span>
                    <span class="c1"># Clear the batch data from memory - this is helpful when working with GPU</span>
                    <span class="k">del</span> <span class="n">batch_x</span>
                    <span class="k">del</span> <span class="n">batch_y</span>
                    <span class="k">del</span> <span class="n">batch_data</span>

                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Creating checkpoint after epoch &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e_i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
                    <span class="n">cp_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">cp_epochs</span> <span class="o">==</span> <span class="n">e_i</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">check_points</span><span class="p">[</span><span class="n">cp_ind</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_check_point</span><span class="p">(</span><span class="n">inc_penalizers</span><span class="o">=</span><span class="n">cp_penalizers</span><span class="p">)</span>
                    <span class="n">check_points</span><span class="p">[</span><span class="n">cp_ind</span><span class="p">][</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">e_i</span>

            <span class="c1"># Take care of logging everything</span>
            <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span>
            <span class="n">epoch_elapsed_time</span><span class="p">[</span><span class="n">e_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed_time</span>
            <span class="n">epoch_nll</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_nll</span>
            <span class="n">epoch_sub_p_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_p_kl</span>
            <span class="n">epoch_sub_u_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_u_kl</span>
            <span class="n">epoch_sub_psi_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_psi_kl</span>
            <span class="n">epoch_sub_scales_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_scales_kl</span>
            <span class="n">epoch_sub_offsets_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_offsets_kl</span>
            <span class="n">epoch_sub_direct_mappings_kl</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_sub_direct_mappings_kl</span>
            <span class="n">epoch_penalizer_penalties</span><span class="p">[</span><span class="n">e_i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">batch_penalizer_penalties</span>
            <span class="n">epoch_obj</span><span class="p">[</span><span class="n">e_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_obj_log</span>

            <span class="k">if</span> <span class="n">e_i</span> <span class="o">%</span> <span class="n">update_int</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_print_fitting_status</span><span class="p">(</span><span class="n">e_i</span><span class="o">=</span><span class="n">e_i</span><span class="p">,</span> <span class="n">elapsed_time</span><span class="o">=</span><span class="n">elapsed_time</span><span class="p">,</span> <span class="n">batch_obj</span><span class="o">=</span><span class="n">batch_obj_log</span><span class="p">,</span>
                                           <span class="n">cur_learning_rates</span><span class="o">=</span><span class="n">cur_learning_rates</span><span class="p">,</span> <span class="n">s_inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">,</span> <span class="n">batch_nll</span><span class="o">=</span><span class="n">batch_nll</span><span class="p">,</span>
                                           <span class="n">batch_sub_p_kl</span><span class="o">=</span><span class="n">batch_sub_p_kl</span><span class="p">,</span> <span class="n">batch_sub_u_kl</span><span class="o">=</span><span class="n">batch_sub_u_kl</span><span class="p">,</span>
                                           <span class="n">batch_sub_psi_kl</span><span class="o">=</span><span class="n">batch_sub_psi_kl</span><span class="p">,</span> <span class="n">batch_sub_scales_kl</span><span class="o">=</span><span class="n">batch_sub_scales_kl</span><span class="p">,</span>
                                           <span class="n">batch_sub_offsets_kl</span><span class="o">=</span><span class="n">batch_sub_offsets_kl</span><span class="p">,</span>
                                           <span class="n">batch_sub_direct_mappings_kl</span><span class="o">=</span><span class="n">batch_sub_direct_mappings_kl</span><span class="p">,</span>
                                           <span class="n">batch_penalties</span><span class="o">=</span><span class="n">batch_penalizer_penalties</span><span class="p">,</span>
                                           <span class="n">devices</span><span class="o">=</span><span class="n">all_devices</span><span class="p">,</span> <span class="n">penalizers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">,</span> <span class="n">print_opts</span><span class="o">=</span><span class="n">print_opts</span><span class="p">)</span>

        <span class="c1"># Return logs and check points</span>
        <span class="k">if</span> <span class="n">check_points</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_points</span> <span class="o">=</span> <span class="p">[</span><span class="n">cp</span> <span class="k">for</span> <span class="n">cp</span> <span class="ow">in</span> <span class="n">check_points</span> <span class="k">if</span> <span class="n">cp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">log</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">:</span> <span class="n">epoch_elapsed_time</span><span class="p">,</span> <span class="s1">&#39;obj&#39;</span><span class="p">:</span> <span class="n">epoch_obj</span><span class="p">,</span> <span class="s1">&#39;mdl_nll&#39;</span><span class="p">:</span> <span class="n">epoch_nll</span><span class="p">,</span> <span class="s1">&#39;sub_p_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_p_kl</span><span class="p">,</span>
               <span class="s1">&#39;sub_u_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_u_kl</span><span class="p">,</span> <span class="s1">&#39;sub_psi_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_psi_kl</span><span class="p">,</span> <span class="s1">&#39;sub_scales_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_scales_kl</span><span class="p">,</span>
               <span class="s1">&#39;sub_offsets_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_offsets_kl</span><span class="p">,</span> <span class="s1">&#39;sub_direct_mappings_kl&#39;</span><span class="p">:</span> <span class="n">epoch_sub_direct_mappings_kl</span><span class="p">,</span>
               <span class="s1">&#39;penalties&#39;</span><span class="p">:</span> <span class="n">epoch_penalizer_penalties</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">log</span><span class="p">,</span> <span class="n">check_points</span><span class="p">]</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.plot_log"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.plot_log">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">plot_log</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">log</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">show_obj</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_mdl_nll</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_p_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">show_u_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_psi_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_scales_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">show_offsets_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_direct_mappings_kl</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">show_penalties</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Produces a figure of the values in a log produced by fit().</span>

<span class="sd">        Args:</span>
<span class="sd">            log: The log to plot.</span>
<span class="sd">            </span>
<span class="sd">            show_obj: True if the objective should be plotted through time</span>
<span class="sd">            </span>
<span class="sd">            show_mdl_nll: True if model negative log likelihood should be plotted through time</span>
<span class="sd">            </span>
<span class="sd">            show_p_kl: True if the kl divergences between prior and posterior distributions for p modes should be</span>
<span class="sd">                       plotted through time.</span>
<span class="sd">                         </span>
<span class="sd">            show_u_kl: True if the kl divergences between prior and posterior distributions for u modes should be</span>
<span class="sd">                       plotted through time. </span>
<span class="sd">            </span>
<span class="sd">            show_psi_kl: True if the kl divergences between prior and posterior distributions for psi parameters should</span>
<span class="sd">                         be plotted through time. </span>
<span class="sd">            </span>
<span class="sd">            show_scales_kl: True if the kl divergences between prior and posterior distributions for scale parameters </span>
<span class="sd">                            should be plotted through time. </span>
<span class="sd">            </span>
<span class="sd">            show_offsets_kl: True if the kl divergences between prior and posterior distributions for offset parameters </span>
<span class="sd">                             should be plotted through time.</span>

<span class="sd">            show_direct_mappings_kl: True if the kl divergences between prior and posterior distributions for </span>
<span class="sd">                                     direct mapping parameters should be plotted through time. </span>
<span class="sd">             </span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_plots</span> <span class="o">=</span> <span class="p">(</span><span class="n">show_obj</span> <span class="o">+</span> <span class="n">show_mdl_nll</span> <span class="o">+</span> <span class="n">show_p_kl</span> <span class="o">+</span> <span class="n">show_u_kl</span> <span class="o">+</span> <span class="n">show_psi_kl</span> <span class="o">+</span> <span class="n">show_scales_kl</span> <span class="o">+</span> <span class="n">show_offsets_kl</span> <span class="o">+</span>
                   <span class="n">show_direct_mappings_kl</span> <span class="o">+</span> <span class="n">show_penalties</span><span class="p">)</span>

        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">n_plots</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int&#39;</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

        <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">show_obj</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;obj&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Objective&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_mdl_nll</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;mdl_nll&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Model Negative Log Likelihoods&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_p_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_p_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject P KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_u_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_u_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject U KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_psi_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_psi_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject Psi KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_scales_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_scales_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject Scales KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_offsets_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_offsets_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject Offsets KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_direct_mappings_kl</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;sub_direct_mappings_kl&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Subject DMs KL&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">show_penalties</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">cnt</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;elapsed_time&#39;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s1">&#39;penalties&#39;</span><span class="p">])</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Penalties&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter.to"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter.to">[docs]</a>    <span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">distribute_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Move everything in the fitter to a specified device.</span>

<span class="sd">        This is most useful when wanting to clean up after fitting and you need to move models to CPU.</span>

<span class="sd">        Args:</span>
<span class="sd">            device: The device to move everything to (e.g., torch.device(&#39;cpu&#39;))</span>

<span class="sd">            distribute_data: True if data should be moved as well.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">s_coll</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">s_collections</span><span class="p">:</span>
            <span class="n">s_coll</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">distribute_data</span><span class="o">=</span><span class="n">distribute_data</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prior_collection</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_modules</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">penalizer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalizers</span><span class="p">:</span>
                <span class="n">penalizer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter._calc_kl_and_backward"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter._calc_kl_and_backward">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_calc_kl_and_backward</span><span class="p">(</span><span class="n">dists0</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                          <span class="n">dists1</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="kc">None</span><span class="p">]],</span>
                          <span class="n">props</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                          <span class="n">prop_inds</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span> <span class="kc">None</span><span class="p">],</span>
                          <span class="n">smps</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="kc">None</span><span class="p">]]):</span>
        <span class="sd">&quot;&quot;&quot; Helper function for computing KL divergence between posterior and prior distributions and calling backwards.</span>

<span class="sd">        This functions handles the case when distributions and/or properties are not provided.</span>

<span class="sd">        Args:</span>

<span class="sd">            dists0: Posterior distributions.  If a None value is provided in the list, this serves as a placeholder</span>
<span class="sd">            indicating no calculations should be done.</span>

<span class="sd">            dist1: Prior distributions.</span>

<span class="sd">            props: List of properties</span>

<span class="sd">            prop_inds: props_inds[i] is the index in props that dists0[i] and dists[1] i should be conditioned on.</span>

<span class="sd">            smps: smps[i] is a set of samples to use for computing kl divergence.  Can be None if the kl calculation</span>
<span class="sd">            for a distribution type is known analytically.</span>

<span class="sd">        Returns:</span>

<span class="sd">            kl: The computed kl divergence</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># If we have no distributions to worry about, this is easy</span>
        <span class="k">if</span> <span class="n">dists0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dists0</span><span class="p">):</span>
            <span class="k">return</span> <span class="mf">0.0</span>

        <span class="c1"># If we have at least one distribution, then we compute kl divergences</span>
        <span class="n">kl</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">d0</span><span class="p">,</span> <span class="n">d1</span><span class="p">,</span> <span class="n">prop_ind</span><span class="p">,</span> <span class="n">smp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">dists0</span><span class="p">,</span> <span class="n">dists1</span><span class="p">,</span> <span class="n">prop_inds</span><span class="p">,</span> <span class="n">smps</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">d0</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">prop_ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">dist_props</span> <span class="o">=</span> <span class="n">props</span><span class="p">[</span><span class="n">prop_ind</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">dist_props</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="n">kl</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">d0</span><span class="o">.</span><span class="n">kl</span><span class="p">(</span><span class="n">d_2</span><span class="o">=</span><span class="n">d1</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">dist_props</span><span class="p">,</span> <span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">))</span>

        <span class="n">kl</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">kl</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter._move_dists"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter._move_dists">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_move_dists</span><span class="p">(</span><span class="n">dists</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Moves distributions to a device, avoiding calling .to() on None entries in a list. &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dists</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dists</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">d</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter._print_fitting_status"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter._print_fitting_status">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_print_fitting_status</span><span class="p">(</span><span class="n">e_i</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">elapsed_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">batch_obj</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">cur_learning_rates</span><span class="p">,</span>
                              <span class="n">s_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">batch_nll</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">batch_sub_p_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                              <span class="n">batch_sub_u_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">batch_sub_psi_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                              <span class="n">batch_sub_scales_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">batch_sub_offsets_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                              <span class="n">batch_sub_direct_mappings_kl</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">batch_penalties</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
                              <span class="n">penalizers</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">ParameterPenalizer</span><span class="p">],</span> <span class="n">devices</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">],</span>
                              <span class="n">print_opts</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Helper function for printing updates on fitting process.</span>

<span class="sd">        Args:</span>
<span class="sd">            e_i: The epoch index</span>

<span class="sd">            elapsed_time: Elapsed fitting time</span>

<span class="sd">            batch_obj: The objective value for the a batch of data (This will typically be the last batch of data</span>
<span class="sd">            for the epoch)</span>

<span class="sd">            cur_learning_rates: The current learning rates</span>

<span class="sd">            s_inds: The indices of the subjects that are being fit</span>

<span class="sd">            batch_nll: The negative log-likelihoods for the batch for each fit subject model</span>
<span class="sd">            (should correspond to s_inds)</span>

<span class="sd">            batch_sub_p_kl: The kl divergences for the p-mode distributions for each subject for the batch.</span>

<span class="sd">            batch_sub_u_kl: The kl divergences for the u-mode distributions for each subject for the batch.</span>

<span class="sd">            batch_sub_psi_kl: The kl divergences for the psi parameter distributions for each subject for the batch.</span>

<span class="sd">            batch_sub_scales_kl: The kl divergences for the scale parameter distributions for each subject for the</span>
<span class="sd">            batch.</span>

<span class="sd">            batch_sub_offsets_kl: The kl divergences for the offset parameter distributions for each subject for the</span>
<span class="sd">            batch.</span>

<span class="sd">            batch_sub_direct_mappings_kl: The kl divergences for the direct mapping parameter distributions for each</span>
<span class="sd">            subject for the batch.</span>

<span class="sd">            batch_penalties: The penalties each penalizer produced for the batch.</span>

<span class="sd">            penalizers: The penalizers used in fitting.</span>

<span class="sd">            devices: List of devices to print memory stats for.</span>

<span class="sd">            print_opts: A dictionary with fields with boolean values indicating which information should be shown.</span>
<span class="sd">            The fields are: mdl_nll, sub_kls, penalties, memory_usage.  Any fields that are not provided will be</span>
<span class="sd">            assumed to be false.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_penalizers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_penalties</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_format_print_opts</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">f</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="n">d</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">_format_print_opts</span><span class="p">(</span><span class="n">print_opts</span><span class="p">,</span> <span class="s1">&#39;mdl_nll&#39;</span><span class="p">)</span>
        <span class="n">_format_print_opts</span><span class="p">(</span><span class="n">print_opts</span><span class="p">,</span> <span class="s1">&#39;sub_kls&#39;</span><span class="p">)</span>
        <span class="n">_format_print_opts</span><span class="p">(</span><span class="n">print_opts</span><span class="p">,</span> <span class="s1">&#39;memory_usage&#39;</span><span class="p">)</span>
        <span class="n">_format_print_opts</span><span class="p">(</span><span class="n">print_opts</span><span class="p">,</span> <span class="s1">&#39;penalties&#39;</span><span class="p">)</span>
        <span class="n">_format_print_opts</span><span class="p">(</span><span class="n">print_opts</span><span class="p">,</span> <span class="s1">&#39;penalizer_states&#39;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;*****************************************************&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e_i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; complete.  Obj: &#39;</span> <span class="o">+</span>
              <span class="s1">&#39;</span><span class="si">{:.2e}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">batch_obj</span><span class="p">))</span> <span class="o">+</span>
              <span class="s1">&#39;, LR: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cur_learning_rates</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">print_opts</span><span class="p">[</span><span class="s1">&#39;mdl_nll&#39;</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Model NLLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_nll</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">print_opts</span><span class="p">[</span><span class="s1">&#39;sub_kls&#39;</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj P KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_p_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj U KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_u_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj Psi KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_psi_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj Scale KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_scales_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj Offsets KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_offsets_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Subj Direct Mappings KLs: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;s_&#39;</span><span class="p">,</span>
                                     <span class="n">vls</span><span class="o">=</span><span class="n">batch_sub_direct_mappings_kl</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="n">s_inds</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">print_opts</span><span class="p">[</span><span class="s1">&#39;penalties&#39;</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Penalties: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;p_&#39;</span><span class="p">,</span> <span class="n">vls</span><span class="o">=</span><span class="n">batch_penalties</span><span class="p">,</span>
                                     <span class="n">inds</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_penalizers</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">print_opts</span><span class="p">[</span><span class="s1">&#39;penalizer_states&#39;</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">penalizer</span> <span class="ow">in</span> <span class="n">penalizers</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">penalizer</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">print_opts</span><span class="p">[</span><span class="s1">&#39;memory_usage&#39;</span><span class="p">]:</span>
            <span class="n">device_memory_allocated</span> <span class="o">=</span> <span class="n">torch_devices_memory_usage</span><span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;memory_allocated&#39;</span><span class="p">)</span>
            <span class="n">device_max_memory_allocated</span> <span class="o">=</span> <span class="n">torch_devices_memory_usage</span><span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s1">&#39;max_memory_allocated&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Device memory allocated: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;d_&#39;</span><span class="p">,</span>
                                     <span class="n">vls</span><span class="o">=</span><span class="n">device_memory_allocated</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">device_memory_allocated</span><span class="p">))))</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">format_output_list</span><span class="p">(</span><span class="n">base_str</span><span class="o">=</span><span class="s1">&#39;Device max memory allocated: &#39;</span><span class="p">,</span> <span class="n">it_str</span><span class="o">=</span><span class="s1">&#39;d_&#39;</span><span class="p">,</span>
                                     <span class="n">vls</span><span class="o">=</span><span class="n">device_max_memory_allocated</span><span class="p">,</span> <span class="n">inds</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">device_max_memory_allocated</span><span class="p">))))</span>

        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Elapsed time: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">))</span></div>

<div class="viewcode-block" id="MultiSubjectVIFitter._sample_posteriors"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.MultiSubjectVIFitter._sample_posteriors">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_sample_posteriors</span><span class="p">(</span><span class="n">dists</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">],</span> <span class="n">all_props</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">prop_inds</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                           <span class="n">squeeze_std_smp</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Samples posteriors, returning samples in compact and standard form.</span>

<span class="sd">        Args:</span>
<span class="sd">            dists: List of distributions to sample.  Entries can be None (allowing for placeholders)</span>

<span class="sd">            all_props: List of property tensors.</span>

<span class="sd">            prop_inds: prop_inds[i] contains is the index in all_props for dists[i].  If prop_inds[i] is None,</span>
<span class="sd">            then sampling is done without conditioning on properties.</span>

<span class="sd">        Returns:</span>

<span class="sd">            smps: smps[i] is the compact samples for dists[i].  If dists[i] was none, smps[i] will ne none.</span>

<span class="sd">            std_smps: std_smps[i] is smps[i] in standard form.  If dists[i] was none, std_smps[i] will be none.</span>

<span class="sd">            squeeze_std_sample: True if standard sample should be squeezed before returning.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dists</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="n">n_dists</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prop_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prop_inds</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_dists</span>

        <span class="n">smps</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_dists</span>
        <span class="n">std_smps</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_dists</span>

        <span class="k">for</span> <span class="n">d_i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">prop_inds</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">smps</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">all_props</span><span class="p">[</span><span class="n">prop_inds</span><span class="p">[</span><span class="n">d_i</span><span class="p">]])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">smps</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
                <span class="n">std_smps</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="n">smps</span><span class="p">[</span><span class="n">d_i</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">squeeze_std_smp</span><span class="p">:</span>
            <span class="n">std_smps</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">std_smps</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">smps</span><span class="p">,</span> <span class="n">std_smps</span></div></div>


<div class="viewcode-block" id="eval_fits"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.eval_fits">[docs]</a><span class="k">def</span> <span class="nf">eval_fits</span><span class="p">(</span><span class="n">s_collections</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">SubjectVICollection</span><span class="p">],</span>
              <span class="n">input_modules</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">],</span>
              <span class="n">data</span><span class="p">:</span> <span class="n">TimeSeriesBatch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
              <span class="n">metric</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_preds</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
              <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; Measures model fits on a given set of data.</span>

<span class="sd">    This function generates predictions for each model using the posterior means of modes. It then evaluates these</span>
<span class="sd">    predictions using negative log-likelihood by default but the user can specify other metrics for measuring</span>
<span class="sd">    prediction quality.</span>

<span class="sd">    Args:</span>
<span class="sd">        s_collections: A sequence of VI collections we want to evaluate.</span>

<span class="sd">        input_modules: A sequence of input modules, corresponding to the input modules that should be used</span>
<span class="sd">        to preprocess the input for each collection in s_collections.</span>

<span class="sd">        data: The data to use for evaluation</span>

<span class="sd">        batch_size: The number of samples to send to GPU at one time for evaluation; can be useful if working with</span>
<span class="sd">        low-memory GPUs.</span>

<span class="sd">        metric: A function which computes fit quality given the output of predict_with_truth</span>

<span class="sd">        return_preds: True if predictions should be returned</span>

<span class="sd">        sample: True if when forming model parameters, instead of using means of posteriors, samples from the</span>
<span class="sd">        posteriors should be used instead.</span>

<span class="sd">    Returns:</span>
<span class="sd">        metrics: metrics[i] is the fit quality for s_collections[i].  Note that if no metric is supplied, this will</span>
<span class="sd">        just be a list of negative log-likelihood values, but custom metric functions can return arbitrary objects.</span>

<span class="sd">        preds_with_truth: preds_with_truth[i] are the predictions for s_collections[i] produced with the function</span>
<span class="sd">        predict_with_turth. This will only be returned in return_preds is true.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Generate predictions</span>
    <span class="n">n_mdls</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_collections</span><span class="p">)</span>
    <span class="n">preds_with_truth</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_mdls</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_mdls</span>
    <span class="k">for</span> <span class="n">c_i</span><span class="p">,</span> <span class="p">(</span><span class="n">s_coll_i</span><span class="p">,</span> <span class="n">input_modules_i</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">s_collections</span><span class="p">,</span> <span class="n">input_modules</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">c_i</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Generating predictions for fit: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">c_i</span><span class="p">))</span>

        <span class="c1"># Make prediction</span>
        <span class="n">pred_i</span> <span class="o">=</span> <span class="n">predict_with_truth</span><span class="p">(</span><span class="n">s_collection</span><span class="o">=</span><span class="n">s_coll_i</span><span class="p">,</span> <span class="n">input_modules</span><span class="o">=</span><span class="n">input_modules_i</span><span class="p">,</span>
                                    <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">time_grp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                    <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>

        <span class="c1"># Evaluate fits</span>
        <span class="k">if</span> <span class="n">metric</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="s1">&#39;truth&#39;</span><span class="p">][</span><span class="n">h</span><span class="p">])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="s1">&#39;truth&#39;</span><span class="p">]))]</span>
            <span class="n">mn</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">][</span><span class="n">h</span><span class="p">])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_i</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]))]</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">s_coll_i</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">neg_ll</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">mn</span><span class="o">=</span><span class="n">mn</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
                <span class="n">metrics</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">pred_i</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_preds</span><span class="p">:</span>
            <span class="n">preds_with_truth</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_i</span>

    <span class="k">if</span> <span class="n">return_preds</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">metrics</span><span class="p">,</span> <span class="n">preds_with_truth</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">metrics</span></div>


<div class="viewcode-block" id="predict"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.predict">[docs]</a><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">s_collection</span><span class="p">:</span> <span class="n">SubjectVICollection</span><span class="p">,</span> <span class="n">input_modules</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span>
            <span class="n">data</span><span class="p">:</span> <span class="n">TimeSeriesBatch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot; Predicts output given input from a model with posterior distributions over parameters.</span>

<span class="sd">    If posterior distributions for a parameter are present, predictions are based on the posterior mean by</span>
<span class="sd">    default (but see sample input for using samples instead).  If posterior distributions for a parameter are not</span>
<span class="sd">    present, the parameter value in the subject model will be used.</span>

<span class="sd">    Note: All predictions will be returned on host (cpu) memory as numpy arrays.</span>

<span class="sd">    Args:</span>
<span class="sd">        s_collection: The collection for the subject.   Any data in the collection will be ignored.</span>

<span class="sd">        input_modules: Input modules for preprocessing data.</span>

<span class="sd">        data: The data to predict with.</span>

<span class="sd">        batch_size: The number of samples we predict on at a time.  This is helpful if using a GPU</span>
<span class="sd">        with limited memory.</span>

<span class="sd">        sample: If true, instead of using posterior means for model parameters when forming predictions,</span>
<span class="sd">        the posteriors will be sampled and these samples will be used for model parameters.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pred_mn: The predicted means given the input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_total_smps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n_batches</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">n_total_smps</span><span class="p">)</span><span class="o">/</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="c1"># Define a helper function</span>
    <span class="k">def</span> <span class="nf">_get_post_vls</span><span class="p">(</span><span class="n">dists</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">],</span> <span class="n">all_props</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">prop_inds</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                        <span class="n">squeeze_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Gets the posterior means (or samples the posteriors) for a list of distributions, handling cases where some</span>
<span class="sd">        distributions are None.</span>

<span class="sd">        Args:</span>
<span class="sd">            dists: The distributions to get posterior means for.  Can be None, in which case this function returns None.</span>

<span class="sd">            all_props: List of properties.</span>

<span class="sd">            prop_inds: prop_inds[i] is the index into all_props for the properties for dists[i].  If no properties</span>
<span class="sd">            are needed for the distribution prop_inds[i] should be None.  If no properties are needed for all</span>
<span class="sd">            of the distributions, prop_inds can be None.</span>

<span class="sd">            squeeze_output: True if output should be squeezed.</span>

<span class="sd">            sample: If true, posteriors will be sampled instead of using their means</span>

<span class="sd">        Returns:</span>

<span class="sd">            mns: The means of distributions.  mns[i] is the mean for distribution i and will be None if dists[i] was</span>
<span class="sd">            None.  mns will be None if dists was None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">dists</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="n">n_dists</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">prop_inds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prop_inds</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_dists</span>

        <span class="n">vls</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_dists</span>
        <span class="k">for</span> <span class="n">d_i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dists</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">prop_inds</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
                        <span class="n">vls</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">all_props</span><span class="p">[</span><span class="n">prop_inds</span><span class="p">[</span><span class="n">d_i</span><span class="p">]]))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">vls</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">all_props</span><span class="p">[</span><span class="n">prop_inds</span><span class="p">[</span><span class="n">d_i</span><span class="p">]])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">sample</span><span class="p">:</span>
                        <span class="n">vls</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">vls</span><span class="p">[</span><span class="n">d_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">d</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">squeeze_output</span><span class="p">:</span>
            <span class="n">vls</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vls</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">vls</span>

    <span class="c1"># Get the parameters</span>

    <span class="n">p</span> <span class="o">=</span> <span class="n">_get_post_vls</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">p_dists</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">p_props</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">_get_post_vls</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">u_dists</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">u_props</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">scales</span> <span class="o">=</span> <span class="n">_get_post_vls</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">scale_dists</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">scale_props</span><span class="p">,</span>
                           <span class="n">squeeze_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">_get_post_vls</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">offset_dists</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">props</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">offset_props</span><span class="p">,</span>
                            <span class="n">squeeze_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">direct_mappings</span> <span class="o">=</span> <span class="n">_get_post_vls</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">direct_mapping_dists</span><span class="p">,</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">props</span><span class="p">,</span>
                                    <span class="n">s_collection</span><span class="o">.</span><span class="n">direct_mapping_props</span><span class="p">,</span> <span class="n">squeeze_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                    <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>

    <span class="n">s_collection_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">s_collection</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

    <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_batches</span>
    <span class="n">batch_start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">b_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_batches</span><span class="p">):</span>
        <span class="n">batch_end</span> <span class="o">=</span> <span class="n">batch_start</span> <span class="o">+</span> <span class="n">batch_size</span>
        <span class="n">batch_data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">batch_start</span><span class="p">:</span><span class="n">batch_end</span><span class="p">]</span>

        <span class="c1"># Move data to device the collection is on</span>
        <span class="n">batch_data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">s_collection_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="n">s_collection_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

        <span class="c1"># Form x</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">i_g</span><span class="p">][</span><span class="n">batch_data</span><span class="o">.</span><span class="n">i_x</span><span class="p">]</span> <span class="k">for</span> <span class="n">i_g</span> <span class="ow">in</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">input_grps</span><span class="p">]</span>

        <span class="c1"># Apply input modules</span>
        <span class="n">batch_x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_g</span> <span class="k">if</span> <span class="n">i_m</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">i_m</span><span class="p">(</span><span class="n">x_g</span><span class="p">)</span> <span class="k">for</span> <span class="n">i_m</span><span class="p">,</span> <span class="n">x_g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_modules</span><span class="p">,</span> <span class="n">batch_x</span><span class="p">)]</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">batch_y</span> <span class="o">=</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">s_mdl</span><span class="o">.</span><span class="n">cond_forward</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">u</span><span class="p">,</span> <span class="n">scales</span><span class="o">=</span><span class="n">scales</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
                                                      <span class="n">direct_mappings</span><span class="o">=</span><span class="n">direct_mappings</span><span class="p">)</span>
        <span class="n">batch_y</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">batch_y</span><span class="p">]</span>
        <span class="n">y</span><span class="p">[</span><span class="n">b_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_y</span>

        <span class="n">batch_start</span> <span class="o">=</span> <span class="n">batch_end</span>

    <span class="c1"># Concatenate output</span>
    <span class="n">n_output_grps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">y_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_output_grps</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_output_grps</span><span class="p">):</span>
        <span class="n">y_out</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">batch_y</span><span class="p">[</span><span class="n">h</span><span class="p">]</span> <span class="k">for</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">y_out</span></div>


<div class="viewcode-block" id="predict_with_truth"><a class="viewcode-back" href="../../../../autoapi/janelia_core/ml/latent_regression/vi/index.html#janelia_core.ml.latent_regression.vi.predict_with_truth">[docs]</a><span class="k">def</span> <span class="nf">predict_with_truth</span><span class="p">(</span><span class="n">s_collection</span><span class="p">:</span> <span class="n">SubjectVICollection</span><span class="p">,</span> <span class="n">input_modules</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span>
                       <span class="n">data</span><span class="p">:</span> <span class="n">TimeSeriesBatch</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
                       <span class="n">time_grp</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Predicts output for a model, using posterior over modes, and including true data in output for reference.</span>

<span class="sd">    This is a wrapper function around predict for convenience.</span>

<span class="sd">    Note: All predictions will be returned on host (cpu) memory as numpy arrays.</span>

<span class="sd">    Args:</span>
<span class="sd">        s_collection: The collection for the subject.   Any data in the collection will be ignored.</span>

<span class="sd">        input_modules: Input modules for preprocessing input.</span>

<span class="sd">        data: The data to predict with.</span>

<span class="sd">        batch_size: The number of samples we predict on at a time.  This is helpful if using a GPU</span>
<span class="sd">        with limited memory.</span>

<span class="sd">        time_grp: The index of the group in data with time stamps.  If None, no time stamps will be returned.</span>

<span class="sd">        sample: True if instead of using posterior means for model parameters when making predictions, samples from</span>
<span class="sd">        each distribution should be used instead.</span>

<span class="sd">    Returns:</span>

<span class="sd">        predictions: A dictionary with the following keys:</span>
<span class="sd">            pred: predictions. pred[h] is the prediction for the h^th output group of the model</span>
<span class="sd">            truth: Corresponding true values for those in pred</span>
<span class="sd">            time: It time_grp is not None, the time indices for each point in pred and truth. Otherwise, time will be</span>
<span class="sd">            None.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">output_grps</span> <span class="o">=</span> <span class="n">s_collection</span><span class="o">.</span><span class="n">output_grps</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">s_collection</span><span class="o">=</span><span class="n">s_collection</span><span class="p">,</span> <span class="n">input_modules</span><span class="o">=</span><span class="n">input_modules</span><span class="p">,</span>
                   <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">truth</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">h</span><span class="p">][</span><span class="n">data</span><span class="o">.</span><span class="n">i_y</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">output_grps</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">time_grp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">time_grp</span><span class="p">][</span><span class="n">data</span><span class="o">.</span><span class="n">i_y</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">time</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;pred&#39;</span><span class="p">:</span> <span class="n">pred</span><span class="p">,</span> <span class="s1">&#39;truth&#39;</span><span class="p">:</span> <span class="n">truth</span><span class="p">,</span> <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="n">time</span><span class="p">}</span></div>


</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, William Bishop.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>