<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>janelia_core.ml.torch_distributions &mdash; janelia_core 1.0 documentation</title><link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> janelia_core
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Setting up the core library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html#dependencies">Dependencies</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../autoapi/janelia_core/index.html">janelia_core</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">janelia_core</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>janelia_core.ml.torch_distributions</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for janelia_core.ml.torch_distributions</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot; Torch modules and tools for working with distributions.</span>

<span class="sd">The distribution objects defined here are *not* subclasses of torch.distributions.  There are a couple of</span>
<span class="sd">innovations over standard Pytorch distributions:</span>

<span class="sd">    1) Samples are returned in compact notation.  This is convenient when sampling structured data and enables</span>
<span class="sd">    efficient representation of sparse samples.  Each distribution also has its own methods for converting between</span>
<span class="sd">    compact and standard data representations.</span>

<span class="sd">    2) The distributions here naturally accomodate conditioning data.  See the base class CondVAEDistribution for</span>
<span class="sd">    more details.</span>

<span class="sd">In addition to holding distribution objects, this module also holds distribution penalizers.  See the base class</span>
<span class="sd">DistributionPenalizer for more information.</span>

<span class="sd"> &quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Sequence</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">janelia_core.math.basic_functions</span> <span class="kn">import</span> <span class="n">list_grid_pts</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_functions</span> <span class="kn">import</span> <span class="n">log_cosh</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">FixedOffsetExp</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">IndSmpConstantBoundedFcn</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">IndSmpConstantRealFcn</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">SCC</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">SumAlongDim</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">SumOfTiledHyperCubeBasisFcns</span>
<span class="kn">from</span> <span class="nn">janelia_core.ml.extra_torch_modules</span> <span class="kn">import</span> <span class="n">Tanh</span>


<div class="viewcode-block" id="CondVAEDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondVAEDistribution</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; CondVAEDistribution is a base class for conditional distributions used by VAEs.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a CondVAEDistribution object. &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="CondVAEDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes the conditional mean of the distribution at different samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: A tensor of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i, :] is the mean conditioned on x[i, :]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from a conditional distribution.</span>

<span class="sd">        When possible, samples should be generated from a reparameterized distribution.</span>

<span class="sd">        Returned samples may be represented by a set of compact parameters.  See form_standard_sample() on how to</span>
<span class="sd">        transform this compact representation into a standard representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            smp: The sample. The returned value of samples can be quite flexible.  It could be a tensor of shape n_smps,</span>
<span class="sd">            with each entry representing a sample or it could be another object with attributes which specify the values</span>
<span class="sd">            of the sample.  For example, if sampling from a spike and slab parameter, the returned value could be a list</span>
<span class="sd">            with one entry specifying the number of sample, another containing a tensor specifying non-zero samples and</span>
<span class="sd">            another tensor specifying the values of the non-zero samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a standard representation of a sample from the output of sample.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: Compact representation of a sample.</span>

<span class="sd">        Returns:</span>
<span class="sd">            formed_smp: A tensor of shape n_smps*d_y.  formed_smp[i,:] is the i^th sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a compact representation of a sample given a standard representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: The standard representation of the sample of shape n_smps</span>

<span class="sd">        Returns:</span>
<span class="sd">            formed_smp: The compact representation of the sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.sample_to"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.sample_to">[docs]</a>    <span class="k">def</span> <span class="nf">sample_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Moves a sample in compact form to a given device.</span>

<span class="sd">        This function is provided because different distributions may return samples in arbitrary objects,</span>
<span class="sd">        so a custom function may be needed to move a sample to a device.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: The sample to move.</span>

<span class="sd">            device: The device to move the sample to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span><span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondVAEDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes the conditional log probability of individual samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x</span>

<span class="sd">            y: Compact representation of the samples we desire the probability for.  Compact representation means the</span>
<span class="sd">            form of a sample as output by the sample() function.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Conditional log probability of each sample. Of shape n_smps.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.kl"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes the KL divergence between this object and another of the same type conditioned on input.</span>

<span class="sd">        Specifically computes:</span>

<span class="sd">            KL(p_1(y_i|x_i), p_2(y_i|x_i)),</span>

<span class="sd">        where p_1(y_i | x_i) represents the conditional distributions for each sample.  Here, p_1 is the conditional</span>
<span class="sd">        distribution represented by this object and p_2 is the distribution represented by another object of the same</span>
<span class="sd">        type.</span>

<span class="sd">        Note: This function will move the conditioning data (x) and the sample (smp) to the appropriate device(s)</span>
<span class="sd">        so calculations can be carried out without needing to move this object or the other conditional</span>
<span class="sd">        distribution between devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_2: The other conditional distribution in the KL divergence.</span>

<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">            smp: A set of samples in compact form. Sample i should be drawn from p(y_i|x[i,:]). This is an optional</span>
<span class="sd">            input that is provided because sometimes it may not be possible to compute the KL divergence</span>
<span class="sd">            between two distributions analytically.  In these cases, an object may still implement the kl method</span>
<span class="sd">            by computing an empirical estimate of the kl divergence as log p_1(y_i&#39;|x_i) - log p_2(y_i&#39;| x_i),</span>
<span class="sd">            where y_i&#39; is drawn from p_1(y_i|x_i). This is the base behavior of this method.  Objects for which kl</span>
<span class="sd">            can be computed analytically should override this method.</span>

<span class="sd">            return_device: The device the calculated kl tensor should be returned to.  If None, this will</span>
<span class="sd">            be the device the first parameter of this object is on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            kl: Of shape n_smps.  kl[i] is the KL divergence between the two distributions for the i^th conditioning</span>
<span class="sd">            input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">self_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">d_2_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

        <span class="k">if</span> <span class="n">return_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_device</span> <span class="o">=</span> <span class="n">self_device</span>

        <span class="n">smp_self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_to</span><span class="p">(</span><span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">self_device</span><span class="p">)</span>
        <span class="n">x_self</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">self_device</span><span class="p">)</span>
        <span class="n">smp_d_2</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">sample_to</span><span class="p">(</span><span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">d_2_device</span><span class="p">)</span>
        <span class="n">x_d_2</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">d_2_device</span><span class="p">)</span>

        <span class="n">kl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_self</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">smp_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span> <span class="o">-</span> <span class="n">d_2</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_d_2</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">smp_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">kl</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>

<div class="viewcode-block" id="CondVAEDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        In particular this returns the list of parameters for which gradients can be estimated with the</span>
<span class="sd">        reparaterization trick when the distribution serves as q when optimizing KL(q, p).</span>

<span class="sd">        If no parameters can be estimated in this way, it should return an empty list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            l: the list of parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div>

<div class="viewcode-block" id="CondVAEDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondVAEDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span><span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters which should be estimated with a score method based gradient.</span>

<span class="sd">        In particular this returns the list of parameters for which gradients can be estimated with the</span>
<span class="sd">        score function based gradient when the distribution serves as q when optimizing KL(q, p).</span>

<span class="sd">        If no parameters can be estimated in this way, should return an empty list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            l: the list of parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span></div></div>


<div class="viewcode-block" id="CondFoldedNormalDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondFoldedNormalDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A multivariate conditional folded normal distribution.</span>

<span class="sd">    A folder normal distribution is the distribution on the random variable, Y = abs(Z), when Z is</span>
<span class="sd">    distributed N(\mu, \sigma^2). This object represents a conditional distribution over a set of random</span>
<span class="sd">    variables, each of which is independent and distributed according to a Folded Normal, conditioned on X.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu_f</span><span class="p">,</span> <span class="n">sigma_f</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new CondFoldedNormalDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            mu_f: A module whose forward function accepts input of size n_smps*d_x and outputs a vector of mu</span>
<span class="sd">            parameters for size n_smps*d_y</span>

<span class="sd">            sigma_f: A module whose forward function accepts input of size n_smps*d_x and outputs a vector of</span>
<span class="sd">            standard deviations for each sample of size n_smps*d_y</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mu_f</span> <span class="o">=</span> <span class="n">mu_f</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_f</span> <span class="o">=</span> <span class="n">sigma_f</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;log_constants&#39;</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.0</span><span class="p">))</span> <span class="o">-</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;sqrt_2_over_pi&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)))</span>

<div class="viewcode-block" id="CondFoldedNormalDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a sample in standard form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Converts sample in standard form to compact form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional mean given samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: data samples are conditioned on. Of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i,:] is the mean conditioned on x[i,:]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">(</span><span class="n">sigma</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">sqrt_2_over_pi</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">mu</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">+</span>
                <span class="n">mu</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">(</span><span class="n">mu</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))))</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes log P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x</span>

<span class="sd">            y: Values we desire the log probability for.  Of shape n_smps*d_y.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Log-likelihood of each sample. Of shape n_smps.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">sigma_sq</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_constants</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">mu</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma_sq</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_cosh</span><span class="p">(</span><span class="n">mu</span><span class="o">*</span><span class="n">y</span><span class="o">/</span><span class="n">sigma_sq</span><span class="p">),</span>
                         <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from the reparameterized form of P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_mps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            y: sampled data of shape n_smps*d_y.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mn</span> <span class="o">+</span> <span class="n">z</span><span class="o">*</span><span class="n">std</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.sample_to"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.sample_to">[docs]</a>    <span class="k">def</span> <span class="nf">sample_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Moves a sample to a specified device.</span>

<span class="sd">        See function of parent object for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span></div>

<div class="viewcode-block" id="CondFoldedNormalDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondFoldedNormalDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="CondBernoulliDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondBernoulliDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A module for working with conditional Bernoulli distributions.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_prob_fcn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a BernoulliCondDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            log_prob_fcn: A function which accepts input of shape n_smps*d_x and outputs a tensor of shape n_smps with</span>
<span class="sd">            the log probability that each sample is 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_fcn</span> <span class="o">=</span> <span class="n">log_prob_fcn</span>

<div class="viewcode-block" id="CondBernoulliDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional mean given samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: data samples are conditioned on. Of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i] is the mean conditioned on x[i,:]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">nz_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob_fcn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">nz_prob</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes log P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape nSmps*d_x.</span>

<span class="sd">            y: Compact representation (a tensor of type byte) of the sample.</span>

<span class="sd">        Returns:</span>
<span class="sd">            log_prob: the log probability of each sample</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If y is not a 1-d tensor.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;y must be a 1 dimensional tensor.&#39;</span><span class="p">))</span>

        <span class="n">n_smps</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">zero_inds</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">0</span>

        <span class="n">log_nz_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_prob_fcn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_smps</span><span class="p">)</span>
        <span class="n">log_prob</span><span class="p">[</span><span class="o">~</span><span class="n">zero_inds</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_nz_prob</span><span class="p">[</span><span class="o">~</span><span class="n">zero_inds</span><span class="p">]</span>
        <span class="n">log_prob</span><span class="p">[</span><span class="n">zero_inds</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_nz_prob</span><span class="p">[</span><span class="n">zero_inds</span><span class="p">]))</span>

        <span class="k">return</span> <span class="n">log_prob</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from P(y|x)</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape nSmps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            smp: smp[i] is the value of the i^th sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_prob_fcn</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">bern_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bern_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">byte</span><span class="p">()</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Converts between compact and standard sample form.</span>

<span class="sd">        See method of parent for more information. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Converts sample in standard form to compact form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span>  <span class="n">smp</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with the reparamaterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">()</span></div>

<div class="viewcode-block" id="CondBernoulliDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondBernoulliDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters that can be optimized with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span></div></div>


<div class="viewcode-block" id="CondGammaDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondGammaDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A distribution over a set of conditionally independent Gamma random variables.</span>

<span class="sd">    We use the convention of parameterizing a Gamma distribution with concentration (also refered to as shape) and</span>
<span class="sd">    rate parameters.</span>

<span class="sd">    Much of the implementation here has been taken from torch&#39;s own Gamma distribution.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">conc_f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">rate_f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a CondGammaDistribution object.</span>

<span class="sd">        conc_f: A module whose forward function accepts input of size n_smps*d_x and outputs concentration values in</span>
<span class="sd">        a tensor of size n_smps*d_y</span>

<span class="sd">        rate_f: A module whose forward function accepts input of size n_smps*d_x and outputs rate values in</span>
<span class="sd">        a tensor of size n_smps*d_y</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span> <span class="o">=</span> <span class="n">conc_f</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span> <span class="o">=</span> <span class="n">rate_f</span>

<div class="viewcode-block" id="CondGammaDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Converts between compact and standard sample form.</span>

<span class="sd">        See method of parent for more information. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondGammaDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a sample in standard form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondGammaDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional mean given samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: data samples are conditioned on. Of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i,:] is the mean conditioned on x[i,:]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGammaDistribution.kl"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes the KL divergence between the conditional distribution represented by this object and another.</span>

<span class="sd">        KL divergence is computed based on the closed form formula for KL divergence between two Gamma distributions.</span>

<span class="sd">        Note: This function will move the conditioning data (x) to the appropriate device(s)</span>
<span class="sd">            so calculations can be carried out without needing to move this object or the other conditional</span>
<span class="sd">            distribution between devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_2: The other conditional distribution in the KL divergence.</span>

<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">            smp: This input is ignored, as KL divergence is based on a closed form formula.</span>

<span class="sd">            return_device: The device the calculated kl tensor should be returned to.  If None, this will</span>
<span class="sd">            be the device the first parameter of this object is on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            kl: Of shape n_smps.  kl[i] is the KL divergence between the two distributions for the i^th conditioing</span>
<span class="sd">            input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">self_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">d_2_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

        <span class="n">x_self</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">self_device</span><span class="p">)</span>
        <span class="n">x_d_2</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d_2_device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_device</span> <span class="o">=</span> <span class="n">self_device</span>

        <span class="n">self_conc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
        <span class="n">d_2_conc</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>

        <span class="n">self_rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
        <span class="n">d_2_rate</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">self_conc</span> <span class="o">-</span> <span class="n">d_2_conc</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">digamma</span><span class="p">(</span><span class="n">self_conc</span><span class="p">)</span>
                         <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">self_conc</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">d_2_conc</span><span class="p">)</span>
                         <span class="o">+</span> <span class="n">d_2_conc</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">self_rate</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">d_2_rate</span><span class="p">))</span>
                         <span class="o">+</span> <span class="n">self_conc</span> <span class="o">*</span> <span class="p">((</span><span class="n">d_2_rate</span> <span class="o">-</span> <span class="n">self_rate</span><span class="p">)</span> <span class="o">/</span> <span class="n">self_rate</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGammaDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes log P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x</span>

<span class="sd">            y: Values we desire the log probability for.  Of shape n_smps*d_y.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Log-likelihood of each sample. Of shape n_smps.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">concentration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">rate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">concentration</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span> <span class="o">+</span>
                         <span class="p">(</span><span class="n">concentration</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span>
                         <span class="n">rate</span> <span class="o">*</span> <span class="n">y</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">concentration</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGammaDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from the reparameterized form of P(y|x).</span>

<span class="sd">          If a sample without gradients is desired, wrap the call to sample in torch.no_grad().</span>

<span class="sd">          Args:</span>
<span class="sd">              x: Data we condition on.  Of shape n_smps*d_x.</span>

<span class="sd">          Returns:</span>
<span class="sd">              y: sampled data of shape n_smps*d_y.</span>
<span class="sd">          &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">_standard_gamma</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGammaDistribution.std"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.std">[docs]</a>    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional standard deviation.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Conditioning data.  Of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">             std: Standard deviation.  Of shape n_smps*d_y.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span></div>

<div class="viewcode-block" id="CondGammaDistribution.mode"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.mode">[docs]</a>    <span class="k">def</span> <span class="nf">mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Conditioning data.  Of shape n_smps*d_x</span>

<span class="sd">        Returns:</span>
<span class="sd">            mode: Mode: Of shape n_smps*d_y.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conc_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rate_f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></div>

<div class="viewcode-block" id="CondGammaDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span></div>

<div class="viewcode-block" id="CondGammaDistribution.sample_to"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.sample_to">[docs]</a>    <span class="k">def</span> <span class="nf">sample_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Moves a sample in compact form to a given device.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGammaDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGammaDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="CondGaussianDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondGaussianDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents a multivariate distribution over a set of conditionally independent Gaussian random variables.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mn_f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">std_f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a CondGaussianDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            mn_f: A module whose forward function accepts input of size n_smps*d_x and outputs a mean for each sample in</span>
<span class="sd">            a tensor of size n_smps*d_y</span>

<span class="sd">            std_f: A module whose forward function accepts input of sixe n_smps*d and outputs a standard deviation for</span>
<span class="sd">            each sample of size n_smps*d_y</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mn_f</span> <span class="o">=</span> <span class="n">mn_f</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_f</span> <span class="o">=</span> <span class="n">std_f</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;log_2_pi&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)))</span>

<div class="viewcode-block" id="CondGaussianDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes conditional mean.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: data samples are conditioned on. Of shape n_smps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i,:] is the mean conditioned on x[i,:]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes log P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x</span>

<span class="sd">            y: Values we desire the log probability for.  Of shape n_smps*d_y.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Log-likelihood of each sample. Of shape n_smps.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">d_y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">ll</span> <span class="o">=</span> <span class="o">-.</span><span class="mi">5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">y</span> <span class="o">-</span> <span class="n">mn</span><span class="p">)</span><span class="o">/</span><span class="n">std</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ll</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ll</span> <span class="o">-=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="n">d_y</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">log_2_pi</span>

        <span class="k">return</span> <span class="n">ll</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from the reparameterized form of P(y|x).</span>

<span class="sd">        If a sample without gradients is desired, wrap the call to sample in torch.no_grad().</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape nSmps*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            y: sampled data of shape nSmps*d_y.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mn</span> <span class="o">+</span> <span class="n">z</span><span class="o">*</span><span class="n">std</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.kl"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes the KL divergence between the conditional distribution represented by this object and another.</span>

<span class="sd">        KL divergence is computed based on the closed form formula for KL divergence between two Gaussians.</span>

<span class="sd">        Note: This function will move the conditioning data (x) to the appropriate device(s)</span>
<span class="sd">            so calculations can be carried out without needing to move this object or the other conditional</span>
<span class="sd">            distribution between devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_2: The other conditional distribution in the KL divergence.</span>

<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">            smp: This input is ignored, as KL divergence is based on a closed form formula.</span>

<span class="sd">            return_device: The device the calculated kl tensor should be returned to.  If None, this will</span>
<span class="sd">            be the device the first parameter of this object is on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            kl: Of shape n_smps.  kl[i] is the KL divergence between the two distributions for the i^th conditioing</span>
<span class="sd">            input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">self_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="n">d_2_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

        <span class="n">x_self</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">self_device</span><span class="p">)</span>
        <span class="n">x_d_2</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d_2_device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">return_device</span> <span class="o">=</span> <span class="n">self_device</span>

        <span class="n">mn_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
        <span class="n">std_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>

        <span class="n">mn_2</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
        <span class="n">std_2</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>

        <span class="n">d</span> <span class="o">=</span> <span class="n">mn_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">sigma_ratio_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">std_1</span><span class="o">/</span><span class="n">std_2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">mn_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">mn_2</span> <span class="o">-</span> <span class="n">mn_1</span><span class="p">)</span><span class="o">/</span><span class="n">std_2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">log_det_1</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std_1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_det_2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std_2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">log_det_diff</span> <span class="o">=</span> <span class="n">log_det_2</span> <span class="o">-</span> <span class="n">log_det_1</span>

        <span class="n">kl</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span><span class="o">*</span><span class="p">(</span><span class="n">sigma_ratio_sum</span> <span class="o">+</span> <span class="n">mn_diff</span> <span class="o">+</span> <span class="n">log_det_diff</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">kl</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a sample in standard form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Converts between compact and standard sample form.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.sample_to"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.sample_to">[docs]</a>    <span class="k">def</span> <span class="nf">sample_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Moves a sample in compact form to a given device.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">smp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span></div>

<div class="viewcode-block" id="CondGaussianDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="CondSpikeSlabDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondSpikeSlabDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents a conditional spike and slab distribution. &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">spike_d</span><span class="p">:</span> <span class="n">CondVAEDistribution</span><span class="p">,</span> <span class="n">slab_d</span><span class="p">:</span> <span class="n">CondVAEDistribution</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a CondSpikeSlabDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            d: The number of variables the spike and slab distribution is over</span>

<span class="sd">            spike_d: The spike distribution</span>

<span class="sd">            slab_d: The slab distribution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span> <span class="o">=</span> <span class="n">spike_d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slab_d</span> <span class="o">=</span> <span class="n">slab_d</span>

<div class="viewcode-block" id="CondSpikeSlabDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes  E(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x</span>

<span class="sd">            y: Values we desire the log probability for.  Of shape nSmps*d_y.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: Conditional expectation. Of shape n_smps*d_y</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_smps</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">spike_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_smps</span><span class="p">)))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">slab_mn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slab_d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spike_p</span><span class="o">*</span><span class="n">slab_mn</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples a conditional spike and slab distribution.</span>

<span class="sd">        This function will return samples in compact form.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: The data to condition on.  Of shape n_smps*d_x.</span>

<span class="sd">        Returns: A compact representation of the sample:</span>

<span class="sd">            n_smps: the number of samples</span>

<span class="sd">            support: A binary tensor. support[i] is 1 if smp i is non-zero</span>

<span class="sd">            nz_vls: A tensor with the non-zero values.  nz_vls[j,:] contains the value for the j^th non-zero entry in</span>
<span class="sd">                    support. In other words, nz_vls gives the non-zero values corresponding to the samples in</span>
<span class="sd">                    x[support, :].  If there are no non-zero values this will be None.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_smps</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">support</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">support</span><span class="p">):</span>
            <span class="n">nz_vls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slab_d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">support</span><span class="p">,</span> <span class="p">:])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nz_vls</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">n_smps</span><span class="p">,</span> <span class="n">support</span><span class="p">,</span> <span class="n">nz_vls</span><span class="p">]</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes log P(y|x).</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_smps*d_x.</span>

<span class="sd">            y: Compact representation of a sample.  See sample().</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Log-likelihood of each sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_smps</span><span class="p">,</span> <span class="n">support</span><span class="p">,</span> <span class="n">nz_vls</span> <span class="o">=</span> <span class="n">y</span>

        <span class="c1"># Log-likelihood due to spike distribution</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">support</span><span class="p">)</span>
        <span class="c1"># Log-likelihood due to slab distribution</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">support</span><span class="p">):</span>
            <span class="n">ll</span><span class="p">[</span><span class="n">support</span><span class="p">]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">slab_d</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">support</span><span class="p">,</span> <span class="p">:],</span> <span class="n">nz_vls</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">ll</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a standard sample representation from a compact representation.</span>

<span class="sd">        Args:</span>
<span class="sd">           smp: The compact representation of a sample (the compact representation of a sample is the form returned by</span>
<span class="sd">           sample)</span>

<span class="sd">        Returns:</span>
<span class="sd">             formed_smp: The standard form of a sample.  formed_smp[i] gives the value of the i^th sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_smps</span><span class="p">,</span> <span class="n">support</span><span class="p">,</span> <span class="n">nz_vls</span> <span class="o">=</span> <span class="n">smp</span>

        <span class="c1"># First handle the case where all values are zero</span>
        <span class="k">if</span> <span class="n">nz_vls</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_smps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">])</span>

        <span class="c1"># Now handle the case where we have at least one non-zero value</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nz_vls</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">formed_smp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n_smps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">])</span>
            <span class="n">formed_smp</span><span class="p">[</span><span class="n">support</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">nz_vls</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">formed_smp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_smps</span><span class="p">)</span>
            <span class="n">formed_smp</span><span class="p">[</span><span class="n">support</span><span class="p">]</span> <span class="o">=</span> <span class="n">nz_vls</span>

        <span class="k">return</span> <span class="n">formed_smp</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a compact sample from a full sample.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: The standard representation of the sample of shape n_smps*d</span>

<span class="sd">        Returns:</span>
<span class="sd">            n_smps, support, nz_vls: Compact representation of the sample.  See sample().</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_smps</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">smp</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">support</span> <span class="o">=</span> <span class="n">smp</span> <span class="o">!=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">support</span><span class="p">):</span>
            <span class="n">nz_vls</span> <span class="o">=</span> <span class="n">smp</span><span class="p">[</span><span class="n">support</span><span class="p">,:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nz_vls</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">n_smps</span><span class="p">,</span> <span class="n">support</span><span class="p">,</span> <span class="n">nz_vls</span><span class="p">]</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">slab_d</span><span class="o">.</span><span class="n">r_params</span><span class="p">()</span></div>

<div class="viewcode-block" id="CondSpikeSlabDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondSpikeSlabDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">spike_d</span><span class="o">.</span><span class="n">s_params</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="CondMatrixProductDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondMatrixProductDistribution</span><span class="p">(</span><span class="n">CondVAEDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents conditional distributions over matrices.</span>

<span class="sd">    Consider a matrix, W, with N rows and M columns.  Given a tensor X with N rows and P columns of conditioning data,</span>
<span class="sd">    this object represents:</span>

<span class="sd">            P(W|X) = \prod_i=1^N P_i(W[i,:]| X[i, :]),</span>

<span class="sd">        where:</span>

<span class="sd">            P_i(W[i,:] | X[i, :]) = \prod_j=1^M P_j(W[i,j] | X[i,:]),</span>

<span class="sd">        where the P_j distributions are specified by the user.</span>

<span class="sd">    In other words, we model all entries of W as conditionally independent given X, where entries of W are modeled as</span>
<span class="sd">    distributed according to a different conditional distribution depending on what column they are in.</span>


<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dists</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">CondVAEDistribution</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new CondMatrixProductDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            dists: dists[j] is P_j, that is the conditional distribution to use for column j.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dists</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">dists</span><span class="p">)</span>

<div class="viewcode-block" id="CondMatrixProductDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes the conditional mean of the distribtion at different samples.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: A tensor of shape n_rows*d_x.</span>

<span class="sd">        Returns:</span>
<span class="sd">            mn: mn[i, :] is the mean conditioned on x[i, :]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Samples from a conditional distribution.</span>

<span class="sd">        Note: Sample is represented in compact form.  Use form_standard_sample to form</span>
<span class="sd">        the sample into it&#39;s matrix representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: A tensor of shape n_rows*d_x.  x[i,:] is what row i is conditioned on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            smp: smp[j] is the compact representation of the sample for column j.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">]</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.form_standard_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.form_standard_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_standard_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a standard representation of a sample from the output of sample.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: Compact representation of a sample.</span>

<span class="sd">        Returns:</span>
<span class="sd">            formed_smp: The sample represented as a matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">smp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.form_compact_sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.form_compact_sample">[docs]</a>    <span class="k">def</span> <span class="nf">form_compact_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">object</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Forms a compact representation of a sample given a standard representation.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: The standard representation of the sample as a matrix.</span>

<span class="sd">        Returns:</span>
<span class="sd">            formed_smp: The compact representation of the sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Break up our columns of the matrix, making sure they have the right shap</span>
        <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">smp</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">col_smps</span> <span class="o">=</span> <span class="p">[</span><span class="n">smp</span><span class="p">[:,</span> <span class="n">c_i</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">)]</span>

        <span class="c1"># Now call form standard sample on each column with the appropriate distribution</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">form_standard_sample</span><span class="p">(</span><span class="n">c_s</span><span class="p">)</span> <span class="k">for</span> <span class="n">c_s</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">col_smps</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)]</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.sample_to"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.sample_to">[docs]</a>    <span class="k">def</span> <span class="nf">sample_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Moves a sample in compact form to a given device.</span>

<span class="sd">        Args:</span>
<span class="sd">            smp: The sample to move.</span>

<span class="sd">            device: The device to move the sample to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">sample_to</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">smp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)]</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Computes the conditional log probability of individual rows.</span>

<span class="sd">        Args:</span>
<span class="sd">            x: Data we condition on.  Of shape n_rows*d_x</span>

<span class="sd">            y: Compact representation of the samples we desire the probability for.  Compact representation means the</span>
<span class="sd">            form of a sample as output by the sample() function.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ll: Conditional log probability of each row. Of shape n_rows.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Calculate the log-likelihood of each entry in the matrix</span>
        <span class="n">n_rows</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">entry_ll</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">c_s</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">c_s</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">entry_ll</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.kl"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">Sequence</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes the KL divergence between this object and another CondMatrixProductDistribution conditioned on input.</span>

<span class="sd">        This function overrides the default kl function of CondVAEDistribution so that the KL divergence is</span>
<span class="sd">        computed between distributions for the same column and then summed up. This is still mathematically</span>
<span class="sd">        correct, but if the distributions for the columns also override kl, then distribution specific kl</span>
<span class="sd">        calculations (perhaps analytical calculations) can be carried out.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_2: The other conditional distribution in the KL divergence.</span>

<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">            smp: An set samples of shape n_smps*d_y. smp[i,:] should be drawn this objects distribution.  This input is</span>
<span class="sd">            provided because some distributions for the columns may not analytically compute KL divergence.</span>

<span class="sd">            return_device: The device the calculated kl tensor should be returned to.  If None, this will</span>
<span class="sd">            be the device the first parameter of this object is on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            kl: Of shape n_smps.  kl[i] is the KL divergence between the two distributions for the i^th sample.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_cols</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">smp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">smp</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">)</span>

        <span class="n">kl</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">kl</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">return_device</span><span class="o">=</span><span class="n">return_device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">):</span>
            <span class="n">kl</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span><span class="o">.</span><span class="n">kl</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">],</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">[</span><span class="n">c_i</span><span class="p">],</span> <span class="n">return_device</span><span class="o">=</span><span class="n">return_device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">kl</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.r_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.r_params">[docs]</a>    <span class="k">def</span> <span class="nf">r_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of parameters for which gradients can be estimated with the reparameterization trick.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span></div>

<div class="viewcode-block" id="CondMatrixProductDistribution.s_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixProductDistribution.s_params">[docs]</a>    <span class="k">def</span> <span class="nf">s_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns an empty list as there are no parameters for optimization with a score method based gradient.</span>

<span class="sd">        See method of parent for more information.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="CondGaussianMatrixProductDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianMatrixProductDistribution">[docs]</a><span class="k">class</span> <span class="nc">CondGaussianMatrixProductDistribution</span><span class="p">(</span><span class="n">CondMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents conditional Gaussian distributions over matrices.</span>

<span class="sd">    Consider a matrix, W, with N rows and M columns.  Given a tensor X with N rows and P columns of conditioning data,</span>
<span class="sd">    this object represents:</span>

<span class="sd">            P(W|X) = \prod_i=1^N P_i(W[i,:]| X[i, :]),</span>

<span class="sd">        where:</span>

<span class="sd">            P_i(W[i,:] | X[i, :]) = \prod_j=1^M P_j(W[i,j] | X[i,:]),</span>

<span class="sd">        where the P_j distributions are conditional Gaussian distributions specified by the user.</span>

<span class="sd">    In other words, we model all entries of W as conditionally independent given X, where entries of W are modeled as</span>
<span class="sd">    distributed according to a different conditional Gaussian distribution depending on what column they are in.</span>

<span class="sd">    This objects extends CondMatrixProductDistribution, and it&#39;s main purpose is to allow KL divergences to be</span>
<span class="sd">    computed not only between itself and another CondMatrixProductDistribution but also a CondGaussianDistribtion when</span>
<span class="sd">    both distributions are over matrices of the same shape.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dists</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">CondGaussianDistribution</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new CondGaussianMatrixProductDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            dists: Conditional gaussian distributions for each column of the matrix.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dists</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">CondGaussianDistribution</span><span class="p">):</span>
                <span class="k">raise</span><span class="p">(</span><span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;All distributions must be CondGaussianDistribution objects.&#39;</span><span class="p">))</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">dists</span><span class="p">)</span>

<div class="viewcode-block" id="CondGaussianMatrixProductDistribution.kl"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondGaussianMatrixProductDistribution.kl">[docs]</a>    <span class="k">def</span> <span class="nf">kl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">smp</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">return_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Computes the KL divergence between the conditional distribution represented by this object and another.</span>

<span class="sd">        The second distribtion can be either another CondMatrixProductDistribution or a CondGaussianDistribution over</span>
<span class="sd">        matrices of the same size this distribution is over.</span>

<span class="sd">        KL divergence is computed based on the closed form formula for KL divergence between two Gaussians.</span>

<span class="sd">        Note: This function will move the conditioning data (x) to the appropriate device(s)</span>
<span class="sd">            so calculations can be carried out without needing to move this object or the other conditional</span>
<span class="sd">            distribution between devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            d_2: The other conditional distribution in the KL divergence.</span>

<span class="sd">            x: A tensor of shape n_smps*d_x.  x[i,:] is what sample i is conditioned on.</span>

<span class="sd">            smp: This input is ignored, as KL divergence is based on a closed form formula.</span>

<span class="sd">            return_device: The device the calculated kl tensor should be returned to.  If None, this will</span>
<span class="sd">            be the device the first parameter of this object is on.</span>

<span class="sd">        Returns:</span>
<span class="sd">            kl: Of shape n_smps.  kl[i] is the KL divergence between the two distributions for the i^th conditioning</span>
<span class="sd">            input.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d_2</span><span class="p">,</span> <span class="n">CondGaussianMatrixProductDistribution</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">kl</span><span class="p">(</span><span class="n">d_2</span><span class="o">=</span><span class="n">d_2</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">smp</span><span class="o">=</span><span class="n">smp</span><span class="p">,</span> <span class="n">return_device</span><span class="o">=</span><span class="n">return_device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">d_2</span><span class="p">,</span> <span class="n">CondGaussianDistribution</span><span class="p">):</span>

            <span class="n">self_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
            <span class="n">d_2_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">d_2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>

            <span class="c1"># Make (possible) copies of conditioning data on each device we need it</span>
            <span class="n">x_self</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">self_device</span><span class="p">)</span>
            <span class="n">x_d_2</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d_2_device</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">return_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">return_device</span> <span class="o">=</span> <span class="n">self_device</span>

            <span class="n">mn_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">std_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x_self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">mn_2</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">mn_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>
            <span class="n">std_2</span> <span class="o">=</span> <span class="n">d_2</span><span class="o">.</span><span class="n">std_f</span><span class="p">(</span><span class="n">x_d_2</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">return_device</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">mn_1</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">mn_2</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot compute KL divergence between distributions over matrices of different shapes.&#39;</span><span class="p">))</span>

            <span class="n">d</span> <span class="o">=</span> <span class="n">mn_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">sigma_ratio_sum</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">std_1</span> <span class="o">/</span> <span class="n">std_2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">mn_diff</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="n">mn_2</span> <span class="o">-</span> <span class="n">mn_1</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">log_det_1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std_1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">log_det_2</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std_2</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">log_det_diff</span> <span class="o">=</span> <span class="n">log_det_2</span> <span class="o">-</span> <span class="n">log_det_1</span>

            <span class="n">kl</span> <span class="o">=</span> <span class="o">.</span><span class="mi">5</span> <span class="o">*</span> <span class="p">(</span><span class="n">sigma_ratio_sum</span> <span class="o">+</span> <span class="n">mn_diff</span> <span class="o">+</span> <span class="n">log_det_diff</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">kl</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;d_2 must be either a CondGaussianMatrixProductDistribution or a CondGaussianDistribution.&#39;</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="MatrixGammaProductDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixGammaProductDistribution">[docs]</a><span class="k">class</span> <span class="nc">MatrixGammaProductDistribution</span><span class="p">(</span><span class="n">CondMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents a distribution over matrices where each entry is pulled iid from a separate Gamma distribution.</span>

<span class="sd">    For a matrix, W, with N rows and M columns, we model:</span>

<span class="sd">        P(W) = \prod_i=1^N \prod_j=1^M P_ij(W[i,j]),</span>

<span class="sd">    where P_ij is a Gamma distribution with concentration parameter \alpha_ij and rate parameter \beta_ij.</span>

<span class="sd">    Note: This function extends CondMatrixProductDistribution, allowing this distribution to be used in</span>
<span class="sd">    code where conditional distributions are required, so that the resulting &quot;conditional distributions&quot;</span>
<span class="sd">    are the same irrespective of conditioning input.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">conc_lb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">conc_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="n">conc_iv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
                 <span class="n">rate_lb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span><span class="p">,</span> <span class="n">rate_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1000.0</span><span class="p">,</span> <span class="n">rate_iv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new MatrixGammaProductDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The shape of matrices this represents distributions over.</span>

<span class="sd">            conc_lb: The lower bound that concentration parameters can take on</span>

<span class="sd">            conc_ub: The upper bound that concentration parameters can take on</span>

<span class="sd">            conc_iv: The initial value for concentration parameters.  All distributions will be initialized to have the</span>
<span class="sd">            same initial values.</span>

<span class="sd">            rate_lb: The lower bound that rate parameters can take on</span>

<span class="sd">            rate_ub: The upper bound that rate parameters can take on</span>

<span class="sd">            rate_iv: The initial value for rate parameters.  All distributions will be initialized to have the</span>
<span class="sd">            same initial values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="n">col_dists</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cols</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">conc_f</span> <span class="o">=</span> <span class="n">IndSmpConstantBoundedFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=</span><span class="n">conc_lb</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">conc_ub</span><span class="p">,</span> <span class="n">init_value</span><span class="o">=</span><span class="n">conc_iv</span><span class="p">,</span>
                                              <span class="n">check_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">rate_f</span> <span class="o">=</span> <span class="n">IndSmpConstantBoundedFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=</span><span class="n">rate_lb</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">rate_ub</span><span class="p">,</span> <span class="n">init_value</span><span class="o">=</span><span class="n">rate_iv</span><span class="p">,</span>
                                              <span class="n">check_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">col_dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CondGammaDistribution</span><span class="p">(</span><span class="n">conc_f</span><span class="o">=</span><span class="n">conc_f</span><span class="p">,</span> <span class="n">rate_f</span><span class="o">=</span><span class="n">rate_f</span><span class="p">)</span>

        <span class="c1"># Create the object</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">col_dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span> <span class="o">=</span> <span class="n">n_rows</span></div>


<div class="viewcode-block" id="MatrixFoldedNormalProductDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixFoldedNormalProductDistribution">[docs]</a><span class="k">class</span> <span class="nc">MatrixFoldedNormalProductDistribution</span><span class="p">(</span><span class="n">CondMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents a distribution over matrices where each entry is pulled iid from a Folded Normal distribution.</span>

<span class="sd">    For a matrix, W, with N rows and M columns, we model:</span>

<span class="sd">        P(W) = \prod_i=1^N \prod_j=1^M P_ij(W[i,j]),</span>

<span class="sd">    where P_ij is a Folded Normal distribution with parameters \mu_ij and \sigma_ij.</span>

<span class="sd">    Note: This function extends CondMatrixProductDistribution, allowing this distribution to be used in</span>
<span class="sd">    code where conditional distributions are required, so that the resulting &quot;conditional distributions&quot;</span>
<span class="sd">    are the same irrespective of conditioning input.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">mu_lb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">mu_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">mu_iv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">sigma_lb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">001</span><span class="p">,</span> <span class="n">sigma_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">sigma_iv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new MatrixGammaProductDistribution object.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The shape of matrices this represents distributions over.</span>

<span class="sd">            mu_lb: The lower bound that mu parameters can take on</span>

<span class="sd">            mu_ub: The upper bound that mu parameters can take on</span>

<span class="sd">            mu_iv: The initial value for mu parameters.  All distributions will be initialized to have the</span>
<span class="sd">            same initial values.</span>

<span class="sd">            sigma_lb: The lower bound that sigma parameters can take on</span>

<span class="sd">            sigma_ub: The upper bound that sigma parameters can take on</span>

<span class="sd">            sigma_iv: The initial value for sigma parameters.  All distributions will be initialized to have the</span>
<span class="sd">            same initial values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="n">col_dists</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cols</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">mu_f</span> <span class="o">=</span> <span class="n">IndSmpConstantBoundedFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=</span><span class="n">mu_lb</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">mu_ub</span><span class="p">,</span> <span class="n">init_value</span><span class="o">=</span><span class="n">mu_iv</span><span class="p">)</span>
            <span class="n">sigma_f</span> <span class="o">=</span> <span class="n">IndSmpConstantBoundedFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=</span><span class="n">sigma_lb</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">sigma_ub</span><span class="p">,</span>
                                               <span class="n">init_value</span><span class="o">=</span><span class="n">sigma_iv</span><span class="p">)</span>
            <span class="n">col_dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CondFoldedNormalDistribution</span><span class="p">(</span><span class="n">mu_f</span><span class="o">=</span><span class="n">mu_f</span><span class="p">,</span> <span class="n">sigma_f</span><span class="o">=</span><span class="n">sigma_f</span><span class="p">)</span>

        <span class="c1"># Create the object</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">col_dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span> <span class="o">=</span> <span class="n">n_rows</span>

<div class="viewcode-block" id="MatrixFoldedNormalProductDistribution.forward"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixFoldedNormalProductDistribution.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Overwrites parent forward so x does not have to be provided. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span></div>

<div class="viewcode-block" id="MatrixFoldedNormalProductDistribution.sample"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixFoldedNormalProductDistribution.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Overwrites parent sample so x does not have to be provided. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span></div>

<div class="viewcode-block" id="MatrixFoldedNormalProductDistribution.log_prob"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixFoldedNormalProductDistribution.log_prob">[docs]</a>    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">Sequence</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Overwrites parent log_prob so x does not have to be provided.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If y is None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;y value cannot be none&#39;</span><span class="p">))</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="MatrixGaussianProductDistribution"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixGaussianProductDistribution">[docs]</a><span class="k">class</span> <span class="nc">MatrixGaussianProductDistribution</span><span class="p">(</span><span class="n">CondGaussianMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Represents a distribution over matrices where each entry is pulled iid from a separate Gaussian distribution.</span>

<span class="sd">    For a matrix, W, with N rows and M columns, we model:</span>

<span class="sd">        P(W) = \prod_i=1^N \prod_j=1^M P_ij(W[i,j]),</span>

<span class="sd">    where P_ij is a Gaussian distribution with mean mu_ij and standard deviation std_ij.</span>

<span class="sd">    Note: This function extends CondMatrixProductDistribution, allowing this distribution to be used in</span>
<span class="sd">    code where conditional distributions are required, so that the resulting &quot;conditional distributions&quot;</span>
<span class="sd">    are the same irrespective of conditioning input.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">mn_mn</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">mn_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span><span class="p">,</span>
                 <span class="n">std_lb</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">000001</span><span class="p">,</span> <span class="n">std_ub</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span> <span class="n">std_iv</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new MatrixGaussianProductDistribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape: The shape of matrices this represents distributions over.</span>

<span class="sd">            mn_mn, std_mn: The mean and standard deviation to use when generating random initial values for the</span>
<span class="sd">            mean distribution for each entry.</span>

<span class="sd">            std_lb, std_ub, std_iv: lower &amp; upper bounds for standard deviation values and the initial value</span>
<span class="sd">            for the standard deviation for the distribution for each entry.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Generate the distributions for each column</span>
        <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="n">col_dists</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cols</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">mn_f</span> <span class="o">=</span> <span class="n">IndSmpConstantRealFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">init_mn</span><span class="o">=</span><span class="n">mn_mn</span><span class="p">,</span> <span class="n">init_std</span><span class="o">=</span><span class="n">mn_std</span><span class="p">,</span> <span class="n">check_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">std_f</span> <span class="o">=</span> <span class="n">IndSmpConstantBoundedFcn</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">lower_bound</span><span class="o">=</span><span class="n">std_lb</span><span class="p">,</span> <span class="n">upper_bound</span><span class="o">=</span><span class="n">std_ub</span><span class="p">,</span> <span class="n">init_value</span><span class="o">=</span><span class="n">std_iv</span><span class="p">,</span>
                                             <span class="n">check_sizes</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">col_dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CondGaussianDistribution</span><span class="p">(</span><span class="n">mn_f</span><span class="o">=</span><span class="n">mn_f</span><span class="p">,</span> <span class="n">std_f</span><span class="o">=</span><span class="n">std_f</span><span class="p">)</span>

        <span class="c1"># Create the object</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">col_dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_rows</span> <span class="o">=</span> <span class="n">n_rows</span>

<div class="viewcode-block" id="MatrixGaussianProductDistribution.initialize"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.MatrixGaussianProductDistribution.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mn_mn</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">mn_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span><span class="p">,</span> <span class="n">std_v</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Initializes parameters of the distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            mn_mn, mn_std: The mean and standard deviation for the distribution values for the mean are drawn from</span>

<span class="sd">            std_v: The value to set the standard deviation to everywhere</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">mn_f</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">vl</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="n">mn_mn</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">mn_std</span><span class="p">)</span>

            <span class="n">std_device</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">lower_bound</span><span class="o">.</span><span class="n">device</span>
            <span class="n">lower_bound</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">lower_bound</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">upper_bound</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">upper_bound</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">init_v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arctanh</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">std_v</span> <span class="o">-</span> <span class="n">lower_bound</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">upper_bound</span> <span class="o">-</span> <span class="n">lower_bound</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">init_v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">init_v</span><span class="p">)</span>
            <span class="n">init_v</span> <span class="o">=</span> <span class="n">init_v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">std_device</span><span class="p">)</span>
            <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">v</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">init_v</span></div></div>


<div class="viewcode-block" id="CondMatrixHypercubePrior"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixHypercubePrior">[docs]</a><span class="k">class</span> <span class="nc">CondMatrixHypercubePrior</span><span class="p">(</span><span class="n">CondGaussianMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Extends CondGaussianMatrixProductDistribution so the distribution for each column is a Gaussian with mean and standard</span>
<span class="sd">    deviation functions which are sums of tiled hypercube basis functions.</span>

<span class="sd">    Specifically, For a matrix, W, under a CondMatrixProductDistribution, we model:</span>

<span class="sd">        W[i,j] ~ P_j(W[i,j] | X[i,:]).</span>

<span class="sd">    Here, we specify that P_j is a conditional Gaussian distribution with mean given by m(X[i,:]) and standard</span>
<span class="sd">    deviation by s(X[i,:]). Specifically, m() is a SumOfTiledHyperCubeBasisFcns function and s() is an exponentiated</span>
<span class="sd">    SumOfTiledHyperCubeBasisFcns function plus an offset.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">mn_hc_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">std_hc_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">min_std</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">mn_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">std_init</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="o">.</span><span class="mi">01</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a CondMatrixHypercubePrior object</span>

<span class="sd">        Args:</span>
<span class="sd">            n_cols: The number of columns in the matrices we represent distributions over.</span>

<span class="sd">            mn_hc_params: A dictionary with parameters for passing into the init() function of</span>
<span class="sd">            SumOfTiledHyperCubeBasisFcns when creating the hypercube function for the mean function for each P_j.</span>

<span class="sd">            std_hc_params: A dictionary with parameters for passing into the init() function of</span>
<span class="sd">            SumOfTiledHyperCubeBasisFcns when creating the hypercube function which will be exponentiated and offset</span>
<span class="sd">            to form the final standard deviation function for each P_j.</span>

<span class="sd">            min_std: The min standard deviation any P_j can take on.</span>

<span class="sd">            mn_init: The initial value for the mean function. The mean will take on this value everywhere.</span>

<span class="sd">            std_init: The initial value for the standard deviation function.  The standard deviation will take</span>
<span class="sd">            on this value everywhere. Must be greater than min_std</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If std_init is not greater than min_std.</span>

<span class="sd">        &quot;&quot;&quot;</span>


        <span class="k">if</span> <span class="n">std_init</span> <span class="o">&lt;=</span> <span class="n">min_std</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;std_init must be greater than min_std&#39;</span><span class="p">))</span>

        <span class="c1"># Form each P_j</span>
        <span class="n">col_dists</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cols</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>

            <span class="c1"># Create mean function, setting it&#39;s initial value</span>
            <span class="n">mn_f</span> <span class="o">=</span> <span class="n">SumOfTiledHyperCubeBasisFcns</span><span class="p">(</span><span class="o">**</span><span class="n">mn_hc_params</span><span class="p">)</span>

            <span class="c1"># Create standard deviation function, setting it&#39;s initial value</span>
            <span class="n">std_hc_f</span> <span class="o">=</span> <span class="n">SumOfTiledHyperCubeBasisFcns</span><span class="p">(</span><span class="o">**</span><span class="n">std_hc_params</span><span class="p">)</span>
            <span class="n">std_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">std_hc_f</span><span class="p">,</span> <span class="n">FixedOffsetExp</span><span class="p">(</span><span class="n">min_std</span><span class="p">))</span>

            <span class="c1"># Create the distribution for the column</span>
            <span class="n">col_dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CondGaussianDistribution</span><span class="p">(</span><span class="n">mn_f</span><span class="o">=</span><span class="n">mn_f</span><span class="p">,</span> <span class="n">std_f</span><span class="o">=</span><span class="n">std_f</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">col_dists</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cols</span> <span class="o">=</span> <span class="n">n_cols</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mn_hc_params</span> <span class="o">=</span> <span class="n">mn_hc_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">std_hc_params</span> <span class="o">=</span> <span class="n">std_hc_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_std</span> <span class="o">=</span> <span class="n">min_std</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_mn</span><span class="p">(</span><span class="n">mn_init</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_std</span><span class="p">(</span><span class="n">std_init</span><span class="p">)</span>

<div class="viewcode-block" id="CondMatrixHypercubePrior.increase_std"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixHypercubePrior.increase_std">[docs]</a>    <span class="k">def</span> <span class="nf">increase_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Increases the standard deviation by a factor which is approximately log(f).</span>

<span class="sd">        Args:</span>
<span class="sd">            f: The factor to increase standard deviation by.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">:</span>
            <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">std_f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondMatrixHypercubePrior.set_mn"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixHypercubePrior.set_mn">[docs]</a>    <span class="k">def</span> <span class="nf">set_mn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Set the mean to a single value everyhwere.</span>

<span class="sd">        Args:</span>
<span class="sd">            v: The value to set the mean to</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">mn_hc_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span><span class="o">.</span><span class="n">mn_f</span>
            <span class="n">n_basis_fcns_per_mn_cube</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mn_hc_params</span><span class="p">[</span><span class="s1">&#39;n_div_per_hc_side_per_dim&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">mn_cube_vl</span> <span class="o">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">n_basis_fcns_per_mn_cube</span>
            <span class="n">mn_hc_f</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">mn_cube_vl</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">mn_hc_f</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div>

<div class="viewcode-block" id="CondMatrixHypercubePrior.set_std"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.CondMatrixHypercubePrior.set_std">[docs]</a>    <span class="k">def</span> <span class="nf">set_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Sets the standard deviation to a single value everywhere.</span>

<span class="sd">        Args:</span>
<span class="sd">            v: The value to set the standard deviation to</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cols</span><span class="p">):</span>
            <span class="n">std_hc_f</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span><span class="o">.</span><span class="n">std_f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">n_basis_fcns_per_std_cube</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std_hc_params</span><span class="p">[</span><span class="s1">&#39;n_div_per_hc_side_per_dim&#39;</span><span class="p">])[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">std_cube_vl</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_std</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_basis_fcns_per_std_cube</span>
            <span class="n">std_hc_f</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">std_cube_vl</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">std_hc_f</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="GroupCondMatrixHypercubePrior"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.GroupCondMatrixHypercubePrior">[docs]</a><span class="k">class</span> <span class="nc">GroupCondMatrixHypercubePrior</span><span class="p">(</span><span class="n">CondGaussianMatrixProductDistribution</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Extends CondGaussianMatrixProductDistribution so the distribution for each column is a Gaussian with</span>
<span class="sd">    mean and standard deviation functions that depend on groups of properties.</span>

<span class="sd">    Specifically, For a matrix, W, under a CondMatrixProductDistribution, we model:</span>

<span class="sd">        W[i,j] ~ P_j(W[i,j] | X[i,:]).</span>

<span class="sd">    Here, we specify that P_j is a conditional Gaussian distribution with mean given by m(X[i,:]) and standard</span>
<span class="sd">    deviation by s(X[i,:]). For m(), we specify</span>

<span class="sd">        m(X[i,:]) = s_mn*tanh( \sum_{ind_j \in inds} f^mn_j(X[i, ind_j]) ) + o_mn,</span>

<span class="sd">    where each f_j() is a SumOfTiledHyperCubeBasisFcns function.</span>

<span class="sd">    For s(), we specify</span>

<span class="sd">        s(X[i,:]) = exp( \sum_{ind_j \in inds} f^std_j(X[i, ind_j]) ) + min_std,</span>

<span class="sd">    where min_std is a fixed, small offset ensuring s() stays strictly positive.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">group_inds</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span>
                 <span class="n">mn_hc_params</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">std_hc_params</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
                 <span class="n">min_std</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">mn_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">std_init</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
                 <span class="n">tanh_init_opts</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new GroupCondMatrixHypercubePrior object.</span>

<span class="sd">        Args:</span>
<span class="sd">            n_cols: The number of columns in the matrices we represent distributions over.</span>

<span class="sd">            group_inds: group_inds[j] are the indices into the dimensions of X for properties for group j</span>

<span class="sd">            mn_hc_params: mn_hc_params[j] is a dictionary with parameters for passing into the init() function of</span>
<span class="sd">            SumOfTiledHyperCubeBasisFcns when creating the hypercube function for f^mn_j.</span>

<span class="sd">            std_hc_params: std_hc_params[j] is a dictionary with parameters for passing into the init() function</span>
<span class="sd">            of SumOfTiledHyperCubeBasisFcns when creating the hypercube function for f^std_j.</span>

<span class="sd">            min_std: The min standard deviation any P_j can take on.</span>

<span class="sd">            mn_init: The initial value for the mean function. The mean will take on this value everywhere.</span>

<span class="sd">            std_init: The initial value for the standard deviation function.  The standard deviation will take</span>
<span class="sd">            on this value everywhere. Must be greater than min_std</span>

<span class="sd">            tanh_init_opts: Dictionary of additional options when initializing the Tanh module for</span>
<span class="sd">            the mean function for each mode. If None, no options will be passed</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: If std_init is not greater than min_std.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">std_init</span> <span class="o">&lt;=</span> <span class="n">min_std</span><span class="p">:</span>
            <span class="k">raise</span><span class="p">(</span><span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;std_init must be greater than min_std&#39;</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">tanh_init_opts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tanh_init_opts</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># Make sure group inds are of the appropriate type</span>
        <span class="n">group_inds</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">inds</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="k">for</span> <span class="n">inds</span> <span class="ow">in</span> <span class="n">group_inds</span><span class="p">]</span>

        <span class="n">n_prop_spaces</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">group_inds</span><span class="p">)</span>

        <span class="n">dists</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span><span class="o">*</span><span class="n">n_cols</span>
        <span class="k">for</span> <span class="n">c_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_cols</span><span class="p">):</span>

            <span class="c1"># Setup mn function</span>
            <span class="n">mn_hc_fcns</span> <span class="o">=</span> <span class="p">[</span><span class="n">SumOfTiledHyperCubeBasisFcns</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">mn_hc_params</span><span class="p">]</span>
            <span class="n">mn_fcn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">SCC</span><span class="p">(</span><span class="n">group_inds</span><span class="o">=</span><span class="n">group_inds</span><span class="p">,</span> <span class="n">group_modules</span><span class="o">=</span><span class="n">mn_hc_fcns</span><span class="p">),</span>
                                         <span class="n">SumAlongDim</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">Tanh</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">tanh_init_opts</span><span class="p">))</span>

            <span class="c1"># Set initial value of mean function</span>
            <span class="n">mn_fcn</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">o</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">mn_init</span>

            <span class="c1"># Setup std function</span>
            <span class="n">std_hc_fcns</span> <span class="o">=</span> <span class="p">[</span><span class="n">SumOfTiledHyperCubeBasisFcns</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">std_hc_params</span><span class="p">]</span>
            <span class="n">std_fcn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">SCC</span><span class="p">(</span><span class="n">group_inds</span><span class="o">=</span><span class="n">group_inds</span><span class="p">,</span> <span class="n">group_modules</span><span class="o">=</span><span class="n">std_hc_fcns</span><span class="p">),</span>
                                          <span class="n">SumAlongDim</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">FixedOffsetExp</span><span class="p">(</span><span class="n">o</span><span class="o">=</span><span class="n">min_std</span><span class="p">))</span>

            <span class="c1"># Set initial value of std_hc_fcns</span>
            <span class="k">for</span> <span class="n">p_i</span><span class="p">,</span> <span class="n">fcn</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">std_hc_fcns</span><span class="p">):</span>
                <span class="n">div_f</span> <span class="o">=</span> <span class="n">n_prop_spaces</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">mn_hc_params</span><span class="p">[</span><span class="n">p_i</span><span class="p">][</span><span class="s1">&#39;n_div_per_hc_side_per_dim&#39;</span><span class="p">])</span>
                <span class="n">fcn</span><span class="o">.</span><span class="n">b_m</span><span class="o">.</span><span class="n">data</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">std_init</span> <span class="o">-</span> <span class="n">min_std</span><span class="p">)</span><span class="o">/</span><span class="n">div_f</span>

            <span class="n">dists</span><span class="p">[</span><span class="n">c_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">CondGaussianDistribution</span><span class="p">(</span><span class="n">mn_f</span><span class="o">=</span><span class="n">mn_fcn</span><span class="p">,</span> <span class="n">std_f</span><span class="o">=</span><span class="n">std_fcn</span><span class="p">)</span>

            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dists</span><span class="o">=</span><span class="n">dists</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistributionPenalizer"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.DistributionPenalizer">[docs]</a><span class="k">class</span> <span class="nc">DistributionPenalizer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; A base class for creating distribution penalizer objects.</span>

<span class="sd">    The main idea behind a penalizer object (vs. just applying a penalizer function) is that the ways we may</span>
<span class="sd">    want to penalize a distribution may require keeping track of some penalty parameters (e.g., a set of locations</span>
<span class="sd">    where we want to sample a distribution at).  Some of these parameters could even be optimizable.  Because of this,</span>
<span class="sd">    we introduce this concept of penalizer objects which are torch modules, so we can keep track of these parameters,</span>
<span class="sd">    easily move them between devices, etc...</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a DistributionPenalizer object. &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

<div class="viewcode-block" id="DistributionPenalizer.check_point"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.DistributionPenalizer.check_point">[docs]</a>    <span class="k">def</span> <span class="nf">check_point</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Returns a dictionary of parameters for the penalizer that should be saved in a check point.</span>

<span class="sd">        For the purposes of creating a check point, we can save memory by only logging the important parameters of a</span>
<span class="sd">        penalizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span><span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">)</span></div>

<div class="viewcode-block" id="DistributionPenalizer.get_marked_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.DistributionPenalizer.get_marked_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_marked_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns all parameters marked with the key string.</span>

<span class="sd">        Penalizers must associate each parameter with a unique key (e.g., fast_learning_rate_params). Each</span>
<span class="sd">        parameter should be associated with only one key (though multiple parameters can use the same key).  This</span>
<span class="sd">        function will return a list of parameters associated with the requested key.  If no parameters match the</span>
<span class="sd">        key an empty list should be returned.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span><span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">)</span></div>

<div class="viewcode-block" id="DistributionPenalizer.list_param_keys"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.DistributionPenalizer.list_param_keys">[docs]</a>    <span class="k">def</span> <span class="nf">list_param_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a list of keys associated with parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            keys: The list of keys.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span><span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">)</span></div>

<div class="viewcode-block" id="DistributionPenalizer.penalize"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.DistributionPenalizer.penalize">[docs]</a>    <span class="k">def</span> <span class="nf">penalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="n">CondVAEDistribution</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Calculates a penalty over a distribution.</span>

<span class="sd">        Args:</span>
<span class="sd">            d: The distribution to penalize</span>

<span class="sd">        Returns:</span>
<span class="sd">            penalty: The scalar penalty</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span><span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ColumnMeanClusterPenalizer"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer">[docs]</a><span class="k">class</span> <span class="nc">ColumnMeanClusterPenalizer</span><span class="p">(</span><span class="n">DistributionPenalizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Penalizes the mean of a conditional distribution over matrices to encouraging clustering of column values.</span>

<span class="sd">    Clustering here means clustering of values given what they are conditioned on.</span>

<span class="sd">    In particular, we work with conditional distributions over matrices M \in R^{n \times p} conditioned on</span>
<span class="sd">    input X \in R^{n \times q}, where each row of M is associated with the corresponding row of X.  Our goal is</span>
<span class="sd">    to encourage large values in each column of M to be assoicated with values in X that are close in space.</span>

<span class="sd">    We achieve this by:</span>

<span class="sd">        1) Keeping track of a &quot;center&quot; parameter for each column c_j \in R^{1 \times q} and &quot;scale&quot;</span>
<span class="sd">        parameter s_j \in R^{1 \times q} for each column j \in [1, p].  These parameters are learnable (but the</span>
<span class="sd">        user can chose to fix the scales).</span>

<span class="sd">        2) Let E_j be the expected value of column j conditioned on X.  We compute the cluster penalty for</span>
<span class="sd">        column j as: k_j = \sum_i w_i*d_i, where w_i is the absolute value of E_j[j] after E_j has been normalized</span>
<span class="sd">        to have a length of 1 and d_i is the square of scaled distance from c_j defined as</span>
<span class="sd">        d_i = \sum_k=1^q ((X[i, k] - c_j[k])/s_j[k])**2.  To guard against division by zero, small offsets are</span>
<span class="sd">        added as needed in the calculations.</span>

<span class="sd">        3) The penalty can be made arbitrarily small by driving the scales to infinity.  To prevent this,</span>
<span class="sd">        we calculate a term p = \sum_j \sum_q s_j[q]**2</span>

<span class="sd">        4) The final penalty is scale_penalty*p + \sum_j k_j</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_ctrs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">init_scales</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">scale_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Creates a new ColumnMeanClusterPenalizer object.</span>

<span class="sd">        Args:</span>
<span class="sd">            init_ctrs: Initial centers for each column.  Of shape [n_cols, x_dim]</span>

<span class="sd">            x: The points at which we evaluate the mean of the distribution. Of shape [n_pts, x_dim].</span>

<span class="sd">            init_scales: Initial scales for each column. Of shape [n_cols, x_dim]. If None, initial scales will be set</span>
<span class="sd">            to 1 for all dimensions and modes.</span>

<span class="sd">            scale_weight: The weight to apply to the scale penalty if learning scales.  If None, the scales will be be</span>
<span class="sd">            fixed at their init values and not learned.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">n_modes</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">init_ctrs</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Setup centers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span> <span class="o">=</span> <span class="n">n_modes</span>  <span class="c1"># We refer to columns as modes in the code</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">col_ctrs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init_ctrs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_weight_pen</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_scale_pen</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Setup weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span> <span class="o">=</span> <span class="n">scale_weight</span>
        <span class="k">if</span> <span class="n">scale_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># Indicates we want to treat weights as a parameter</span>
            <span class="k">if</span> <span class="n">init_scales</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">init_scales</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_modes</span><span class="p">,</span> <span class="n">n_cols</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scales</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init_scales</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># Indicates we will fix weights at initial values and not learn them</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;scales&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">init_scales</span><span class="p">))</span>

<div class="viewcode-block" id="ColumnMeanClusterPenalizer.check_point"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer.check_point">[docs]</a>    <span class="k">def</span> <span class="nf">check_point</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a dictionary with a copy of key parameters of the penalizer.</span>

<span class="sd">         Returns:</span>
<span class="sd">             params: A dictionary with the following keys:</span>

<span class="sd">                col_ctrs: The value of column centers</span>

<span class="sd">                scales: The value of the scales</span>

<span class="sd">                last_weight_pen: The value of the last weight penalty computed with the penalizer</span>

<span class="sd">                last_scale_pen: The value of the last scale penalty computed with the penalizer</span>
<span class="sd">         &quot;&quot;&quot;</span>

        <span class="n">col_ctrs_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">col_ctrs</span><span class="p">)</span>
        <span class="n">col_ctrs_copy</span> <span class="o">=</span> <span class="n">col_ctrs_copy</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">scales_copy</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">)</span>
        <span class="n">scales_copy</span> <span class="o">=</span> <span class="n">scales_copy</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;col_ctrs&#39;</span><span class="p">:</span> <span class="n">col_ctrs_copy</span><span class="p">,</span> <span class="s1">&#39;scales&#39;</span><span class="p">:</span> <span class="n">scales_copy</span><span class="p">,</span>
                <span class="s1">&#39;last_weight_pen&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_weight_pen</span><span class="p">,</span> <span class="s1">&#39;last_scale_pen&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_scale_pen</span><span class="p">}</span></div>

<div class="viewcode-block" id="ColumnMeanClusterPenalizer.get_marked_params"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer.get_marked_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_marked_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns parameters that should be assigned fast and slow learning rates.</span>

<span class="sd">        Args:</span>
<span class="sd">            key: The type of parameters that should be returned.  &#39;fast&#39; will return parameters that should be trained</span>
<span class="sd">            with fast learning rates; &#39;slow&#39; will return parameters that should be trained with slow training weights.</span>

<span class="sd">        Returns:</span>
<span class="sd">            params: The list of parameters matching the key</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;fast&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">col_ctrs</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;slow&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span></div>

<div class="viewcode-block" id="ColumnMeanClusterPenalizer.list_param_keys"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer.list_param_keys">[docs]</a>    <span class="k">def</span> <span class="nf">list_param_keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns the list of keys associated with parameters.</span>

<span class="sd">        Returns:</span>
<span class="sd">            keys: The keys</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s1">&#39;fast&#39;</span><span class="p">,</span> <span class="s1">&#39;slow&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="s1">&#39;fast&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="ColumnMeanClusterPenalizer.penalize"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer.penalize">[docs]</a>    <span class="k">def</span> <span class="nf">penalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="n">CondVAEDistribution</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Calculates the penalty for a distribution. &quot;&quot;&quot;</span>

        <span class="c1"># Move the penalizer to the same device as the distribution</span>
        <span class="n">d_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">d_device</span><span class="p">)</span>

        <span class="n">n_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mn</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="n">penalty</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">m_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_modes</span><span class="p">):</span>

            <span class="n">mn_i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mn</span><span class="p">[:,</span> <span class="p">[</span><span class="n">m_i</span><span class="p">]])</span>
            <span class="n">norm_vl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mn_i</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="o">.</span><span class="mi">000001</span>
            <span class="n">dist_i_scaled_sq</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(((</span><span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">col_ctrs</span><span class="p">[</span><span class="n">m_i</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="p">[</span><span class="n">m_i</span><span class="p">,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="o">.</span><span class="mi">001</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">weighted_dist_i</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">mn_i</span><span class="p">)</span><span class="o">/</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">norm_vl</span><span class="p">))</span><span class="o">*</span><span class="n">dist_i_scaled_sq</span>
            <span class="n">penalty</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weighted_dist_i</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_weight_pen</span> <span class="o">=</span> <span class="n">penalty</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># Penalize for scale</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">penalty</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_weight</span><span class="o">*</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scales</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_scale_pen</span> <span class="o">=</span> <span class="n">penalty</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_weight_pen</span>

        <span class="k">return</span> <span class="n">penalty</span></div>

<div class="viewcode-block" id="ColumnMeanClusterPenalizer.__str__"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.ColumnMeanClusterPenalizer.__str__">[docs]</a>    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Returns a string of the current state of the penalizer. &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;Weight penalty: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_weight_pen</span><span class="p">)</span> <span class="o">+</span>
                <span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> Scale penalty: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_scale_pen</span><span class="p">))</span></div></div>


<div class="viewcode-block" id="gen_columns_mean_cluster_penalizer"><a class="viewcode-back" href="../../../autoapi/janelia_core/ml/torch_distributions/index.html#janelia_core.ml.torch_distributions.gen_columns_mean_cluster_penalizer">[docs]</a><span class="k">def</span> <span class="nf">gen_columns_mean_cluster_penalizer</span><span class="p">(</span><span class="n">n_cols</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim_ranges</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">n_pts_per_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                                       <span class="n">n_ctrs_per_dim</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
                                       <span class="n">init_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">,</span>
                                       <span class="n">scale_weight</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
                                       <span class="n">penalizer_pts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ColumnMeanClusterPenalizer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot; Generates a columns mean cluster penalizer for a conditional distribution over matrices.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_cols: The number of columns in the matrices the conditional distribution is over.</span>

<span class="sd">        dim_ranges: dim_ranges[:,0] are the starting values for each dimension of the data the distribtion is</span>
<span class="sd">        conditioned on and dim_ranges[:,1] are the ending values</span>

<span class="sd">        n_ctrs_per_dim: When generating the initial center points, we will lay them out evenly on a grid.  This is</span>
<span class="sd">        the number of points on the grid in each dimension.</span>

<span class="sd">        n_pts_per_dim: The number of sample points to generate per dimension.  The final sample points will</span>
<span class="sd">        be a grid sampled at this many points per dimension within the range of dimensions specified by dim_ranges.</span>

<span class="sd">        init_scale: The value that for the initial scales of the penalizer for all modes and dimensions.</span>

<span class="sd">        scale_weight: The scale weight for the penalizer.</span>

<span class="sd">        penalizer_pts: A tensor of points to penalize at.  If None, one will be created based on dim_ranges and</span>
<span class="sd">        n_pts_per_dim.  Using this input is useful if creating multiple penalizers that all use the same penalizer</span>
<span class="sd">        points, so that they can all reference the same list of points and duplicate lists of poitns do not have to be</span>
<span class="sd">        created to save memory.</span>

<span class="sd">    Returns:</span>
<span class="sd">        p: The generated penalizer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Generate points we penalize at</span>
    <span class="k">if</span> <span class="n">penalizer_pts</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">penalizer_grid_limits</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">dim_ranges</span><span class="p">)</span>
        <span class="n">penalizer_grid_limits</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">penalizer_grid_limits</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="o">.</span><span class="mi">001</span>
        <span class="n">penalizer_grid_limits</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">penalizer_grid_limits</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="o">.</span><span class="mi">001</span>

        <span class="n">penalizer_n_grid_pts</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">n_pts_per_dim</span><span class="p">)</span>

        <span class="n">penalizer_pts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">list_grid_pts</span><span class="p">(</span><span class="n">grid_limits</span><span class="o">=</span><span class="n">penalizer_grid_limits</span><span class="p">,</span>
                                               <span class="n">n_pts_per_dim</span><span class="o">=</span><span class="n">penalizer_n_grid_pts</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="n">init_ctrs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">list_grid_pts</span><span class="p">(</span><span class="n">grid_limits</span><span class="o">=</span><span class="n">dim_ranges</span><span class="p">,</span> <span class="n">n_pts_per_dim</span><span class="o">=</span><span class="n">n_ctrs_per_dim</span><span class="p">))</span>

    <span class="c1"># Generate initial scales</span>
    <span class="n">init_scales</span> <span class="o">=</span> <span class="n">init_scale</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n_cols</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">ColumnMeanClusterPenalizer</span><span class="p">(</span><span class="n">init_ctrs</span><span class="o">=</span><span class="n">init_ctrs</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">penalizer_pts</span><span class="p">,</span> <span class="n">scale_weight</span><span class="o">=</span><span class="n">scale_weight</span><span class="p">,</span>
                                      <span class="n">init_scales</span><span class="o">=</span><span class="n">init_scales</span><span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, William Bishop.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>