:py:mod:`janelia_core.dataprocessing.baseline`
==============================================

.. py:module:: janelia_core.dataprocessing.baseline

.. autoapi-nested-parse::

   Tools for calculating baseline values for fluorescence data.



Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   janelia_core.dataprocessing.baseline.percentile_filter_1d
   janelia_core.dataprocessing.baseline.percentile_filter_multi_d
   janelia_core.dataprocessing.baseline._percentile_filter_arg_unpack
   janelia_core.dataprocessing.baseline.calculate_causal_percentile_baseline
   janelia_core.dataprocessing.baseline.calculate_causal_percentile_baselines



.. py:function:: percentile_filter_1d(data: numpy.ndarray, window_length: int, filter_start: int, write_offset: int, p: float, n_hist_bins: int = 1000) -> numpy.ndarray

   Performs percentile filtering for a single variable.

   This function uses a moving window to calculate percentiles.  The window is determined by two parameters:
   window_length and filter_start. Window_length is the number of data points in the window.

   The location in the data where filtering is started is determined by filter_start, which gives the
   index of the first value of data that should be in the window.  Negative filter_starts are acceptable
   to indicate a window which begins only partially overlapping the data.

   Finally, write_offset is the offset between the first sample in the window and the sample in the
   output the filtered value should be assigned to.

   Note that windows at the beginning and end of the data may only partially overlap the data.  In these
   cases, only values in the window will be used for calculating percentiles.

   Here are some examples.  To perform standard, acausal filtering with a window of size 101 set:

       window_length = 101

       filter_start = -50

       write_offset = 50

   To perform standard, causal filtering with a window of size 101 set:

       window_length = 101

       filter_start: 0

       write_offset = 100

   Diagram of window placement and parameters::

            Location of first window for filtering:

                       |--------------------|: Window length
                    t=0
                    |
              Data: XXX|XXXXXXXXXXXXXXXXXXXX|XXXX
                       ^                    ^
                       |                    |
                       filter start         window end

    Filtered Data:    |----------|: Write offset
                   YYY|YYYYYYYYYYYYYYYYYYYY|YYYY
                                 ^
                                 |
                     filtered value written here


   Args:

       data: an array of data.

       window_length: The length of samples in a window

       filter_start: The index into the data for the start of the first window.  Negative values indicate
       the first window only partially overlaps the data.

       write_offset: The offset between the first entry in a window and the sample in the output the filtered
       value is written to.

       p: The percentile to use in the baseline calculations.

       n_hist_bins: Percentiles are calculated using a histogram binning technique to improve computational
       efficiency.  This is the number of bins to use in the histogram between the min and max value in the data.

   Returns:

       y: The filtered data.  The same shape as one time point of data. Any points for which a percentile was not
       calculated will be nan.

   Raises:

       RuntimeError: If data with more than 2 dimensions is given as input data



.. py:function:: percentile_filter_multi_d(data: numpy.ndarray, window_length: int, filter_start: int, write_offset, p: float, mask: numpy.ndarray = None, n_processes: int = 1) -> numpy.ndarray

   Calculates baselines independently for each variable in the data across time.

   This function is a wrapper around percentile_filter_1d.  It adds the ability to filter in parellel on
   machines with multiple cores and to filter a restricted set of variabels in a volume, indicated by a mask.

   Args:
       data: an array of data.  First dimension is time.

       window_length, filter_start, write_offset, p: See percentile_filter

       mask: A boolean array the size of one time point of data.  Entries with a value of 1 indicate percentiles for
       that variable should be calculated.  If None, percentiles for all variables will be calculated.

       n_processes: The number of processes to use when calculating baselines.  When calculating baselines for many
       variables on machines with multiple cores, setting this greater than 1 can improve computation time.

   Returns:

       y: The filtered data.  The same shape as one time point of data.  If a mask was used so percentiles were not
       calculated for some variables, the percentiles for these variables will be nan.

   Raises:
       RuntimeError: If data with more than 2 dimensions is given as input data



.. py:function:: _percentile_filter_arg_unpack(kwargs)


.. py:function:: calculate_causal_percentile_baseline(data: numpy.ndarray, window_size: int, p: float, n_hist_bins: int = 1000) -> numpy.ndarray

   Calculates percentile based baseline in causal manner for one variable.

   The value baseline[i] is calculated as the p-th percentile in the window data[i-window_size+1:i+1].

   Values of baseline[0:window_size] = NAN.

   If data is all a constant value, the non-NAN values in the returned baseline will be that constant value.

   Args:
       data: a 1-d array of data

       window_size: The size of the window to use (units are number of samples)

       p: The percentile to use in the baseline calculations.  Must be in the range [0, 1)

       n_hist_bins: The number of bins to use when calculating histograms for the baseline calculations.

   Returns:
       baseline - an array the same shape as data giving the calculated baseline value at each point.



.. py:function:: calculate_causal_percentile_baselines(data: numpy.ndarray, window_size: int, p: float, n_hist_bins: int = 1000, n_processes=None) -> numpy.ndarray

   A wrapper function for calculating baseline values for multiple variables in parallel.

   This function wraps around calculate_causal_percentile_baseline, allowing a user to use multiple
   cores to calculate baselines in parallel.

   Args:
       data: An array or size time * (data_shape) with data to calculate baselines for.  Here data_shape is the shape
       of the data at each point in time.

       window_size: See calculate_causal_percentile_baseline()

       p: See calculate_causal_percentile_baseline()

       n_hist_bins: See calculate_causal_percentile_baseline()

       n_processes: The number of processes to use.  If none, this will be set to the number of processors on the
       machine.

   Returns:
       baselines - The baselines for the variables.  Will be the same shape as data.



