:py:mod:`janelia_core.ml.extra_torch_functions`
===============================================

.. py:module:: janelia_core.ml.extra_torch_functions

.. autoapi-nested-parse::

   Contains custom PyTorch functions.



Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   janelia_core.ml.extra_torch_functions.knn_do
   janelia_core.ml.extra_torch_functions.knn_mc
   janelia_core.ml.extra_torch_functions.log_cosh



Attributes
~~~~~~~~~~

.. autoapisummary::

   janelia_core.ml.extra_torch_functions.LOG_2


.. py:data:: LOG_2
   

   The value log(2) as a torch tensor.

.. py:function:: knn_do(x: torch.Tensor, ctrs: torch.Tensor, k: int, m: int, n_ctrs_used: int) -> torch.Tensor

   Searches for the k nearest centers to each point in a set of data, applying dropout to centers.

   This function wraps around knn_mc, applying dropout to the centers.  By this, we mean that the function
   will first randomly select n_ctrs_used centers to use, and then it will only look for nearest neighbors
   among these centers.  Setting n_ctrs_used to the total number of centers results in no dropout.

   Args:
       x: The set of data.  We return centers closest to each point in x.  Of shape n_smps*d

       ctrs: The centers to search among.  Of shape n_ctrs*d

       k: The number of nearest neighbors to search for.

       m: The number of centers to process at a time in the call to knn_mc.  Larger values of m will enable faster
       computation on GPU but use more memory.

       n_ctrs_used: The number of centers to randomly select.

   Returns:
       indices: The indices of the nearest centers for each data point. indices[:,i] are the indices for x[i,:]



.. py:function:: knn_mc(x: torch.Tensor, ctrs: torch.Tensor, k: int, m: int) -> torch.Tensor

   Memory constrained version of knn function.

   In this implementation we search for the k nearest centers to each point in a set of data.

   We say it is memory constrained because we can limit the number of centers we search among at a time.  By
   looping through centers in blocks, we can limit the amount of memory used.  Specifically, for any given block, we
   use broadcasting to enable fast calculations, which uses O(n_ctrs*n_data_points) amount of memory, so by limiting
   the number of centers we search through at once, we can limit memory usage.  A post-processing step at the end
   of each loop keeps track of the k-nearest centers seen up until that point in time to each data point.

   Args:
       x: The set of data.  We return centers closest to each point in x.  Of shape n_smps*d

       ctrs: The centers to search among.  Of shape n_ctrs*d

       k: The number of nearest neighbors to search for.

       m: The number of centers to process at a time.  Larger values of m will enable faster computation on GPU but use
       more memory.

   Returns:
       indices: The indices of the nearest centers for each data point. indices[:,i] are the indices for x[i,:]

   Raise:
       ValueError: If k is greater than the number of centers.


.. py:function:: log_cosh(x: torch.Tensor) -> torch.Tensor

   Computes log cosh(x) in a numerically stable way.

   Args:
       x: Input values

   Returns:
       y: Output values


