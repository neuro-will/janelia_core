{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.extra_torch_modules import Bias\n",
    "from janelia_core.ml.latent_regression import LatentRegModel\n",
    "from janelia_core.ml.latent_regression import LinearMap\n",
    "from janelia_core.ml.latent_regression import IdentityMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for model go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = [100000, 100000]\n",
    "d_out = [100000, 100000]\n",
    "\n",
    "d_proj = [2, 2]\n",
    "d_trans = [2, 2]\n",
    "\n",
    "n_smps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the model here\n",
    "n_output_groups = len(d_in)\n",
    "\n",
    "#M = LinearMap(d_proj, d_trans)\n",
    "M = IdentityMap()\n",
    "S = [Bias(d_o) for d_o in d_out]\n",
    "mdl = LatentRegModel(d_in, d_out, d_proj, d_trans, M, S, direct_pairs=None, w_gain=50, \n",
    "                    noise_range=[5.0, 10.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some x data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.randn([n_smps, d]) for d in d_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mdl(x)\n",
    "y = mdl.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_fitted = IdentityMap()\n",
    "#M_fitted = LinearMap(d_proj, d_trans)\n",
    "S_fitted = [Bias(d_o) for d_o in d_out]\n",
    "fitted_mdl = LatentRegModel(d_in, d_out, d_proj, d_trans, M_fitted, S_fitted, direct_pairs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move model to cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mdl=fitted_mdl.cuda()\n",
    "x = [x_i.pin_memory() for x_i in x]\n",
    "y = [y_i.pin_memory() for y_i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Elapsed fitting time 0.0, vl: 270558820.0, lr: 0.001\n",
      "1000: Elapsed fitting time 73.83841872215271, vl: 62343080.0, lr: 0.001\n",
      "2000: Elapsed fitting time 144.23129653930664, vl: 33904956.0, lr: 0.001\n",
      "3000: Elapsed fitting time 214.32604789733887, vl: 11670952.0, lr: 0.001\n",
      "4000: Elapsed fitting time 283.36871576309204, vl: 4858177.5, lr: 0.001\n",
      "5000: Elapsed fitting time 354.6586682796478, vl: 4859257.5, lr: 0.001\n",
      "6000: Elapsed fitting time 424.3720681667328, vl: 3494480.8, lr: 0.001\n",
      "7000: Elapsed fitting time 493.31621646881104, vl: 3569555.2, lr: 0.001\n",
      "8000: Elapsed fitting time 561.1847276687622, vl: 3108593.2, lr: 0.001\n",
      "9000: Elapsed fitting time 629.228794336319, vl: 2456560.8, lr: 0.001\n",
      "10000: Elapsed fitting time 699.0594162940979, vl: 1770930.9, lr: 0.001\n",
      "11000: Elapsed fitting time 768.0774261951447, vl: 1655595.2, lr: 0.001\n",
      "12000: Elapsed fitting time 837.0835249423981, vl: 1211581.0, lr: 0.001\n",
      "13000: Elapsed fitting time 907.0052354335785, vl: 1069917.5, lr: 0.001\n"
     ]
    }
   ],
   "source": [
    "log = fitted_mdl.fit(x, y, max_its=50000, batch_size=10, send_size=10, update_int=1000, min_var = .01,\n",
    "                     learning_rates=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.figure()\n",
    "plt.plot(log['elapsed_time'], log['obj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare predictions from fitted model to ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mdl = fitted_mdl.to('cpu')\n",
    "x = [x_g.to('cpu') for x_g in x]\n",
    "y = [y_h.to('cpu') for y_h in y]\n",
    "\n",
    "plt_smps = np.arange(1000)\n",
    "\n",
    "%matplotlib qt\n",
    "true_y_hat = mdl(x)\n",
    "fitted_y_hat = fitted_mdl(x)\n",
    "\n",
    "for g in range(n_output_groups):\n",
    "    plt.figure()\n",
    "    for d in range(5):\n",
    "        plt.subplot(1, 5, d+1)\n",
    "        true_obs_values = y[g][plt_smps, d].detach().numpy()\n",
    "        true_plt_values = true_y_hat[g][plt_smps, d].detach().numpy()\n",
    "        fitted_plt_values = fitted_y_hat[g][plt_smps, d].detach().numpy()\n",
    "        plt.plot(true_plt_values, 'go')\n",
    "        plt.plot(true_plt_values, 'ro')\n",
    "        plt.plot(fitted_plt_values, 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
