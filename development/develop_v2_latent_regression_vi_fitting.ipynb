{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook for development and testing of code for the second version of fitting latent regression models across multiple subjects with variational inference.  The main advance in version 2.0 of the code is the ability to support distributions across additional model parameters (not just the modes). \n",
    "\n",
    "In particular we generate models of how one neural population drives another as follows:\n",
    "\n",
    "1) The user specified a number of subjects and how many neurons are in each population for each of those subjects. Neuron locations for each subject are than randomly drawn from a uniform distribution on the unit square. \n",
    "\n",
    "2) Our models include only neural dynamics (no stimulus input or behavioral output) and we use an identity mapping in \n",
    "the low d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.datasets import TimeSeriesDataset\n",
    "from janelia_core.ml.latent_regression.group_maps import IdentityMap\n",
    "from janelia_core.ml.latent_regression.subject_models import LatentRegModel\n",
    "from janelia_core.ml.latent_regression.vi import PriorCollection\n",
    "from janelia_core.ml.latent_regression.vi import SubjectVICollection\n",
    "from janelia_core.ml.torch_distributions import CondGaussianDistribution\n",
    "from janelia_core.ml.torch_distributions import CondMatrixHypercubePrior\n",
    "from janelia_core.ml.torch_distributions import CondMatrixProductDistribution\n",
    "from janelia_core.ml.torch_distributions import MatrixGaussianProductDistribution\n",
    "from janelia_core.ml.utils import torch_mod_to_fcn\n",
    "from janelia_core.visualization.image_visualization import visualize_2d_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and model specification goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we specify the number of subjects (by the length of the list) and number of neurons that will be present\n",
    "# each population for each subject\n",
    "\n",
    "n_subj_neurons = [(1000, 1100),\n",
    "                  (900, 910),\n",
    "                  (1100, 700)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for creating hypercube functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_fcn_params = {'n_divisions_per_dim': [1000, 1000], \n",
    "                 'dim_ranges': np.asarray([[0, 1.0], [0, 1.0]]), \n",
    "                 'n_div_per_hc_side_per_dim': [1, 1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we specify the mean and standard deviation functions for the different parameters of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp2d(torch.nn.Module):\n",
    "    def __init__(self, ctr, std, gain, offset):\n",
    "        #assert(ctr.shape == [1, 2])\n",
    "        #assert(std.shape == [1,2])\n",
    "        \n",
    "        super().__init__()\n",
    "        self.ctr = torch.nn.Parameter(ctr)\n",
    "        self.std = torch.nn.Parameter(std)\n",
    "        self.gain = torch.nn.Parameter(gain)\n",
    "        self.offset = torch.nn.Parameter(offset)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return (self.gain*torch.exp(-1*torch.sum((x - self.ctr)**2/self.std, dim=1)) + self.offset).unsqueeze(1)  \n",
    "\n",
    "class constantF(torch.nn.Module):\n",
    "    def __init__(self, vl):\n",
    "        super().__init__()\n",
    "        self.vl = vl\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vl*torch.ones([x.shape[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the distributions over p and u modes\n",
    "\n",
    "Here we implicitly define the number of modes by the number of distributions we define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ctrs = [torch.tensor([.25, .25]), torch.tensor([.75, .75])]\n",
    "true_p_dists = CondMatrixProductDistribution([CondGaussianDistribution(mn_f=exp2d(ctr = c, \n",
    "                                                                                  std = torch.tensor([1.0, 1.0]),\n",
    "                                                                                  gain = torch.tensor(2.0), \n",
    "                                                                                  offset = torch.tensor(1.0)),\n",
    "                                                                        std_f=constantF(.1)) \n",
    "                                              for c in p_ctrs])\n",
    "\n",
    "\n",
    " \n",
    "u_ctrs = [torch.tensor([.25, .25]), torch.tensor([.75, .75])]\n",
    "true_u_dists = CondMatrixProductDistribution([CondGaussianDistribution(mn_f=exp2d(ctr = c, \n",
    "                                                                                  std = torch.tensor([1.0, 1.0]),\n",
    "                                                                                  gain = torch.tensor(2.0), \n",
    "                                                                                  offset = torch.tensor(1.0)),\n",
    "                                                                        std_f=constantF(.1)) \n",
    "                                              for c in u_ctrs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the distributions over scales and offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scale_dist = CondGaussianDistribution(mn_f=exp2d(ctr = torch.tensor([.5, .5]), \n",
    "                                                    std = torch.tensor([6.0, 6.0]),\n",
    "                                                    gain = torch.tensor(1.0), \n",
    "                                                    offset = torch.tensor(0.0)),\n",
    "                                        std_f=constantF(.1))\n",
    "\n",
    "true_offset_dist = CondGaussianDistribution(mn_f=exp2d(ctr = torch.tensor([.5, .5]), \n",
    "                                                    std = torch.tensor([6.0, 6.0]),\n",
    "                                                    gain = torch.tensor(.1), \n",
    "                                                    offset = torch.tensor(0.0)),\n",
    "                                        std_f=constantF(.1))\n",
    "\n",
    "true_psi_dist = CondGaussianDistribution(mn_f=exp2d(ctr = torch.tensor([.5, .5]), \n",
    "                                                    std = torch.tensor([6.0, 6.0]),\n",
    "                                                    gain = torch.tensor(.2), \n",
    "                                                    offset = torch.tensor(.1)),\n",
    "                                        std_f=constantF(.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we generate our true subject models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = len(true_p_dists.dists)\n",
    "n_subjs = len(n_subj_neurons)\n",
    "true_subj_models = [None]*n_subjs\n",
    "true_data = [None]*n_subjs\n",
    "\n",
    "for s_i in range(n_subjs):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate neuron locations\n",
    "        p_neuron_locs = torch.rand(size=[n_subj_neurons[s_i][0], 2])\n",
    "        u_neuron_locs = torch.rand(size=[n_subj_neurons[s_i][1], 2])\n",
    "    \n",
    "        # Generate modes\n",
    "        p_modes = true_p_dists.form_standard_sample(true_p_dists.sample(p_neuron_locs))\n",
    "        u_modes = true_u_dists.form_standard_sample(true_u_dists.sample(u_neuron_locs))\n",
    "        \n",
    "        # Generate scales and offsets\n",
    "        scales = true_scale_dist.form_standard_sample(true_scale_dist.sample(u_neuron_locs)).squeeze()\n",
    "        offsets = true_offset_dist.form_standard_sample(true_offset_dist.sample(u_neuron_locs)).squeeze()\n",
    "        \n",
    "        # Generate psi\n",
    "        psi = true_psi_dist.form_standard_sample(true_psi_dist.sample(u_neuron_locs)).squeeze()\n",
    "        assert(torch.all(psi > 0))\n",
    "    \n",
    "        s_mdl = LatentRegModel(d_in = [n_subj_neurons[s_i][0]], d_out = [n_subj_neurons[s_i][1]], \n",
    "                               d_proj=[n_modes], d_trans=[n_modes], \n",
    "                               m=IdentityMap(),\n",
    "                               s=[torch.nn.Identity()], \n",
    "                               use_scales=True,\n",
    "                               use_offsets=True)\n",
    "    \n",
    "        s_mdl.p[0].data = p_modes\n",
    "        s_mdl.u[0].data = u_modes\n",
    "        s_mdl.offsets[0].data = offsets\n",
    "        s_mdl.scales[0].data = scales\n",
    "        s_mdl.psi[0].data = psi\n",
    "    \n",
    "        true_subj_models[s_i] = {'mdl': s_mdl, 'p_neuron_locs': p_neuron_locs, 'u_neuron_locs': u_neuron_locs}\n",
    "    \n",
    "        \n",
    "        u_data = [torch.randn(size=[2000, n_subj_neurons[s_i][0]])]\n",
    "        p_data = s_mdl.generate(u_data)\n",
    "        \n",
    "        true_data[s_i] = (u_data, p_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we set things up for fitting with variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_prior = CondMatrixHypercubePrior(n_cols=n_modes, mn_hc_params=hc_fcn_params, std_hc_params=hc_fcn_params, \n",
    "                                   min_std=.00001)\n",
    "\n",
    "u_prior = CondMatrixHypercubePrior(n_cols=n_modes, mn_hc_params=hc_fcn_params, std_hc_params=hc_fcn_params, \n",
    "                                   min_std=.00001)\n",
    "\n",
    "scales_prior = CondMatrixHypercubePrior(n_cols=1, mn_hc_params=hc_fcn_params, std_hc_params=hc_fcn_params, \n",
    "                                   min_std=.00001, mn_init=1.0)\n",
    "\n",
    "offsets_prior = CondMatrixHypercubePrior(n_cols=1, mn_hc_params=hc_fcn_params, std_hc_params=hc_fcn_params, \n",
    "                                   min_std=.00001, mn_init=0.0)\n",
    "\n",
    "prior_collection = PriorCollection(p_dists=[p_prior], u_dists=[u_prior], psi_dists=[None], \n",
    "                                   scale_dists=[scales_prior], offset_dists=[offsets_prior])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define subject models and posteriors for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_i in range(n_subjs):\n",
    "    \n",
    "    # Create subject model for fitting\n",
    "    s_mdl = LatentRegModel(d_in = [n_subj_neurons[s_i][0]], d_out = [n_subj_neurons[s_i][1]], \n",
    "                           d_proj=[n_modes], d_trans=[n_modes], m=IdentityMap(), s=[torch.nn.Identity()],\n",
    "                           assign_p_modes=False, assign_u_modes=False, assign_scales=False, assign_offsets=False,\n",
    "                           assign_psi=True) # We will fit point estimates for psi (and not distributions)\n",
    "    \n",
    "    # Create posterior distributions\n",
    "    p_post = MatrixGaussianProductDistribution(shape=[n_subj_neurons[s_i][0], n_modes], mn_mn=.01, mn_std=.001)\n",
    "    u_post = MatrixGaussianProductDistribution(shape=[n_subj_neurons[s_i][1], n_modes], mn_mn=.01, mn_std=.001)\n",
    "    scale_post = MatrixGaussianProductDistribution(shape=[n_subj_neurons[s_i][1], 1], mn_mn=1.0, mn_std=.001)\n",
    "    offset_post = MatrixGaussianProductDistribution(shape=[n_subj_neurons[s_i][1], 1], mn_mn=0.0, mn_std=.001)\n",
    "    \n",
    "    # Package data\n",
    "    data = TimeSeriesDataset([true_data[s_i][0][0], true_data[s_i][1][0]])[:]\n",
    "    \n",
    "    vi_collection = SubjectVICollection(s_mdl=s_mdl, p_dists=[p_post], u_dists=[u_post], psi_dists=[None],\n",
    "                                        scale_dists=[scale_post], offset_dists=[offset_post],\n",
    "                                        data=data, input_grps=[0], output_grps=[1], \n",
    "                                        props=[true_subj_models[s_i]['p_neuron_locs'], \n",
    "                                               true_subj_models[s_i]['u_neuron_locs']],\n",
    "                                        p_props = [0], u_props=[1], psi_props=[None], \n",
    "                                        scale_props=[1], offset_props=[1], min_var=[.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_collection.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
