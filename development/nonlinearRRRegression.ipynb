{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code demonstrating basic non-linear reduced rank regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.non_linear_rr_regression import NonLinearRRRegresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ground truth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in, d_out, d_latent, n_smps = 10, 1, 5, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model = NonLinearRRRegresion(d_in, d_out, d_latent)\n",
    "true_model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 10*torch.rand([n_smps, d_in])\n",
    "y = true_model.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model we will fit to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = NonLinearRRRegresion(d_in, d_out, d_latent)\n",
    "fitted_model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(fitted_model.parameters(), lr=.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: tensor(676.7207, grad_fn=<ThAddBackward>)\n",
      "10000: tensor(-1997.0679, grad_fn=<ThAddBackward>)\n",
      "20000: tensor(-1997.1992, grad_fn=<ThAddBackward>)\n",
      "30000: tensor(-1997.4355, grad_fn=<ThAddBackward>)\n",
      "40000: tensor(-1997.6963, grad_fn=<ThAddBackward>)\n",
      "50000: tensor(-1997.9697, grad_fn=<ThAddBackward>)\n",
      "60000: tensor(-1998.2139, grad_fn=<ThAddBackward>)\n",
      "70000: tensor(-1998.3999, grad_fn=<ThAddBackward>)\n",
      "80000: tensor(-1998.5483, grad_fn=<ThAddBackward>)\n",
      "90000: tensor(-1998.6914, grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    mns = fitted_model(x.data)\n",
    "    nll = fitted_model.neg_log_likelihood(y.data, mns)\n",
    "    nll.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10000 == 0: \n",
    "        print(str(i) + ': ' + str(nll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_model.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(true_model.v.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True:[[ 1.2590263  -1.2053972   1.0192255  -0.07308094 -0.26994985]\n",
      " [-0.27447778 -0.66325015 -0.7861464   0.31014583  1.5234082 ]\n",
      " [ 2.3829527   0.25622398  2.7640421   0.83891886  0.93794334]\n",
      " [-0.3133924  -0.02407174  0.48695427 -0.5916968  -0.58193713]\n",
      " [ 0.34021762 -2.0596166   1.6914777   0.715947    0.99405986]\n",
      " [-0.06310934  0.7603012  -1.1970751  -1.4510733  -1.3762658 ]\n",
      " [ 0.74086326 -0.85661495 -0.4107939   0.3653844  -0.0554444 ]\n",
      " [ 1.0266626  -0.2076049   0.16687714 -0.64381164  1.6740636 ]\n",
      " [ 0.4389416   0.22841504 -1.7320949  -0.918125   -0.11705229]\n",
      " [-0.09034348 -1.3651582  -1.3821507   0.19972941  0.12244542]]\n",
      "Estimated:[[ 0.11375403 -0.8313391  -0.443484   -0.31506518  0.4224595 ]\n",
      " [-0.18684912  0.42683733 -0.55218244 -0.17781012 -0.9466747 ]\n",
      " [ 0.57588804  0.16899127 -0.16189727  0.3720263   0.45424137]\n",
      " [-2.5420985  -0.10009155 -1.2288768   0.9684696   0.5528205 ]\n",
      " [ 1.2885051  -0.149726   -0.8331857  -0.41344592 -1.0360056 ]\n",
      " [ 0.94741935 -0.92330265  0.23068245 -1.7658409  -0.15574302]\n",
      " [ 0.44624314  0.67140627 -0.17246982  0.16674711 -1.4455174 ]\n",
      " [ 1.0582652  -1.2882584   0.36547238  0.8080257  -0.6408623 ]\n",
      " [ 0.5389028   0.3200463   0.17565575  1.6802882  -0.09906998]\n",
      " [-0.8323169   1.6795905  -0.27863     0.04378409  1.7121569 ]]\n"
     ]
    }
   ],
   "source": [
    "cmp_a = 'w0'\n",
    "\n",
    "true_p = getattr(true_model, cmp_a).detach().numpy()\n",
    "est_p = getattr(fitted_model, cmp_a).detach().numpy()\n",
    "\n",
    "print('True:' + str(true_p))\n",
    "print('Estimated:' + str(est_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.neg_log_likelihood(y.detach(), mns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.diag(true_model.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.from_numpy(np.asarray([2.0, 3, 4], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum((a**2)/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
