{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code demonstrating basic non-linear reduced rank regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.non_linear_rr_regression import NonLinearRRRegresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup ground truth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in, d_out, d_latent, n_smps = 5, 2, 1, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model = NonLinearRRRegresion(d_in, d_out, d_latent)\n",
    "true_model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3*torch.rand([n_smps, d_in])\n",
    "y = true_model.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model we will fit to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = NonLinearRRRegresion(d_in, d_out, d_latent)\n",
    "fitted_model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(fitted_model.parameters(), lr=.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: tensor(-596.9268, grad_fn=<ThAddBackward>)\n",
      "10000: tensor(-596.9265, grad_fn=<ThAddBackward>)\n",
      "20000: tensor(-596.9265, grad_fn=<ThAddBackward>)\n",
      "30000: tensor(-596.9264, grad_fn=<ThAddBackward>)\n",
      "40000: tensor(-596.9267, grad_fn=<ThAddBackward>)\n",
      "50000: tensor(-596.9263, grad_fn=<ThAddBackward>)\n",
      "60000: tensor(-596.9265, grad_fn=<ThAddBackward>)\n",
      "70000: tensor(-596.9265, grad_fn=<ThAddBackward>)\n",
      "80000: tensor(-596.9266, grad_fn=<ThAddBackward>)\n",
      "90000: tensor(-596.9266, grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    mns = fitted_model(x.data)\n",
    "    nll = fitted_model.neg_log_likelihood(y.data, mns)\n",
    "    nll.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10000 == 0: \n",
    "        print(str(i) + ': ' + str(nll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model.standardize()\n",
    "fitted_model.standardize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1590],\n",
       "        [-0.6123]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_model.o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_y_pred = fitted_model(x)\n",
    "true_y_pred = true_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "for i in range(d_out):\n",
    "    plt.plot(fitted_y_pred.detach().numpy()[:, i])\n",
    "    plt.plot(true_y_pred.detach().numpy()[:,i], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5213258, 2.5004637, 2.4576912, 2.4506242, 2.39124  , 2.4571948,\n",
       "       2.524058 , 2.5083914, 2.5068321, 2.5083055, 2.523325 , 2.5241075,\n",
       "       2.4992495, 2.5077837, 2.4875846, 2.433589 , 2.5199747, 2.5229208,\n",
       "       2.5186596, 2.4962378, 2.522494 , 2.5205393, 2.5138154, 2.5179913,\n",
       "       2.5214345, 2.521766 , 2.5154588, 2.5217237, 2.500745 , 2.5228767,\n",
       "       2.444665 , 2.5174341, 2.5151272, 2.523124 , 2.5184429, 2.41749  ,\n",
       "       2.518446 , 2.517745 , 2.5129542, 2.5240316, 2.5220778, 2.51514  ,\n",
       "       2.5020812, 2.5236766, 2.5240703, 2.5214515, 2.5225945, 2.3544936,\n",
       "       2.5129848, 2.5239315, 2.5193515, 2.5182672, 2.485341 , 2.517187 ,\n",
       "       2.5227256, 2.509751 , 2.5214734, 2.287788 , 2.5162997, 2.5240479,\n",
       "       2.5216334, 2.37201  , 2.4891155, 2.2969468, 2.488935 , 2.5217392,\n",
       "       2.4590187, 2.448059 , 2.4874482, 2.5232246, 2.5178142, 2.5207422,\n",
       "       2.5236647, 2.5197964, 2.5233173, 2.5236292, 2.4151235, 2.5233717,\n",
       "       2.5073595, 2.52051  , 2.3309822, 2.4420936, 2.4692626, 2.5197887,\n",
       "       2.5005512, 2.5154774, 2.3190687, 2.5161495, 2.5214546, 2.481745 ,\n",
       "       2.5162804, 2.5215461, 2.497205 , 2.5035238, 2.523413 , 2.5087602,\n",
       "       2.5150704, 2.5152671, 2.5235007, 2.5236876, 2.5229797, 2.4072533,\n",
       "       2.4101725, 2.4141963, 2.5235057, 2.5188966, 2.4077861, 2.5172064,\n",
       "       2.5055945, 2.438648 , 2.5234714, 2.3953109, 2.5235696, 2.4286969,\n",
       "       2.5239904, 2.5115662, 2.4300106, 2.5102627, 2.4970064, 2.5226195,\n",
       "       2.5214586, 2.523408 , 2.5198708, 2.5209677, 2.5186095, 2.4781246,\n",
       "       2.5220888, 2.4911456, 2.5237548, 2.3897016, 2.5220802, 2.5124156,\n",
       "       2.5034513, 2.5150418, 2.446438 , 2.5005994, 2.522178 , 2.506881 ,\n",
       "       2.5215037, 2.5178032, 2.5213244, 2.5225637, 2.3478591, 2.4915426,\n",
       "       2.3472612, 2.309139 , 2.5190763, 2.42945  , 2.5128624, 2.4250214,\n",
       "       2.522722 , 2.5223324, 2.5169291, 2.5191238, 2.501832 , 2.518055 ,\n",
       "       2.516231 , 2.5218902, 2.5081801, 2.5085719, 2.490726 , 2.4955423,\n",
       "       2.3720458, 2.5203161, 2.5088146, 2.5069962, 2.5230913, 2.5003219,\n",
       "       2.506809 , 2.5237641, 2.5074012, 2.5187912, 2.5200064, 2.5198765,\n",
       "       2.523335 , 2.3904364, 2.515106 , 2.5203588, 2.4940703, 2.4909596,\n",
       "       2.5098758, 2.5141187, 2.5039296, 2.5232892, 2.5092278, 2.519282 ,\n",
       "       2.4764926, 2.4907327, 2.3195372, 2.5201886, 2.4912202, 2.497749 ,\n",
       "       2.521779 , 2.5076709, 2.3018992, 2.469761 , 2.519254 , 2.5205472,\n",
       "       2.4802148, 2.4073238, 2.418718 , 2.5017207, 2.497404 , 2.5195756,\n",
       "       2.5076642, 2.5086055, 2.4669268, 2.4834743, 2.511816 , 2.523217 ,\n",
       "       2.4809573, 2.5229247, 2.368804 , 2.3789752, 2.3555782, 2.4998155,\n",
       "       2.5232425, 2.5239816, 2.5168943, 2.4767065, 2.5058742, 2.3742833,\n",
       "       2.516679 , 2.52069  , 2.5209892, 2.5059505, 2.4472961, 2.5141025,\n",
       "       2.4168663, 2.5075386, 2.511029 , 2.494756 , 2.522546 , 2.5240643,\n",
       "       2.5240169, 2.4458263, 2.5228775, 2.505802 , 2.3267837, 2.5138617,\n",
       "       2.4915597, 2.513603 , 2.521686 , 2.5159466, 2.4823766, 2.3398569,\n",
       "       2.4976926, 2.5123596, 2.4764829, 2.3819547, 2.5164359, 2.435729 ,\n",
       "       2.4786649, 2.514045 , 2.5123801, 2.333376 , 2.491001 , 2.512539 ,\n",
       "       2.5239491, 2.5017414, 2.3854098, 2.5110877, 2.4796212, 2.51604  ,\n",
       "       2.514049 , 2.2606812, 2.2193747, 2.4530127, 2.4961376, 2.4734633,\n",
       "       2.5116076, 2.5231624, 2.4888527, 2.418469 , 2.519208 , 2.520664 ,\n",
       "       2.5095718, 2.465347 , 2.4719765, 2.5100925, 2.5000434, 2.3653464,\n",
       "       2.445316 , 2.522926 , 2.521931 , 2.521793 , 2.5164566, 2.4986734,\n",
       "       2.5058708, 2.4426005, 2.3305862, 2.5203314, 2.3482876, 2.3875918,\n",
       "       2.521289 , 2.4671736, 2.521124 , 2.517386 , 2.5241842, 2.4324446,\n",
       "       2.503358 , 2.510399 , 2.5212154, 2.502542 , 2.5226305, 2.521907 ,\n",
       "       2.5219653, 2.5130033, 2.5186448, 2.5073729, 2.5102837, 2.5223048,\n",
       "       2.5223012, 2.5085826, 2.5232635, 2.520274 , 2.5233293, 2.524088 ,\n",
       "       2.5153708, 2.42141  , 2.5185554, 2.5009198, 2.5078094, 2.4188042,\n",
       "       2.5220318, 2.5120926, 2.5013819, 2.3955786, 2.4918718, 2.466631 ,\n",
       "       2.4894636, 2.5126724, 2.5235946, 2.5161815, 2.4470696, 2.5228398,\n",
       "       2.449761 , 2.4896293, 2.5234642, 2.4694822, 2.4714193, 2.520948 ,\n",
       "       2.229473 , 2.520755 , 2.4805565, 2.4472187, 2.5232887, 2.5089512,\n",
       "       2.46176  , 2.2349744, 2.5202997, 2.516736 , 2.516501 , 2.4930198,\n",
       "       2.285212 , 2.5236712, 2.5199046, 2.5079744, 2.5240161, 2.4702344,\n",
       "       2.4627352, 2.5229182, 2.4039347, 2.40667  , 2.260912 , 2.5211158,\n",
       "       2.515584 , 2.5230649, 2.491211 , 2.4484825, 2.522317 , 2.5211673,\n",
       "       2.5046206, 2.5006764, 2.523928 , 2.5154152, 2.524188 , 2.4955494,\n",
       "       2.5227869, 2.519446 , 2.5229487, 2.5214677, 2.4974027, 2.518284 ,\n",
       "       2.4689295, 2.411257 , 2.5004277, 2.4971235, 2.3408978, 2.4341156,\n",
       "       2.5159652, 2.5229433, 2.4935849, 2.5222957, 2.5218735, 2.37366  ,\n",
       "       2.4953442, 2.5210798, 2.4394822, 2.5171518, 2.5066125, 2.523789 ,\n",
       "       2.5218377, 2.4447494, 2.5223403, 2.4907606, 2.411778 , 2.500466 ,\n",
       "       2.4928963, 2.2970111, 2.4930978, 2.5073295, 2.3864062, 2.516624 ,\n",
       "       2.3973734, 2.5210612, 2.4978478, 2.5205925, 2.5240993, 2.5128264,\n",
       "       2.5170815, 2.5042243, 2.4713545, 2.511742 , 2.5185895, 2.5214295,\n",
       "       2.5146706, 2.5201647, 2.5225341, 2.4557428, 2.3889282, 2.5102184,\n",
       "       2.5089054, 2.522252 , 2.5216827, 2.5216043, 2.5240462, 2.5213394,\n",
       "       2.5032067, 2.5240507, 2.5189614, 2.5059984, 2.4331455, 2.5237164,\n",
       "       2.5231683, 2.4552047, 2.5209093, 2.518818 , 2.5238287, 2.5150318,\n",
       "       2.5235317, 2.4639997, 2.3945909, 2.5227382, 2.508144 , 2.4360995,\n",
       "       2.5206842, 2.5239825, 2.499488 , 2.510652 , 2.5097344, 2.3883512,\n",
       "       2.5160794, 2.5235333, 2.4860551, 2.4748168, 2.5189648, 2.4320536,\n",
       "       2.519821 , 2.4564438, 2.524144 , 2.466906 , 2.3149135, 2.5122526,\n",
       "       2.5080662, 2.5109947, 2.5028975, 2.4925022, 2.522131 , 2.522812 ,\n",
       "       2.51296  , 2.485205 , 2.521437 , 2.5193133, 2.5236979, 2.5132222,\n",
       "       2.395946 , 2.4391973, 2.5206544, 2.521082 , 2.5110965, 2.5225415,\n",
       "       2.4028163, 2.495505 , 2.4869745, 2.5152707, 2.518883 , 2.4780188,\n",
       "       2.5038953, 2.4137   , 2.5241191, 2.4497328, 2.35752  , 2.523447 ,\n",
       "       2.4742565, 2.490292 , 2.5117338, 2.5149515, 2.5009599, 2.520617 ,\n",
       "       2.5181205, 2.312207 , 2.4797485, 2.507567 , 2.4567177, 2.5235288,\n",
       "       2.5234392, 2.5230744, 2.3940337, 2.4336557, 2.509211 , 2.3860795,\n",
       "       2.513944 , 2.5032065, 2.4943395, 2.5173812, 2.5226707, 2.490663 ,\n",
       "       2.4981866, 2.522747 , 2.4846106, 2.5108278, 2.364916 , 2.5125709,\n",
       "       2.4660413, 2.488437 , 2.513249 , 2.5230675, 2.5212216, 2.514541 ,\n",
       "       2.5240703, 2.3003268, 2.5076027, 2.2473962, 2.4722397, 2.5208545,\n",
       "       2.486227 , 2.4953384, 2.5194385, 2.523526 , 2.5181353, 2.5226471,\n",
       "       2.517871 , 2.4849887, 2.496454 , 2.4765778, 2.5215669, 2.523159 ,\n",
       "       2.5106695, 2.5006962, 2.5238726, 2.5240612, 2.5067997, 2.254076 ,\n",
       "       2.2216532, 2.5217104, 2.521541 , 2.5172794, 2.5175195, 2.4548256,\n",
       "       2.398543 , 2.5227041, 2.52077  , 2.401971 , 2.522277 , 2.5238068,\n",
       "       2.5215476, 2.3834696, 2.4515803, 2.5235732, 2.5219815, 2.420319 ,\n",
       "       2.491696 , 2.5228388, 2.5122502, 2.4981651, 2.5147936, 2.5227172,\n",
       "       2.519628 , 2.5211208, 2.5230064, 2.4418983, 2.406654 , 2.516615 ,\n",
       "       2.5007734, 2.5135398, 2.5227463, 2.4956214, 2.4718635, 2.519088 ,\n",
       "       2.5112715, 2.5205398, 2.5145955, 2.4007194, 2.5139315, 2.5232263,\n",
       "       2.5172243, 2.5151184, 2.5230641, 2.501947 , 2.5225596, 2.5207467,\n",
       "       2.5182993, 2.4280934, 2.4777565, 2.522111 , 2.5208364, 2.3906763,\n",
       "       2.5233812, 2.5204663, 2.4585366, 2.5170686, 2.51751  , 2.4806948,\n",
       "       2.5096214, 2.4857225, 2.507051 , 2.5230472, 2.5232315, 2.5232925,\n",
       "       2.5227506, 2.5209875, 2.5015588, 2.4717002, 2.5226586, 2.5207481,\n",
       "       2.4975913, 2.4371486, 2.509141 , 2.5213532, 2.3375747, 2.523293 ,\n",
       "       2.490704 , 2.470974 , 2.51987  , 2.4784448, 2.5217857, 2.4092848,\n",
       "       2.4695013, 2.5206406, 2.3603442, 2.2549715, 2.5170982, 2.4641922,\n",
       "       2.517738 , 2.4163496, 2.5223818, 2.4943676, 2.5217018, 2.4416091,\n",
       "       2.4993086, 2.5221457, 2.5224407, 2.4992032, 2.411757 , 2.5004551,\n",
       "       2.5190432, 2.321404 , 2.511155 , 2.516777 , 2.4696424, 2.5069187,\n",
       "       2.4841585, 2.5226057, 2.5052183, 2.5001864, 2.5044632, 2.5232382,\n",
       "       2.497336 , 2.5226145, 2.523692 , 2.5190678, 2.5229225, 2.518923 ,\n",
       "       2.5115252, 2.4319065, 2.523132 , 2.5111206, 2.5203047, 2.5164473,\n",
       "       2.5187385, 2.5205817, 2.5012803, 2.5221825, 2.363647 , 2.523139 ,\n",
       "       2.5209243, 2.3959477, 2.4251935, 2.5183377, 2.517177 , 2.5189433,\n",
       "       2.517652 , 2.5230272, 2.3841002, 2.3007572, 2.27431  , 2.503119 ,\n",
       "       2.522884 , 2.5042741, 2.5168247, 2.4481118, 2.4830496, 2.4810982,\n",
       "       2.5148628, 2.478784 , 2.5002296, 2.5225525, 2.51922  , 2.5216846,\n",
       "       2.495358 , 2.521967 , 2.5200536, 2.5163457, 2.465986 , 2.3400857,\n",
       "       2.5157743, 2.5079443, 2.4698951, 2.5149517, 2.5108845, 2.5197065,\n",
       "       2.523368 , 2.5150375, 2.5033238, 2.2170196, 2.5232165, 2.523434 ,\n",
       "       2.411408 , 2.5140717, 2.3936496, 2.5224342, 2.5149693, 2.4387255,\n",
       "       2.5225902, 2.5028975, 2.5226595, 2.4758615, 2.44517  , 2.5217128,\n",
       "       2.519908 , 2.524037 , 2.2975092, 2.3465483, 2.5194068, 2.5232775,\n",
       "       2.4955308, 2.5176167, 2.5229118, 2.5169587, 2.5234141, 2.5219243,\n",
       "       2.4290085, 2.5151327, 2.5233555, 2.489095 , 2.3824325, 2.4561517,\n",
       "       2.4628634, 2.4967852, 2.4297495, 2.4374368, 2.516145 , 2.5210218,\n",
       "       2.3017428, 2.5099235, 2.5161343, 2.5155263, 2.3862464, 2.5241036,\n",
       "       2.502036 , 2.5144393, 2.5052261, 2.5202842, 2.5231977, 2.504384 ,\n",
       "       2.4899867, 2.5222378, 2.51583  , 2.5206103, 2.4567342, 2.5166888,\n",
       "       2.481368 , 2.501382 , 2.5237973, 2.5232606, 2.5160408, 2.5054343,\n",
       "       2.40894  , 2.5088053, 2.467183 , 2.51611  , 2.484087 , 2.4602902,\n",
       "       2.4228244, 2.5030124, 2.502628 , 2.5239534, 2.5117671, 2.51961  ,\n",
       "       2.5203483, 2.487541 , 2.522476 , 2.5153751, 2.5237548, 2.51729  ,\n",
       "       2.4076471, 2.5204933, 2.503992 , 2.5211036, 2.4491475, 2.5139654,\n",
       "       2.523097 , 2.5022116, 2.5193384, 2.3179798, 2.5149145, 2.3438036,\n",
       "       2.5152016, 2.5180247, 2.5234375, 2.5122144, 2.5184388, 2.421481 ,\n",
       "       2.5178084, 2.5136185, 2.3529122, 2.4518914, 2.225137 , 2.5233119,\n",
       "       2.4819186, 2.5133731, 2.5241237, 2.463956 , 2.524039 , 2.3966622,\n",
       "       2.1953433, 2.5000527, 2.438057 , 2.4864373, 2.4660606, 2.3885944,\n",
       "       2.4984736, 2.5222962, 2.5191898, 2.4608424, 2.5028   , 2.5232637,\n",
       "       2.484037 , 2.521701 , 2.4688137, 2.518019 , 2.511339 , 2.4167078,\n",
       "       2.4961226, 2.465011 , 2.5228293, 2.4701874, 2.4948218, 2.4623241,\n",
       "       2.5028975, 2.519243 , 2.4970362, 2.5195818, 2.5230713, 2.4906888,\n",
       "       2.52221  , 2.5236623, 2.5083506, 2.5151434, 2.5229957, 2.5196283,\n",
       "       2.5004978, 2.5187795, 2.4396586, 2.5125268, 2.5168872, 2.4709826,\n",
       "       2.5160909, 2.521042 , 2.5235064, 2.5211048, 2.5047748, 2.4733858,\n",
       "       2.4714534, 2.523201 , 2.51209  , 2.5211635, 2.522416 , 2.4984188,\n",
       "       2.5214624, 2.5159934, 2.5242205, 2.5073946, 2.522557 , 2.4621286,\n",
       "       2.5221841, 2.4727397, 2.512189 , 2.1990836, 2.5030942, 2.512417 ,\n",
       "       2.5177612, 2.5221274, 2.5091593, 2.5233057, 2.4946938, 2.5235868,\n",
       "       2.5133653, 2.5195346, 2.5064461, 2.5159848, 2.479959 , 2.519709 ,\n",
       "       2.4780335, 2.5201354, 2.2345293, 2.523931 , 2.5089638, 2.472574 ,\n",
       "       2.5223935, 2.5229049, 2.522152 , 2.521594 , 2.373623 , 2.5238338,\n",
       "       2.5218918, 2.479499 , 2.5202224, 2.5134084, 2.4699   , 2.5210361,\n",
       "       2.4467673, 2.428189 , 2.4873662, 2.5214837, 2.5185893, 2.3609397,\n",
       "       2.490099 , 2.5232852, 2.510386 , 2.5217159, 2.5218573, 2.2609634,\n",
       "       2.1999104, 2.4739087, 2.516879 , 2.47324  , 2.5220716, 2.5185847,\n",
       "       2.5193887, 2.5013087, 2.4999166, 2.481269 , 2.4771643, 2.522555 ,\n",
       "       2.4846048, 2.5233705, 2.4385376, 2.5190806, 2.5230465, 2.5193238,\n",
       "       2.4982593, 2.4818132, 2.2022285, 2.4235983, 2.5021758, 2.5023189,\n",
       "       2.5238044, 2.509846 , 2.5239086, 2.5215197, 2.522225 , 2.5234494,\n",
       "       2.52316  , 2.497232 , 2.50001  , 2.494095 , 2.5178337, 2.5228653,\n",
       "       2.509347 , 2.4677253, 2.3193047, 2.5232024, 2.5227628, 2.522428 ,\n",
       "       2.4616725, 2.438923 , 2.5121608, 2.400144 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.detach().numpy()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(fitted_model.w1, torch.t(fitted_model.w0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_model.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.5213258 , -0.599764  ],\n",
       "       [ 2.5004637 , -0.5994371 ],\n",
       "       [ 2.4576912 , -0.5944052 ],\n",
       "       ...,\n",
       "       [ 2.438923  , -0.5884206 ],\n",
       "       [ 2.5121608 , -0.59970623],\n",
       "       [ 2.400144  , -0.5603526 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
