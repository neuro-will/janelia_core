{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we develop code to fit latent regression models to data with priors on the projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.extra_torch_modules import Bias\n",
    "from janelia_core.ml.extra_torch_modules import ConstantBoundedFcn\n",
    "from janelia_core.ml.extra_torch_modules import IndSmpConstantBoundedFcn\n",
    "from janelia_core.ml.extra_torch_modules import IndSmpConstantRealFcn\n",
    "from janelia_core.ml.extra_torch_modules import LogGaussianBumpFcn\n",
    "\n",
    "from janelia_core.ml.latent_regression import GroupMatrixMultiply\n",
    "from janelia_core.ml.latent_regression import GroupScalarTransform\n",
    "from janelia_core.ml.latent_regression import LatentRegModel\n",
    "from janelia_core.ml.latent_regression import LinearMap\n",
    "from janelia_core.ml.latent_regression import IdentityMap\n",
    "from janelia_core.ml.latent_regression import vae_fit_latent_reg_model\n",
    "\n",
    "from janelia_core.ml.torch_distributions import CondBernoulliDistribution\n",
    "from janelia_core.ml.torch_distributions import CondGaussianDistribution\n",
    "from janelia_core.ml.torch_distributions import CondSpikeSlabDistribution\n",
    "\n",
    "from janelia_core.visualization.matrix_visualization import cmp_n_mats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = [1000]\n",
    "\n",
    "d_in = n_neurons\n",
    "d_out = n_neurons\n",
    "\n",
    "d_proj = [2]\n",
    "d_trans = [2]\n",
    "\n",
    "n_smps = 1000\n",
    "\n",
    "device = 'cuda' # Device to perform fitting on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mode_mean(d, x_range = [0.0, 1.0], y_range = [0.0, 1.0], n_points_per_side=100):\n",
    "\n",
    "    orig_device = next(d.parameters()).device\n",
    "    \n",
    "    d = d.to('cpu') # Make a copy of model on cpu\n",
    "    \n",
    "    grid = np.mgrid[x_range[0]:x_range[1]:n_points_per_side * 1j,\n",
    "           y_range[0]:y_range[1]:n_points_per_side * 1j]\n",
    "\n",
    "    grid_vec = np.stack([np.ravel(grid[0, :, :]), np.ravel(grid[1, :, :])]).transpose()\n",
    "    grid_vec = torch.from_numpy(grid_vec.astype('float32'))\n",
    "\n",
    "    mn_vec = d(grid_vec).detach().numpy()\n",
    "    mn_image = np.reshape(mn_vec, [n_points_per_side, n_points_per_side])\n",
    "    \n",
    "    plt.imshow(mn_image, extent=[x_range[0], x_range[1], y_range[0], y_range[1]], origin='lower')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    d = d.to(orig_device)\n",
    "\n",
    "def visualize_mode_pairs(d1, d2, x_range = [0.0, 1.0], y_range = [0.0, 1.0], n_points_per_side=100):\n",
    "      \n",
    "    n_modes = len(d1)    \n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for m_i in range(n_modes):\n",
    "            \n",
    "        # Plot d1 modes in top row\n",
    "        plt.subplot(2, n_modes, m_i+1)\n",
    "        visualize_mode_mean(d1[m_i], x_range=x_range, y_range=y_range, n_points_per_side=n_points_per_side)\n",
    "        \n",
    "        # Plot d2 modes in second row\n",
    "        plt.subplot(2, n_modes, m_i+1 + n_modes)\n",
    "        visualize_mode_mean(d2[m_i], x_range=x_range, y_range=y_range, n_points_per_side=n_points_per_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the true conditional priors on mode weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grps = len(n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike and slab modes\n",
    "\n",
    "n_prior_nodes = 20\n",
    "\n",
    "true_prior_p_dists = [None]*n_grps\n",
    "true_prior_u_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "\n",
    "    n_grp_modes = [d_proj[g], d_trans[g]]\n",
    "    for i in range(2):\n",
    "        # Iterate over p and u modes\n",
    "        n_cur_modes = n_grp_modes[i]\n",
    "        proj_mode_dists = [None]*n_cur_modes\n",
    "        for mode_i in range(n_cur_modes):\n",
    "            \n",
    "            spike_log_prob_fcn = LogGaussianBumpFcn(d_x=2, ctr_std_init=0.25, log_gain_init=-0.00001)\n",
    "            spike_d = CondBernoulliDistribution(spike_log_prob_fcn)\n",
    "            \n",
    "            slab_mn_fcn = torch.nn.Sequential(torch.nn.Linear(2,n_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_prior_nodes, n_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_prior_nodes,1))\n",
    "            slab_mn_fcn[4].weight.data = 10*slab_mn_fcn[4].weight.data\n",
    "            \n",
    "            slab_std_fcn = ConstantBoundedFcn(lower_bound=np.asarray([.001]), upper_bound=np.asarray([10]), \n",
    "                                        init_value=np.asarray(.01))\n",
    "            \n",
    "            slab_d = CondGaussianDistribution(mn_f=slab_mn_fcn, std_f=slab_std_fcn)\n",
    "     \n",
    "            proj_mode_dists[mode_i] = CondSpikeSlabDistribution(d=1, spike_d=spike_d, slab_d=slab_d)\n",
    "        \n",
    "        if i == 0:\n",
    "            true_prior_p_dists[g] = proj_mode_dists\n",
    "        else:\n",
    "            true_prior_u_dists[g] = proj_mode_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the true priors by group (so that distributions for p and u modes are together) for convenience\n",
    "true_prior_mode_dists = list(zip(true_prior_p_dists, true_prior_u_dists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the means of the true distributions on weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in range(n_grps):\n",
    "        visualize_mode_pairs(true_prior_p_dists[g], true_prior_u_dists[g])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate neuron properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_props = [torch.zeros(n_neurons[g], 2).uniform_() for g in range(n_grps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate true mode weights from the prior that was just defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_p = [None]*n_grps\n",
    "true_u = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    n_grp_modes = [d_proj[g], d_trans[g]]\n",
    "    \n",
    "    for i in range(2):\n",
    "        n_cur_modes = n_grp_modes[i]\n",
    "        mode_mat = torch.zeros(n_grp_neurons, n_cur_modes)\n",
    "        for mode_i in range(n_cur_modes):\n",
    "            mode_mat[:, mode_i] = true_prior_mode_dists[g][i][mode_i].form_standard_sample(\n",
    "                true_prior_mode_dists[g][i][mode_i].sample(neuron_props[g])).squeeze()\n",
    "        if i == 0:\n",
    "            # P modes\n",
    "            true_p[g] = mode_mat\n",
    "        else:\n",
    "            # U modes\n",
    "            true_u[g] = mode_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the true subject model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_groups = len(d_in)\n",
    "\n",
    "M = IdentityMap()\n",
    "S = [Bias(d_o) for d_o in d_out]\n",
    "mdl = LatentRegModel(d_in, d_out, d_proj, d_trans, M, S, direct_pairs=None, noise_range=[.25, .255])\n",
    "\n",
    "for g, p_g in enumerate(mdl.p):\n",
    "    p_g.data = true_p[g]\n",
    "for h, u_h in enumerate(mdl.u):\n",
    "    u_h.data = true_u[h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.randn([n_smps, d]) for d in d_in]\n",
    "y = mdl.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the subject model we will fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_f = IdentityMap() \n",
    "#m_f = GroupScalarTransform(d=d_proj)\n",
    "#m_f = GroupMatrixMultiply(d_in=d_proj, d_out=d_trans)\n",
    "s_f = [Bias(d_o) for d_o in d_out]\n",
    "subject_mdl_f = LatentRegModel(d_in, d_out, d_proj, d_trans, m_f, s_f, direct_pairs=None, assign_p_u=False)\n",
    "subject_mdl_f = subject_mdl_f.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the inference distribution (  $Q(l, r)$  ) that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_p_mode_dists = [None]*n_grps\n",
    "q_u_mode_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            n_grp_modes = d_proj[g]\n",
    "        else:\n",
    "            n_grp_modes = d_trans[g]\n",
    "    \n",
    "        q_dists = [None]*n_grp_modes\n",
    "        \n",
    "        for mode_i in range(n_grp_modes):\n",
    "            mn_f = IndSmpConstantRealFcn(n_grp_neurons, init_value=.01)\n",
    "            std_f = IndSmpConstantBoundedFcn(n_grp_neurons, lower_bound=.0001, upper_bound=10.0, init_value=.2)\n",
    "            q_dists[mode_i] = CondGaussianDistribution(mn_f=mn_f, std_f=std_f)\n",
    "            q_dists[mode_i] = q_dists[mode_i].to(device)\n",
    "        \n",
    "        if i == 0:\n",
    "            q_p_mode_dists[g] = q_dists\n",
    "        else:\n",
    "            q_u_mode_dists[g] = q_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the conditional prior distribution (  $P(l,r|m)$  ) we will fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpModule(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.exp(x) + .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fit_prior_nodes = 100\n",
    "n_fit_std_prior_nodes = 100\n",
    "\n",
    "prior_p_dists = [None]*n_grps\n",
    "prior_u_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            n_grp_modes = d_proj[g]\n",
    "        else:\n",
    "            n_grp_modes = d_trans[g]\n",
    "            \n",
    "        prior_dists = [None]*n_grp_modes\n",
    "        \n",
    "        for mode_i in range(n_grp_modes):\n",
    "            mn_fcn = torch.nn.Sequential(torch.nn.Linear(2,n_fit_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_fit_prior_nodes, n_fit_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_fit_prior_nodes,1))\n",
    "            mn_fcn[4].weight.data = 50*mn_fcn[4].weight.data\n",
    "            \n",
    "            #std_fcn = torch.nn.Sequential(torch.nn.Linear(2,n_fit_std_prior_nodes), torch.nn.ReLU(), \n",
    "            #                                  torch.nn.Linear(n_fit_std_prior_nodes, n_fit_std_prior_nodes), torch.nn.ReLU(), \n",
    "             #                                 torch.nn.Linear(n_fit_std_prior_nodes,1), ExpModule())\n",
    "            \n",
    "            std_fcn = ConstantBoundedFcn(lower_bound=np.asarray([.001]), upper_bound=np.asarray([10]), \n",
    "                                        init_value=np.asarray(.01))\n",
    "            \n",
    "            prior_dists[mode_i] = CondGaussianDistribution(mn_f=mn_fcn, std_f=std_fcn)\n",
    "            prior_dists[mode_i] = prior_dists[mode_i].to(device)\n",
    "        \n",
    "        if i == 0:\n",
    "            prior_p_dists[g] = prior_dists\n",
    "        else:\n",
    "            prior_u_dists[g] = prior_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send data to device (if it is small enough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_smps <= 1000:\n",
    "    x = [x_g.to(device) for x_g in x]\n",
    "    y = [y_h.to(device) for y_h in y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit everything with variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = vae_fit_latent_reg_model(l_mdl = subject_mdl_f, q_p_dists=q_p_mode_dists, q_u_dists=q_u_mode_dists, \n",
    "                             prior_p_dists=prior_p_dists, prior_u_dists=prior_u_dists, learning_rates = .02,\n",
    "                             x=x, y=y, x_props=neuron_props, batch_size = 1000, send_size = 1000, update_int=200, \n",
    "                             max_its=3000, min_var=.00001, fit_priors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['elapsed_time'], log['elbo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_g = 0\n",
    "\n",
    "true_w = torch.matmul(true_u[vis_g], true_p[vis_g].t()).detach().numpy()\n",
    "\n",
    "est_p = [d.sample(neuron_props[vis_g]) for d in q_p_mode_dists[vis_g]]\n",
    "est_p = torch.cat(est_p, dim=1)\n",
    "#esp_p = torch.matmul(est_p, m_f.w[vis_g])\n",
    "#est_p = est_p*m_f.v[vis_g]\n",
    "\n",
    "est_u = [d.sample(neuron_props[vis_g]) for d in q_u_mode_dists[vis_g]]\n",
    "est_u = torch.cat(est_u, dim=1)\n",
    "\n",
    "est_w = torch.matmul(est_u, est_p.t()).detach().cpu().numpy()\n",
    "\n",
    "cmp_n_mats([true_w, est_w, true_w-est_w], show_colorbars=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_g = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mode_pairs(true_prior_p_dists[vis_g], prior_p_dists[vis_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mode_pairs(true_prior_u_dists[vis_g], prior_u_dists[vis_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_f.v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1.0, 2], [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([1.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
