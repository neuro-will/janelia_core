{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we develop code to fit latent regression models to data with priors on the projection matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from janelia_core.ml.extra_torch_modules import Bias\n",
    "from janelia_core.ml.extra_torch_modules import ConstantBoundedFcn\n",
    "from janelia_core.ml.extra_torch_modules import IndSmpConstantBoundedFcn\n",
    "from janelia_core.ml.extra_torch_modules import IndSmpConstantRealFcn\n",
    "from janelia_core.ml.extra_torch_modules import LogGaussianBumpFcn\n",
    "\n",
    "from janelia_core.ml.latent_regression import LatentRegModel\n",
    "from janelia_core.ml.latent_regression import LinearMap\n",
    "from janelia_core.ml.latent_regression import IdentityMap\n",
    "from janelia_core.ml.latent_regression import vae_fit_latent_reg_model\n",
    "\n",
    "from janelia_core.ml.torch_distributions import CondBernoulliDistribution\n",
    "from janelia_core.ml.torch_distributions import CondGaussianDistribution\n",
    "from janelia_core.ml.torch_distributions import CondSpikeSlabDistribution\n",
    "\n",
    "from janelia_core.visualization.matrix_visualization import cmp_n_mats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = [100, 120]\n",
    "\n",
    "d_in = n_neurons\n",
    "d_out = n_neurons\n",
    "\n",
    "d_proj = [2, 2]\n",
    "d_trans = [2, 2]\n",
    "\n",
    "n_smps = 1000\n",
    "\n",
    "device = 'cuda' # Device to perform fitting on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mode_mean(d, x_range = [0.0, 1.0], y_range = [0.0, 1.0], n_points_per_side=100):\n",
    "\n",
    "    orig_device = d.device\n",
    "    \n",
    "    d = d.to('cpu') # Make a copy of model on cpu\n",
    "    \n",
    "    grid = np.mgrid[x_range[0]:x_range[1]:n_points_per_side * 1j,\n",
    "           y_range[0]:y_range[1]:n_points_per_side * 1j]\n",
    "\n",
    "    grid_vec = np.stack([np.ravel(grid[0, :, :]), np.ravel(grid[1, :, :])]).transpose()\n",
    "    grid_vec = torch.from_numpy(grid_vec.astype('float32'))\n",
    "\n",
    "    mn_vec = d(grid_vec).detach().numpy()\n",
    "    mn_image = np.reshape(mn_vec, [n_points_per_side, n_points_per_side])\n",
    "    \n",
    "    plt.imshow(mn_image, extent=[x_range[0], x_range[1], y_range[0], y_range[1]], origin='lower')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    d = d.to(orig_device)\n",
    "\n",
    "def visualize_mode_pairs(d1, d2, x_range = [0.0, 1.0], y_range = [0.0, 1.0], n_points_per_side=100):\n",
    "      \n",
    "    n_modes = len(d1)    \n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for m_i in range(n_modes):\n",
    "            \n",
    "        # Plot d1 modes in top row\n",
    "        plt.subplot(2, n_modes, m_i+1)\n",
    "        visualize_mode_mean(d1[m_i], x_range=x_range, y_range=y_range, n_points_per_side=n_points_per_side)\n",
    "        \n",
    "        # Plot d2 modes in second row\n",
    "        plt.subplot(2, n_modes, m_i+1 + n_modes)\n",
    "        visualize_mode_mean(d2[m_i], x_range=x_range, y_range=y_range, n_points_per_side=n_points_per_side)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the true conditional priors on mode weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grps = len(n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bishopw\\documents\\research\\projects\\janelia_core\\janelia_core\\ml\\extra_torch_modules.py:64: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  init_v = np.arctanh(2*(init_value - lower_bound)/(upper_bound - lower_bound) - 1)\n"
     ]
    }
   ],
   "source": [
    "# Spike and slab modes\n",
    "\n",
    "n_prior_nodes = 20\n",
    "\n",
    "true_prior_p_dists = [None]*n_grps\n",
    "true_prior_u_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "\n",
    "    n_grp_modes = [d_proj[g], d_trans[g]]\n",
    "    for i in range(2):\n",
    "        # Iterate over p and u modes\n",
    "        n_cur_modes = n_grp_modes[i]\n",
    "        proj_mode_dists = [None]*n_cur_modes\n",
    "        for mode_i in range(n_cur_modes):\n",
    "            \n",
    "            spike_log_prob_fcn = LogGaussianBumpFcn(d_x=2, ctr_std_init=0.25, log_gain_init=0.0)\n",
    "            spike_d = CondBernoulliDistribution(spike_log_prob_fcn)\n",
    "            \n",
    "            slab_mn_fcn = torch.nn.Sequential(torch.nn.Linear(2,n_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_prior_nodes, n_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_prior_nodes,1))\n",
    "            slab_mn_fcn[4].weight.data = 10*slab_mn_fcn[4].weight.data\n",
    "            \n",
    "            slab_std_fcn = ConstantBoundedFcn(lower_bound=np.asarray([.001]), upper_bound=np.asarray([10]), \n",
    "                                        init_value=np.asarray(.01))\n",
    "            \n",
    "            slab_d = CondGaussianDistribution(mn_f=slab_mn_fcn, std_f=slab_std_fcn)\n",
    "    \n",
    "            proj_mode_dists[mode_i] = CondSpikeSlabDistribution(d=1, spike_d=spike_d, slab_d=slab_d)\n",
    "        \n",
    "        if i == 0:\n",
    "            true_prior_p_dists[g] = proj_mode_dists\n",
    "        else:\n",
    "            true_prior_u_dists[g] = proj_mode_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the true priors by group (so that distributions for p and u modes are together) for convenience\n",
    "true_prior_mode_dists = list(zip(true_prior_p_dists, true_prior_u_dists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate neuron properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_props = [torch.zeros(n_neurons[g], 2).uniform_() for g in range(n_grps)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate true mode weights from the prior that was just defined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_p = [None]*n_grps\n",
    "true_u = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    n_grp_modes = [d_proj[g], d_trans[g]]\n",
    "    \n",
    "    for i in range(2):\n",
    "        n_cur_modes = n_grp_modes[i]\n",
    "        mode_mat = torch.zeros(n_grp_neurons, n_cur_modes)\n",
    "        for mode_i in range(n_cur_modes):\n",
    "            mode_mat[:, mode_i] = true_prior_mode_dists[g][i][mode_i].form_standard_sample(\n",
    "                true_prior_mode_dists[g][i][mode_i].sample(neuron_props[g])).squeeze()\n",
    "        if i == 0:\n",
    "            # P modes\n",
    "            true_p[g] = mode_mat\n",
    "        else:\n",
    "            # U modes\n",
    "            true_u[g] = mode_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the true subject model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_output_groups = len(d_in)\n",
    "\n",
    "M = IdentityMap()\n",
    "S = [Bias(d_o) for d_o in d_out]\n",
    "mdl = LatentRegModel(d_in, d_out, d_proj, d_trans, M, S, direct_pairs=None)\n",
    "\n",
    "for g, p_g in enumerate(mdl.p):\n",
    "    p_g.data = true_p[g]\n",
    "for h, u_h in enumerate(mdl.u):\n",
    "    u_h.data = true_u[h]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [torch.randn([n_smps, d]) for d in d_in]\n",
    "y_pred = mdl(x)\n",
    "y = mdl.generate(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the subject model we will fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_f = IdentityMap()\n",
    "s_f = [Bias(d_o) for d_o in d_out]\n",
    "subject_mdl_f = LatentRegModel(d_in, d_out, d_proj, d_trans, m_f, s_f, direct_pairs=None, assign_p_u=False)\n",
    "subject_mdl_f = subject_mdl_f.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the inference distribution (  $Q(l, r)$  ) that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_p_mode_dists = [None]*n_grps\n",
    "q_u_mode_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            n_grp_modes = d_proj[g]\n",
    "        else:\n",
    "            n_grp_modes = d_trans[g]\n",
    "    \n",
    "        q_dists = [None]*n_grp_modes\n",
    "        \n",
    "        for mode_i in range(n_grp_modes):\n",
    "            mn_f = IndSmpConstantRealFcn(n_grp_neurons, init_value=.01)\n",
    "            std_f = IndSmpConstantBoundedFcn(n_grp_neurons, lower_bound=.01, upper_bound=10.0, init_value=.2)\n",
    "            q_dists[mode_i] = CondGaussianDistribution(mn_f=mn_f, std_f=std_f)\n",
    "            q_dists[mode_i] = q_dists[mode_i].to(device)\n",
    "        \n",
    "        if i == 0:\n",
    "            q_p_mode_dists[g] = q_dists\n",
    "        else:\n",
    "            q_u_mode_dists[g] = q_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the conditional prior distribution (  $P(l,r|m)$  ) we will fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fit_prior_nodes = 50\n",
    "\n",
    "prior_p_dists = [None]*n_grps\n",
    "prior_u_dists = [None]*n_grps\n",
    "\n",
    "for g in range(n_grps):\n",
    "    n_grp_neurons = n_neurons[g]\n",
    "    for i in range(2):\n",
    "        if i == 0:\n",
    "            n_grp_modes = d_proj[g]\n",
    "        else:\n",
    "            n_grp_modes = d_trans[g]\n",
    "            \n",
    "        prior_dists = [None]*n_grp_modes\n",
    "        \n",
    "        for mode_i in range(n_grp_modes):\n",
    "            mn_fcn = torch.nn.Sequential(torch.nn.Linear(2,n_fit_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_fit_prior_nodes, n_fit_prior_nodes), torch.nn.ReLU(), \n",
    "                                              torch.nn.Linear(n_fit_prior_nodes,1))\n",
    "            \n",
    "            std_fcn = ConstantBoundedFcn(lower_bound=np.asarray([.001]), upper_bound=np.asarray([10]), \n",
    "                                        init_value=np.asarray(.01))\n",
    "            \n",
    "            prior_dists[mode_i] = CondGaussianDistribution(mn_f=mn_fcn, std_f=std_fcn)\n",
    "            prior_dists[mode_i] = prior_dists[mode_i].to(device)\n",
    "        \n",
    "        if i == 0:\n",
    "            prior_p_dists[g] = prior_dists\n",
    "        else:\n",
    "            prior_u_dists[g] = prior_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit everything with variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU memory usage: 141312 bytes.\n",
      "GPU memory usage after sending properties: 143360 bytes.\n",
      "It: 0: Elapsed fitting time 0.0, elbo: -46668858.5390625, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -46442200.0, kl_p_sum: 117158.197265625, kl_u_sum: 109500.341796875\n",
      "It: 100: Elapsed fitting time 9.588583946228027, elbo: -3273570.0393066406, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -3249225.5, kl_p_sum: 12818.234008789062, kl_u_sum: 11526.305297851562\n",
      "It: 200: Elapsed fitting time 18.81774067878723, elbo: -1861747.574645996, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -1852829.75, kl_p_sum: 4560.582336425781, kl_u_sum: 4357.2423095703125\n",
      "It: 300: Elapsed fitting time 28.085695505142212, elbo: -1256815.7070922852, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -1251725.5, kl_p_sum: 2670.255126953125, kl_u_sum: 2419.9519653320312\n",
      "It: 400: Elapsed fitting time 37.298930406570435, elbo: -898232.6693115234, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -894421.75, kl_p_sum: 1952.964599609375, kl_u_sum: 1857.9547119140625\n",
      "It: 500: Elapsed fitting time 46.51677060127258, elbo: -645498.3089599609, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -642277.5, kl_p_sum: 1617.5455627441406, kl_u_sum: 1603.2633972167969\n",
      "It: 600: Elapsed fitting time 55.720500230789185, elbo: -518102.0489807129, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -515232.875, kl_p_sum: 1433.4239807128906, kl_u_sum: 1435.75\n",
      "It: 700: Elapsed fitting time 64.9040675163269, elbo: -418468.3003234863, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -415816.40625, kl_p_sum: 1322.802734375, kl_u_sum: 1329.0913391113281\n",
      "It: 800: Elapsed fitting time 74.09668588638306, elbo: -350604.9414367676, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -348033.0625, kl_p_sum: 1261.9530944824219, kl_u_sum: 1309.9258422851562\n",
      "It: 900: Elapsed fitting time 83.59949254989624, elbo: -302493.40643310547, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -299980.6875, kl_p_sum: 1229.3164367675781, kl_u_sum: 1283.4024963378906\n",
      "It: 1000: Elapsed fitting time 92.95371270179749, elbo: -260888.2657775879, lr: 0.03, GPU mem. usage: 1834496 bytes\n",
      "    ll: -258377.890625, kl_p_sum: 1209.1827392578125, kl_u_sum: 1301.1924133300781\n"
     ]
    }
   ],
   "source": [
    "log = vae_fit_latent_reg_model(l_mdl = subject_mdl_f, q_p_dists=q_p_mode_dists, q_u_dists=q_u_mode_dists, \n",
    "                             prior_p_dists=prior_p_dists, prior_u_dists=prior_u_dists, learning_rates = .03,\n",
    "                             x=x, y=y, x_props=neuron_props, batch_size = 100, send_size = 100, update_int=100, \n",
    "                             max_its=2000, min_var=.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(log['elapsed_time'], log['elbo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_g = 1\n",
    "\n",
    "true_w = torch.matmul(true_u[vis_g], true_p[vis_g].t()).detach().numpy()\n",
    "\n",
    "est_p = [d.sample(neuron_props[vis_g]) for d in q_p_mode_dists[vis_g]]\n",
    "est_p = torch.cat(est_p, dim=1)\n",
    "\n",
    "est_u = [d.sample(neuron_props[vis_g]) for d in q_u_mode_dists[vis_g]]\n",
    "est_u = torch.cat(est_u, dim=1)\n",
    "\n",
    "est_w = torch.matmul(est_u, est_p.t()).detach().cpu().numpy()\n",
    "\n",
    "cmp_n_mats([true_w, est_w, true_w-est_w], show_colorbars=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mode_pairs(true_prior_u_dists[vis_g], prior_u_dists[vis_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_mode_pairs(true_prior_p_dists[vis_g], prior_p_dists[vis_g])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
